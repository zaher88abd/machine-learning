<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>smartcab</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.6 (http://getbootstrap.com)
 * Copyright 2011-2015 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: thin dotted;
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: thin dotted;
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: thin dotted;
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
@-moz-document url-prefix() {
  div.inner_cell {
    overflow-x: hidden;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 20ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}

@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Machine-Learning-Engineer-Nanodegree">Machine Learning Engineer Nanodegree<a class="anchor-link" href="#Machine-Learning-Engineer-Nanodegree">&#182;</a></h1><h2 id="Reinforcement-Learning">Reinforcement Learning<a class="anchor-link" href="#Reinforcement-Learning">&#182;</a></h2><h2 id="Project:-Train-a-Smartcab-to-Drive">Project: Train a Smartcab to Drive<a class="anchor-link" href="#Project:-Train-a-Smartcab-to-Drive">&#182;</a></h2><p>Welcome to the fourth project of the Machine Learning Engineer Nanodegree! In this notebook, template code has already been provided for you to aid in your analysis of the <em>Smartcab</em> and your implemented learning algorithm. You will not need to modify the included code beyond what is requested. There will be questions that you must answer which relate to the project and the visualizations provided in the notebook. Each section where you will answer a question is preceded by a <strong>'Question X'</strong> header. Carefully read each question and provide thorough answers in the following text boxes that begin with <strong>'Answer:'</strong>. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide in <code>agent.py</code>.</p>
<blockquote><p><strong>Note:</strong> Code and Markdown cells can be executed using the <strong>Shift + Enter</strong> keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Getting-Started">Getting Started<a class="anchor-link" href="#Getting-Started">&#182;</a></h2><p>In this project, you will work towards constructing an optimized Q-Learning driving agent that will navigate a <em>Smartcab</em> through its environment towards a goal. Since the <em>Smartcab</em> is expected to drive passengers from one location to another, the driving agent will be evaluated on two very important metrics: <strong>Safety</strong> and <strong>Reliability</strong>. A driving agent that gets the <em>Smartcab</em> to its destination while running red lights or narrowly avoiding accidents would be considered <strong>unsafe</strong>. Similarly, a driving agent that frequently fails to reach the destination in time would be considered <strong>unreliable</strong>. Maximizing the driving agent's <strong>safety</strong> and <strong>reliability</strong> would ensure that <em>Smartcabs</em> have a permanent place in the transportation industry.</p>
<p><strong>Safety</strong> and <strong>Reliability</strong> are measured using a letter-grade system as follows:</p>
<table>
<thead><tr>
<th style="text-align:center">Grade</th>
<th style="text-align:center">Safety</th>
<th style="text-align:center">Reliability</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">A+</td>
<td style="text-align:center">Agent commits no traffic violations,<br/>and always chooses the correct action.</td>
<td style="text-align:center">Agent reaches the destination in time<br />for 100% of trips.</td>
</tr>
<tr>
<td style="text-align:center">A</td>
<td style="text-align:center">Agent commits few minor traffic violations,<br/>such as failing to move on a green light.</td>
<td style="text-align:center">Agent reaches the destination on time<br />for at least 90% of trips.</td>
</tr>
<tr>
<td style="text-align:center">B</td>
<td style="text-align:center">Agent commits frequent minor traffic violations,<br/>such as failing to move on a green light.</td>
<td style="text-align:center">Agent reaches the destination on time<br />for at least 80% of trips.</td>
</tr>
<tr>
<td style="text-align:center">C</td>
<td style="text-align:center">Agent commits at least one major traffic violation,<br/> such as driving through a red light.</td>
<td style="text-align:center">Agent reaches the destination on time<br />for at least 70% of trips.</td>
</tr>
<tr>
<td style="text-align:center">D</td>
<td style="text-align:center">Agent causes at least one minor accident,<br/> such as turning left on green with oncoming traffic.</td>
<td style="text-align:center">Agent reaches the destination on time<br />for at least 60% of trips.</td>
</tr>
<tr>
<td style="text-align:center">F</td>
<td style="text-align:center">Agent causes at least one major accident,<br />such as driving through a red light with cross-traffic.</td>
<td style="text-align:center">Agent fails to reach the destination on time<br />for at least 60% of trips.</td>
</tr>
</tbody>
</table>
<p>To assist evaluating these important metrics, you will need to load visualization code that will be used later on in the project. Run the code cell below to import this code which is required for your analysis.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Import the visualization code</span>
<span class="kn">import</span> <span class="nn">visuals</span> <span class="kn">as</span> <span class="nn">vs</span>

<span class="c1"># Pretty display for notebooks</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Understand-the-World">Understand the World<a class="anchor-link" href="#Understand-the-World">&#182;</a></h3><p>Before starting to work on implementing your driving agent, it's necessary to first understand the world (environment) which the <em>Smartcab</em> and driving agent work in. One of the major components to building a self-learning agent is understanding the characteristics about the agent, which includes how the agent operates. To begin, simply run the <code>agent.py</code> agent code exactly how it is -- no need to make any additions whatsoever. Let the resulting simulation run for some time to see the various working components. Note that in the visual simulation (if enabled), the <strong>white vehicle</strong> is the <em>Smartcab</em>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Question-1">Question 1<a class="anchor-link" href="#Question-1">&#182;</a></h3><p>In a few sentences, describe what you observe during the simulation when running the default <code>agent.py</code> agent code. Some things you could consider:</p>
<ul>
<li><em>Does the Smartcab move at all during the simulation?</em></li>
<li><em>What kind of rewards is the driving agent receiving?</em></li>
<li><em>How does the light changing color affect the rewards?</em>  </li>
</ul>
<p><strong>Hint:</strong> From the <code>/smartcab/</code> top-level directory (where this notebook is located), run the command</p>
<div class="highlight"><pre><span></span><span class="s1">&#39;python smartcab/agent.py&#39;</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[32]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="o">%</span><span class="k">run</span>  smartcab/agent.py
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>
/-------------------------
| Training trial 1
\-------------------------

Environment.reset(): Trial set up with start = (4, 7), destination = (2, 4), deadline = 25
Simulating trial. . . 
epsilon = 0.9500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.95
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: None, reward: 1.56150894743
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNl&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 0, &#39;action&#39;: None, &#39;reward&#39;: 1.5615089474346047, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNl
Agent properly idled at a red light. (rewarded 1.56)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.95
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: left, reward: -39.8300834161
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNf&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 1, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -39.83008341612503, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNf
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -39.83)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.95
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: None, reward: 2.97444115775
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNfN&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 2, &#39;action&#39;: None, &#39;reward&#39;: 2.9744411577540504, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNfN
Agent properly idled at a red light. (rewarded 2.97)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.95
Environment.act() [POST]: location: (5, 7), heading: (1, 0), action: right, reward: 0.705769458765
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNr&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 3, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.7057694587646244, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNr
Agent drove right instead of left. (rewarded 0.71)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.95
Environment.act() [POST]: location: (5, 6), heading: (0, -1), action: left, reward: 1.79664883017
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNff&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 4, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.7966488301736652, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNff
Agent drove left instead of right. (rewarded 1.80)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.95
Environment.act() [POST]: location: (6, 6), heading: (1, 0), action: right, reward: 0.960608191571
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 5, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.9606081915710271, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent drove right instead of left. (rewarded 0.96)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.95
Environment.act() [POST]: location: (6, 6), heading: (1, 0), action: None, reward: 2.2377635121
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frrNf&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 6, &#39;action&#39;: None, &#39;reward&#39;: 2.237763512101724, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frrNf
Agent properly idled at a red light. (rewarded 2.24)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.95
Environment.act() [POST]: location: (6, 6), heading: (1, 0), action: left, reward: -10.0978096471
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfrl&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 7, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.097809647093321, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfrl
Agent attempted driving left through a red light. (rewarded -10.10)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.95
Environment.act() [POST]: location: (6, 6), heading: (1, 0), action: left, reward: -9.58328656221
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNr&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 8, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -9.583286562208524, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNr
Agent attempted driving left through a red light. (rewarded -9.58)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.95
Environment.act() [POST]: location: (6, 6), heading: (1, 0), action: left, reward: -9.34671460495
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfrN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 9, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -9.34671460494919, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfrN
Agent attempted driving left through a red light. (rewarded -9.35)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.95
Environment.act() [POST]: location: (6, 7), heading: (0, 1), action: right, reward: 0.31342770464
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frflN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 10, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.3134277046395776, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frflN
Agent drove right instead of forward. (rewarded 0.31)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.95
Environment.act() [POST]: location: (6, 7), heading: (0, 1), action: None, reward: 1.04008301456
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNff&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 11, &#39;action&#39;: None, &#39;reward&#39;: 1.040083014559833, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNff
Agent properly idled at a red light. (rewarded 1.04)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.95
Environment.act() [POST]: location: (6, 7), heading: (0, 1), action: forward, reward: -10.1560316824
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 12, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.156031682398368, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent attempted driving forward through a red light. (rewarded -10.16)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.95
Environment.act() [POST]: location: (6, 7), heading: (0, 1), action: left, reward: -39.5548880003
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrrNN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 13, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -39.55488800028788, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrrNN
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -39.55)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.95
Environment.act() [POST]: location: (6, 7), heading: (0, 1), action: None, reward: 1.59161018392
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 14, &#39;action&#39;: None, &#39;reward&#39;: 1.591610183919153, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.59)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.95
Environment.act() [POST]: location: (6, 7), heading: (0, 1), action: left, reward: -9.83843378098
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNr&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 15, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -9.83843378097636, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNr
Agent attempted driving left through a red light. (rewarded -9.84)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.95
Environment.act() [POST]: location: (6, 7), heading: (0, 1), action: None, reward: -5.35193448691
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 16, &#39;action&#39;: None, &#39;reward&#39;: -5.351934486905204, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent idled at a green light with no oncoming traffic. (rewarded -5.35)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.95
Environment.act() [POST]: location: (6, 7), heading: (0, 1), action: left, reward: -19.5899952292
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 3, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 17, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -19.58999522919671, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNN
Agent attempted driving left through traffic and cause a minor accident. (rewarded -19.59)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.95
Environment.act() [POST]: location: (6, 7), heading: (0, 1), action: None, reward: -5.69622318685
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 18, &#39;action&#39;: None, &#39;reward&#39;: -5.696223186846625, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent idled at a green light with no oncoming traffic. (rewarded -5.70)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.95
Environment.act() [POST]: location: (6, 2), heading: (0, 1), action: forward, reward: 0.0259601461529
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 19, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.025960146152881225, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.03)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.95
Environment.act() [POST]: location: (6, 2), heading: (0, 1), action: forward, reward: -10.6493811998
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 20, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.64938119983251, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent attempted driving forward through a red light. (rewarded -10.65)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.95
Environment.act() [POST]: location: (6, 3), heading: (0, 1), action: forward, reward: 0.399564010299
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 21, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.3995640102991581, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent drove forward instead of left. (rewarded 0.40)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.95
Environment.act() [POST]: location: (6, 4), heading: (0, 1), action: forward, reward: 0.153221036312
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 22, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.1532210363124089, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent drove forward instead of left. (rewarded 0.15)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0.95
Environment.act() [POST]: location: (6, 5), heading: (0, 1), action: forward, reward: -0.113772224126
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNf&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 23, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -0.1137722241257142, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNf
Agent drove forward instead of left. (rewarded -0.11)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0.95
Environment.act() [POST]: location: (6, 6), heading: (0, 1), action: forward, reward: -0.101934970008
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNfl&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 24, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -0.10193497000811469, &#39;waypoint&#39;: &#39;left&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: lgNfl
Agent drove forward instead of left. (rewarded -0.10)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 2
\-------------------------

Environment.reset(): Trial set up with start = (7, 2), destination = (5, 4), deadline = 20
Simulating trial. . . 
epsilon = 0.9000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.9
Environment.act() [POST]: location: (7, 2), heading: (0, -1), action: None, reward: 1.97266315444
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: None, &#39;reward&#39;: 1.9726631544441675, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.97)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.9
Environment.act() [POST]: location: (7, 2), heading: (0, -1), action: None, reward: 1.56952115463
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: None, &#39;reward&#39;: 1.5695211546315144, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.57)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.9
Environment.act() [POST]: location: (7, 2), heading: (0, -1), action: None, reward: 2.67717838328
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: None, &#39;reward&#39;: 2.6771783832787803, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 2.68)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.9
Environment.act() [POST]: location: (7, 2), heading: (0, -1), action: None, reward: 1.7688105001
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 1.7688105001044965, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.77)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.9
Environment.act() [POST]: location: (8, 2), heading: (1, 0), action: right, reward: 0.831989921564
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.8319899215643817, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent drove right instead of left. (rewarded 0.83)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.9
Environment.act() [POST]: location: (8, 2), heading: (1, 0), action: forward, reward: -40.8637061268
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNfl&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.8637061268225, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNfl
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.86)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.9
Environment.act() [POST]: location: (8, 2), heading: (1, 0), action: forward, reward: -9.55088577563
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNrl&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.550885775631059, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNrl
Agent attempted driving forward through a red light. (rewarded -9.55)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.9
Environment.act() [POST]: location: (8, 3), heading: (0, 1), action: right, reward: 2.53771321357
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNl&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.537713213570237, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNl
Agent followed the waypoint right. (rewarded 2.54)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.9
Environment.act() [POST]: location: (7, 3), heading: (-1, 0), action: right, reward: 1.57862706777
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.5786270677731908, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 1.58)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.9
Environment.act() [POST]: location: (7, 3), heading: (-1, 0), action: left, reward: -39.1571152649
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNf&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -39.15711526488462, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNf
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -39.16)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.9
Environment.act() [POST]: location: (7, 3), heading: (-1, 0), action: None, reward: 2.54153825103
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: None, &#39;reward&#39;: 2.541538251032656, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.54)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.9
Environment.act() [POST]: location: (6, 3), heading: (-1, 0), action: forward, reward: 2.31256383373
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.3125638337346572, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 2.31)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.9
Environment.act() [POST]: location: (6, 3), heading: (-1, 0), action: None, reward: 1.7520871306
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNl&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: None, &#39;reward&#39;: 1.7520871305986283, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNl
Agent properly idled at a red light. (rewarded 1.75)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.9
Environment.act() [POST]: location: (6, 3), heading: (-1, 0), action: None, reward: 0.674681797941
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: None, &#39;reward&#39;: 0.6746817979408526, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 0.67)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.9
Environment.act() [POST]: location: (6, 2), heading: (0, -1), action: right, reward: 0.208094254556
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 14, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.20809425455628727, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNN
Agent drove right instead of forward. (rewarded 0.21)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.9
Environment.act() [POST]: location: (6, 7), heading: (0, -1), action: forward, reward: 0.14281694223
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNf&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 15, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.14281694222986574, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNf
Agent drove forward instead of left. (rewarded 0.14)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.9
Environment.act() [POST]: location: (6, 6), heading: (0, -1), action: forward, reward: 0.705046172505
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNfN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 16, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.7050461725050599, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNfN
Agent drove forward instead of left. (rewarded 0.71)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.9
Environment.act() [POST]: location: (6, 5), heading: (0, -1), action: forward, reward: 0.0843998476059
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 17, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.08439984760593877, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.08)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.9
Environment.act() [POST]: location: (6, 5), heading: (0, -1), action: None, reward: -5.22565792779
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNf&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 18, &#39;action&#39;: None, &#39;reward&#39;: -5.225657927787727, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNf
Agent idled at a green light with no oncoming traffic. (rewarded -5.23)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.9
Environment.act() [POST]: location: (6, 5), heading: (0, -1), action: forward, reward: -39.9598044101
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNf&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 19, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.95980441008708, &#39;waypoint&#39;: &#39;left&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: lrlNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.96)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 3
\-------------------------

Environment.reset(): Trial set up with start = (3, 7), destination = (7, 2), deadline = 25
Simulating trial. . . 
epsilon = 0.8500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.85
Environment.act() [POST]: location: (3, 7), heading: (-1, 0), action: None, reward: -5.10363931803
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 0, &#39;action&#39;: None, &#39;reward&#39;: -5.103639318026089, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent idled at a green light with no oncoming traffic. (rewarded -5.10)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.85
Environment.act() [POST]: location: (2, 7), heading: (-1, 0), action: forward, reward: 2.85444296667
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.854442966668862, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 2.85)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.85
Environment.act() [POST]: location: (1, 7), heading: (-1, 0), action: forward, reward: 1.40981128554
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNl&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.409811285536963, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNl
Agent followed the waypoint forward. (rewarded 1.41)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.85
Environment.act() [POST]: location: (1, 7), heading: (-1, 0), action: forward, reward: -9.54502752311
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNN&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 3, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.545027523114697, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNN
Agent attempted driving forward through a red light. (rewarded -9.55)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.85
Environment.act() [POST]: location: (1, 7), heading: (-1, 0), action: None, reward: -5.632779998
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfNf&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: -5.6327799980004585, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfNf
Agent idled at a green light with no oncoming traffic. (rewarded -5.63)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.85
Environment.act() [POST]: location: (1, 6), heading: (0, -1), action: right, reward: 1.4041058659
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNf&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 5, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.4041058659043775, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNf
Agent drove right instead of forward. (rewarded 1.40)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.85
Environment.act() [POST]: location: (2, 6), heading: (1, 0), action: right, reward: 1.62165690564
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNl&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 6, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.621656905639774, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNl
Agent drove right instead of left. (rewarded 1.62)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.85
Environment.act() [POST]: location: (2, 6), heading: (1, 0), action: forward, reward: -9.10189373611
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNl&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 7, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.101893736112517, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNl
Agent attempted driving forward through a red light. (rewarded -9.10)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.85
Environment.act() [POST]: location: (2, 6), heading: (1, 0), action: None, reward: 1.01030927097
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 8, &#39;action&#39;: None, &#39;reward&#39;: 1.0103092709748454, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 1.01)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.85
Environment.act() [POST]: location: (2, 6), heading: (1, 0), action: forward, reward: -39.0261549797
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNf&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.026154979655665, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.03)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.85
Environment.act() [POST]: location: (2, 5), heading: (0, -1), action: left, reward: 1.42593913698
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNfN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 10, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.4259391369802827, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNfN
Agent drove left instead of right. (rewarded 1.43)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.85
Environment.act() [POST]: location: (3, 5), heading: (1, 0), action: right, reward: 0.101049853257
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNl&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 11, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.10104985325745253, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNl
Agent drove right instead of left. (rewarded 0.10)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.85
Environment.act() [POST]: location: (3, 5), heading: (1, 0), action: None, reward: 1.34924250731
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNf&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 12, &#39;action&#39;: None, &#39;reward&#39;: 1.3492425073075707, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNf
Agent idled at a green light with oncoming traffic. (rewarded 1.35)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.85
Environment.act() [POST]: location: (3, 5), heading: (1, 0), action: forward, reward: -40.9602800744
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrrNf&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.96028007444311, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrrNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.96)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.85
Environment.act() [POST]: location: (3, 6), heading: (0, 1), action: right, reward: 1.58146453615
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrrNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 14, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.5814645361478021, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrrNN
Agent followed the waypoint right. (rewarded 1.58)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.85
Environment.act() [POST]: location: (3, 7), heading: (0, 1), action: forward, reward: 1.58229423846
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 15, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.5822942384553749, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent drove forward instead of right. (rewarded 1.58)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.85
Environment.act() [POST]: location: (3, 2), heading: (0, 1), action: forward, reward: 0.558236011627
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNlN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 16, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.5582360116273765, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNlN
Agent drove forward instead of right. (rewarded 0.56)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.85
Environment.act() [POST]: location: (3, 2), heading: (0, 1), action: forward, reward: -9.10150216464
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 17, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.101502164641804, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfNN
Agent attempted driving forward through a red light. (rewarded -9.10)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.85
Environment.act() [POST]: location: (3, 2), heading: (0, 1), action: forward, reward: -9.96050764785
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfNl&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 18, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.960507647850445, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfNl
Agent attempted driving forward through a red light. (rewarded -9.96)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.85
Environment.act() [POST]: location: (3, 2), heading: (0, 1), action: left, reward: -9.77964140449
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfrl&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 19, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -9.779641404491416, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfrl
Agent attempted driving left through a red light. (rewarded -9.78)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.85
Environment.act() [POST]: location: (3, 2), heading: (0, 1), action: left, reward: -9.76312121913
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfNN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 20, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -9.76312121913422, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfNN
Agent attempted driving left through a red light. (rewarded -9.76)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.85
Environment.act() [POST]: location: (3, 2), heading: (0, 1), action: left, reward: -20.7986859131
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 3, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgfNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 21, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -20.798685913089646, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgfNN
Agent attempted driving left through traffic and cause a minor accident. (rewarded -20.80)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.85
Environment.act() [POST]: location: (2, 2), heading: (-1, 0), action: right, reward: 1.84638333942
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 22, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.8463833394175182, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 1.85)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0.85
Environment.act() [POST]: location: (2, 3), heading: (0, 1), action: left, reward: -0.760351226884
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 23, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -0.7603512268838244, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent drove left instead of forward. (rewarded -0.76)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0.85
Environment.act() [POST]: location: (2, 3), heading: (0, 1), action: left, reward: -39.4023487337
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNf&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 24, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -39.402348733653355, &#39;waypoint&#39;: &#39;right&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: rrlNf
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -39.40)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 4
\-------------------------

Environment.reset(): Trial set up with start = (2, 5), destination = (4, 3), deadline = 20
Simulating trial. . . 
epsilon = 0.8000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.8
Environment.act() [POST]: location: (3, 5), heading: (1, 0), action: left, reward: 2.44309619318
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.443096193181028, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 2.44)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.8
Environment.act() [POST]: location: (3, 5), heading: (1, 0), action: forward, reward: -39.6547454746
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlfl&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.654745474636506, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlfl
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.65)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.8
Environment.act() [POST]: location: (3, 5), heading: (1, 0), action: None, reward: 2.38155692621
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: None, &#39;reward&#39;: 2.381556926212771, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 2.38)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.8
Environment.act() [POST]: location: (3, 5), heading: (1, 0), action: None, reward: 0.131588586475
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 0.13158858647546257, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent idled at a green light with oncoming traffic. (rewarded 0.13)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.8
Environment.act() [POST]: location: (4, 5), heading: (1, 0), action: forward, reward: 2.62292232312
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.6229223231207346, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 2.62)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.8
Environment.act() [POST]: location: (5, 5), heading: (1, 0), action: forward, reward: 0.740661870293
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNll&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.7406618702933874, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNll
Agent drove forward instead of left. (rewarded 0.74)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.8
Environment.act() [POST]: location: (5, 5), heading: (1, 0), action: left, reward: -40.4039940725
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNfN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -40.403994072450494, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNfN
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -40.40)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.8
Environment.act() [POST]: location: (5, 5), heading: (1, 0), action: None, reward: 0.260859388888
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: None, &#39;reward&#39;: 0.2608593888876607, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent idled at a green light with oncoming traffic. (rewarded 0.26)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.8
Environment.act() [POST]: location: (6, 5), heading: (1, 0), action: forward, reward: 1.44345815701
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgllN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.443458157010522, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgllN
Agent drove forward instead of left. (rewarded 1.44)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.8
Environment.act() [POST]: location: (7, 5), heading: (1, 0), action: forward, reward: 0.681695599749
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.6816955997485961, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent drove forward instead of left. (rewarded 0.68)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.8
Environment.act() [POST]: location: (7, 4), heading: (0, -1), action: left, reward: 2.4772685577
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNf&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.477268557696366, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNf
Agent followed the waypoint left. (rewarded 2.48)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.8
Environment.act() [POST]: location: (7, 4), heading: (0, -1), action: left, reward: -40.0173430811
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNfN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -40.01734308107455, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNfN
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -40.02)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.8
Environment.act() [POST]: location: (7, 4), heading: (0, -1), action: None, reward: 2.0721628951
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNl&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: None, &#39;reward&#39;: 2.072162895100705, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNl
Agent properly idled at a red light. (rewarded 2.07)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.8
Environment.act() [POST]: location: (7, 4), heading: (0, -1), action: None, reward: 1.00360935876
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNl&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: None, &#39;reward&#39;: 1.003609358762722, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNl
Agent properly idled at a red light. (rewarded 1.00)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.8
Environment.act() [POST]: location: (7, 4), heading: (0, -1), action: None, reward: 1.76812689136
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 14, &#39;action&#39;: None, &#39;reward&#39;: 1.768126891360311, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.77)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.8
Environment.act() [POST]: location: (8, 4), heading: (1, 0), action: right, reward: 0.161662822493
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlrN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 15, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.16166282249325525, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlrN
Agent drove right instead of left. (rewarded 0.16)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.8
Environment.act() [POST]: location: (8, 4), heading: (1, 0), action: None, reward: -5.79746825536
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNf&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 16, &#39;action&#39;: None, &#39;reward&#39;: -5.797468255362125, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNf
Agent idled at a green light with no oncoming traffic. (rewarded -5.80)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.8
Environment.act() [POST]: location: (8, 5), heading: (0, 1), action: right, reward: 0.781242486292
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNff&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 17, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.7812424862923834, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNff
Agent drove right instead of forward. (rewarded 0.78)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.8
Environment.act() [POST]: location: (8, 5), heading: (0, 1), action: left, reward: -39.4261002387
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNf&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 18, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -39.42610023865322, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNf
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -39.43)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.8
Environment.act() [POST]: location: (8, 5), heading: (0, 1), action: forward, reward: -9.01118668064
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNl&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 19, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.01118668063771, &#39;waypoint&#39;: &#39;left&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: lrNNl
Agent attempted driving forward through a red light. (rewarded -9.01)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 5
\-------------------------

Environment.reset(): Trial set up with start = (7, 4), destination = (3, 4), deadline = 20
Simulating trial. . . 
epsilon = 0.7500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.75
Environment.act() [POST]: location: (8, 4), heading: (1, 0), action: right, reward: 2.65758443055
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.657584430554879, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 2.66)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.75
Environment.act() [POST]: location: (8, 4), heading: (1, 0), action: None, reward: -5.57244755161
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: None, &#39;reward&#39;: -5.572447551609136, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfNN
Agent idled at a green light with no oncoming traffic. (rewarded -5.57)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.75
Environment.act() [POST]: location: (8, 3), heading: (0, -1), action: left, reward: 0.12149219528
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.12149219527992561, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent drove left instead of forward. (rewarded 0.12)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.75
Environment.act() [POST]: location: (8, 3), heading: (0, -1), action: None, reward: -4.41733191748
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgrff&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: -4.4173319174790375, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgrff
Agent idled at a green light with no oncoming traffic. (rewarded -4.42)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.75
Environment.act() [POST]: location: (8, 3), heading: (0, -1), action: left, reward: -40.0700606758
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrrff&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -40.07006067579549, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrrff
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -40.07)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.75
Environment.act() [POST]: location: (8, 3), heading: (0, -1), action: right, reward: -20.3207702541
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 3, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNfN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -20.320770254126614, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNfN
Agent attempted driving right through traffic and cause a minor accident. (rewarded -20.32)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.75
Environment.act() [POST]: location: (1, 3), heading: (1, 0), action: right, reward: 1.99718039845
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNl&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.9971803984498007, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNl
Agent followed the waypoint right. (rewarded 2.00)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.75
Environment.act() [POST]: location: (2, 3), heading: (1, 0), action: forward, reward: 1.23630438551
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNfN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.236304385505399, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNfN
Agent followed the waypoint forward. (rewarded 1.24)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.75
Environment.act() [POST]: location: (2, 3), heading: (1, 0), action: None, reward: -5.65056960221
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNfl&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: None, &#39;reward&#39;: -5.6505696022134995, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNfl
Agent idled at a green light with no oncoming traffic. (rewarded -5.65)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.75
Environment.act() [POST]: location: (2, 3), heading: (1, 0), action: right, reward: -20.162480309
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 3, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNfl&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -20.162480308991434, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNfl
Agent attempted driving right through traffic and cause a minor accident. (rewarded -20.16)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.75
Environment.act() [POST]: location: (2, 3), heading: (1, 0), action: None, reward: 2.38381760061
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frllN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: None, &#39;reward&#39;: 2.3838176006076663, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frllN
Agent properly idled at a red light. (rewarded 2.38)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.75
Environment.act() [POST]: location: (2, 3), heading: (1, 0), action: forward, reward: -9.30438235508
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.304382355076116, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent attempted driving forward through a red light. (rewarded -9.30)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.75
Environment.act() [POST]: location: (2, 4), heading: (0, 1), action: right, reward: 0.260942038231
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.26094203823113093, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 0.26)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.75
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (3, 4), heading: (1, 0), action: left, reward: 0.848611996199
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNff&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.8486119961989187, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNff
Agent followed the waypoint left. (rewarded 0.85)
30% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Training trial 6
\-------------------------

Environment.reset(): Trial set up with start = (5, 4), destination = (7, 7), deadline = 25
Simulating trial. . . 
epsilon = 0.7000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.7
Environment.act() [POST]: location: (4, 4), heading: (-1, 0), action: right, reward: 1.04370160684
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrflN&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 0, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.0437016068370475, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrflN
Agent drove right instead of left. (rewarded 1.04)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.7
Environment.act() [POST]: location: (4, 3), heading: (0, -1), action: right, reward: 1.2866589245
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNf&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 1, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.2866589244953939, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNf
Agent followed the waypoint right. (rewarded 1.29)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.7
Environment.act() [POST]: location: (5, 3), heading: (1, 0), action: right, reward: 2.87712170813
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNl&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 2, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.877121708128188, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNl
Agent followed the waypoint right. (rewarded 2.88)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.7
Environment.act() [POST]: location: (5, 3), heading: (1, 0), action: None, reward: -4.52606941058
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNlN&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: -4.526069410577215, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNlN
Agent idled at a green light with no oncoming traffic. (rewarded -4.53)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.7
Environment.act() [POST]: location: (5, 4), heading: (0, 1), action: right, reward: 0.519998606721
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlN&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 4, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.5199986067206698, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlN
Agent drove right instead of forward. (rewarded 0.52)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.7
Environment.act() [POST]: location: (6, 4), heading: (1, 0), action: left, reward: 1.48501091337
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNfN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 5, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.4850109133651048, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNfN
Agent followed the waypoint left. (rewarded 1.49)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.7
Environment.act() [POST]: location: (7, 4), heading: (1, 0), action: forward, reward: 1.41042433446
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.410424334463572, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 1.41)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.7
Environment.act() [POST]: location: (7, 3), heading: (0, -1), action: left, reward: 1.43033734184
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNf&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 7, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.430337341835518, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNf
Agent followed the waypoint left. (rewarded 1.43)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.7
Environment.act() [POST]: location: (8, 3), heading: (1, 0), action: right, reward: 1.31199497817
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.3119949781730011, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent drove right instead of forward. (rewarded 1.31)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.7
Environment.act() [POST]: location: (8, 3), heading: (1, 0), action: None, reward: 1.98685097746
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 9, &#39;action&#39;: None, &#39;reward&#39;: 1.9868509774551795, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.99)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.7
Environment.act() [POST]: location: (8, 2), heading: (0, -1), action: left, reward: 1.08851961355
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 10, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.088519613546579, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent followed the waypoint left. (rewarded 1.09)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.7
Environment.act() [POST]: location: (8, 2), heading: (0, -1), action: None, reward: 2.20390652535
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfrf&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 11, &#39;action&#39;: None, &#39;reward&#39;: 2.2039065253487817, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfrf
Agent properly idled at a red light. (rewarded 2.20)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.7
Environment.act() [POST]: location: (8, 2), heading: (0, -1), action: right, reward: -20.7602244485
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 3, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrffN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 12, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -20.760224448511185, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrffN
Agent attempted driving right through traffic and cause a minor accident. (rewarded -20.76)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.7
Environment.act() [POST]: location: (8, 7), heading: (0, -1), action: forward, reward: 1.32062820963
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.3206282096280626, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNN
Agent drove forward instead of left. (rewarded 1.32)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.7
Environment.act() [POST]: location: (8, 7), heading: (0, -1), action: left, reward: -39.9968779142
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNf&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 14, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -39.996877914242, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNf
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -40.00)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.7
Environment.act() [POST]: location: (8, 7), heading: (0, -1), action: None, reward: 1.65235419706
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 15, &#39;action&#39;: None, &#39;reward&#39;: 1.652354197064866, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.65)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.7
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (7, 7), heading: (-1, 0), action: left, reward: 2.05589465727
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 16, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.055894657266496, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent followed the waypoint left. (rewarded 2.06)
32% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Training trial 7
\-------------------------

Environment.reset(): Trial set up with start = (5, 7), destination = (2, 4), deadline = 30
Simulating trial. . . 
epsilon = 0.6500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.65
Environment.act() [POST]: location: (6, 7), heading: (1, 0), action: left, reward: 0.862671576609
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNlr&#39;, &#39;deadline&#39;: 30, &#39;t&#39;: 0, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.8626715766093185, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNlr
Agent drove left instead of right. (rewarded 0.86)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.65
Environment.act() [POST]: location: (6, 7), heading: (1, 0), action: None, reward: 1.13923081346
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNfN&#39;, &#39;deadline&#39;: 29, &#39;t&#39;: 1, &#39;action&#39;: None, &#39;reward&#39;: 1.1392308134600164, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNfN
Agent properly idled at a red light. (rewarded 1.14)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.65
Environment.act() [POST]: location: (6, 7), heading: (1, 0), action: left, reward: -10.8236083823
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNl&#39;, &#39;deadline&#39;: 28, &#39;t&#39;: 2, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.823608382301988, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNl
Agent attempted driving left through a red light. (rewarded -10.82)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.65
Environment.act() [POST]: location: (6, 7), heading: (1, 0), action: forward, reward: -10.8324261686
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 27, &#39;t&#39;: 3, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.832426168578529, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent attempted driving forward through a red light. (rewarded -10.83)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.65
Environment.act() [POST]: location: (6, 7), heading: (1, 0), action: None, reward: 2.730691511
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 26, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 2.7306915110007393, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.73)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.65
Environment.act() [POST]: location: (6, 7), heading: (1, 0), action: None, reward: 1.92312029289
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: 1.9231202928938447, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.92)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.65
Environment.act() [POST]: location: (6, 7), heading: (1, 0), action: None, reward: -4.08136430752
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 6, &#39;action&#39;: None, &#39;reward&#39;: -4.081364307515182, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent idled at a green light with no oncoming traffic. (rewarded -4.08)
77% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.65
Environment.act() [POST]: location: (7, 7), heading: (1, 0), action: forward, reward: 2.75020289934
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 7, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.750202899340088, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 2.75)
73% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.65
Environment.act() [POST]: location: (8, 7), heading: (1, 0), action: forward, reward: 2.85088067875
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNf&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 8, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.8508806787508862, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNf
Agent followed the waypoint forward. (rewarded 2.85)
70% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.65
Environment.act() [POST]: location: (8, 7), heading: (1, 0), action: forward, reward: -10.6151352199
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNl&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.615135219876732, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNl
Agent attempted driving forward through a red light. (rewarded -10.62)
67% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.65
Environment.act() [POST]: location: (8, 6), heading: (0, -1), action: left, reward: 0.691070896666
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 10, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.6910708966659695, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent drove left instead of forward. (rewarded 0.69)
63% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.65
Environment.act() [POST]: location: (8, 6), heading: (0, -1), action: None, reward: 1.48158814744
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrrNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 11, &#39;action&#39;: None, &#39;reward&#39;: 1.4815881474417423, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrrNN
Agent properly idled at a red light. (rewarded 1.48)
60% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.65
Environment.act() [POST]: location: (8, 6), heading: (0, -1), action: None, reward: 2.8233880046
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 12, &#39;action&#39;: None, &#39;reward&#39;: 2.823388004595836, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 2.82)
57% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.65
Environment.act() [POST]: location: (7, 6), heading: (-1, 0), action: left, reward: 1.6998232616
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNfN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 13, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.699823261596531, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNfN
Agent drove left instead of right. (rewarded 1.70)
53% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.65
Environment.act() [POST]: location: (7, 6), heading: (-1, 0), action: None, reward: -4.58533163649
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 14, &#39;action&#39;: None, &#39;reward&#39;: -4.585331636488905, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent idled at a green light with no oncoming traffic. (rewarded -4.59)
50% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.65
Environment.act() [POST]: location: (7, 6), heading: (-1, 0), action: forward, reward: -10.1381829478
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 15, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.13818294776961, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent attempted driving forward through a red light. (rewarded -10.14)
47% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.65
Environment.act() [POST]: location: (7, 6), heading: (-1, 0), action: None, reward: 1.91821046043
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 16, &#39;action&#39;: None, &#39;reward&#39;: 1.9182104604260581, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 1.92)
43% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.65
Environment.act() [POST]: location: (7, 5), heading: (0, -1), action: right, reward: 2.13777735759
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 17, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.1377773575850583, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 2.14)
40% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.65
Environment.act() [POST]: location: (7, 5), heading: (0, -1), action: forward, reward: -39.4274969833
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNfr&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 18, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.427496983313794, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNfr
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.43)
37% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.65
Environment.act() [POST]: location: (7, 5), heading: (0, -1), action: forward, reward: -9.00686100358
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNlN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 19, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.006861003583406, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNlN
Agent attempted driving forward through a red light. (rewarded -9.01)
33% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.65
Environment.act() [POST]: location: (7, 5), heading: (0, -1), action: None, reward: 1.31669007884
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrrNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 20, &#39;action&#39;: None, &#39;reward&#39;: 1.3166900788374292, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrrNN
Agent properly idled at a red light. (rewarded 1.32)
30% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.65
Environment.act() [POST]: location: (7, 5), heading: (0, -1), action: None, reward: -5.74435158108
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 21, &#39;action&#39;: None, &#39;reward&#39;: -5.744351581084996, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent idled at a green light with no oncoming traffic. (rewarded -5.74)
27% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.65
Environment.act() [POST]: location: (8, 5), heading: (1, 0), action: right, reward: 0.644858395706
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNl&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 22, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.6448583957064138, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNl
Agent followed the waypoint right. (rewarded 0.64)
23% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0.65
Environment.act() [POST]: location: (8, 5), heading: (1, 0), action: forward, reward: -10.4590306873
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNr&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 23, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.45903068725096, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNr
Agent attempted driving forward through a red light. (rewarded -10.46)
20% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0.65
Environment.act() [POST]: location: (8, 5), heading: (1, 0), action: None, reward: 1.33957127794
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNfN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 24, &#39;action&#39;: None, &#39;reward&#39;: 1.3395712779414735, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNfN
Agent properly idled at a red light. (rewarded 1.34)
17% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Environment.step(): t = 25
0.65
Environment.act() [POST]: location: (8, 5), heading: (1, 0), action: left, reward: -10.0151335646
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNl&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 25, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.015133564620477, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNl
Agent attempted driving left through a red light. (rewarded -10.02)
13% of time remaining to reach destination.

/-------------------
| Step 26 Results
\-------------------

Environment.step(): t = 26
0.65
Environment.act() [POST]: location: (1, 5), heading: (1, 0), action: forward, reward: 0.782768411957
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNlN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 26, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.7827684119565936, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNlN
Agent followed the waypoint forward. (rewarded 0.78)
10% of time remaining to reach destination.

/-------------------
| Step 27 Results
\-------------------

Environment.step(): t = 27
0.65
Environment.act() [POST]: location: (1, 5), heading: (1, 0), action: None, reward: 0.628028217075
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 27, &#39;action&#39;: None, &#39;reward&#39;: 0.6280282170751035, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 0.63)
7% of time remaining to reach destination.

/-------------------
| Step 28 Results
\-------------------

Environment.step(): t = 28
0.65
Environment.act() [POST]: location: (1, 6), heading: (0, 1), action: right, reward: -0.215266708503
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 28, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.21526670850261953, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent drove right instead of forward. (rewarded -0.22)
3% of time remaining to reach destination.

/-------------------
| Step 29 Results
\-------------------

Environment.step(): t = 29
0.65
Environment.act() [POST]: location: (1, 6), heading: (0, 1), action: None, reward: 0.560350697685
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNlN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 29, &#39;action&#39;: None, &#39;reward&#39;: 0.5603506976850983, &#39;waypoint&#39;: &#39;left&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: lrNlN
Agent properly idled at a red light. (rewarded 0.56)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 8
\-------------------------

Environment.reset(): Trial set up with start = (8, 7), destination = (5, 4), deadline = 30
Simulating trial. . . 
epsilon = 0.6000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.6
Environment.act() [POST]: location: (8, 2), heading: (0, 1), action: left, reward: 0.971080281635
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgllN&#39;, &#39;deadline&#39;: 30, &#39;t&#39;: 0, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.9710802816349435, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgllN
Agent drove left instead of forward. (rewarded 0.97)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.6
Environment.act() [POST]: location: (8, 3), heading: (0, 1), action: forward, reward: 1.05613948808
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNrN&#39;, &#39;deadline&#39;: 29, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.0561394880810235, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNrN
Agent drove forward instead of right. (rewarded 1.06)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.6
Environment.act() [POST]: location: (8, 4), heading: (0, 1), action: forward, reward: 0.899785864921
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNlN&#39;, &#39;deadline&#39;: 28, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.8997858649210998, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNlN
Agent drove forward instead of right. (rewarded 0.90)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.6
Environment.act() [POST]: location: (7, 4), heading: (-1, 0), action: right, reward: 1.31713747178
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 27, &#39;t&#39;: 3, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.3171374717766686, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent followed the waypoint right. (rewarded 1.32)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.6
Environment.act() [POST]: location: (7, 4), heading: (-1, 0), action: None, reward: 1.90365265502
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frrNr&#39;, &#39;deadline&#39;: 26, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 1.9036526550164938, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frrNr
Agent properly idled at a red light. (rewarded 1.90)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.6
Environment.act() [POST]: location: (7, 4), heading: (-1, 0), action: left, reward: -10.5642260763
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 5, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.564226076271304, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent attempted driving left through a red light. (rewarded -10.56)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.6
Environment.act() [POST]: location: (6, 4), heading: (-1, 0), action: forward, reward: 1.78095154924
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfNN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.7809515492423955, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfNN
Agent followed the waypoint forward. (rewarded 1.78)
77% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.6
Environment.act() [POST]: location: (6, 4), heading: (-1, 0), action: left, reward: -9.21813978787
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 7, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -9.218139787866555, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent attempted driving left through a red light. (rewarded -9.22)
73% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.6
Environment.act() [POST]: location: (6, 4), heading: (-1, 0), action: forward, reward: -10.5386141058
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNr&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 8, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.538614105757379, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNr
Agent attempted driving forward through a red light. (rewarded -10.54)
70% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.6
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (5, 4), heading: (-1, 0), action: forward, reward: 2.01274193672
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNf&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.0127419367224677, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNf
Agent followed the waypoint forward. (rewarded 2.01)
67% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Training trial 9
\-------------------------

Environment.reset(): Trial set up with start = (6, 3), destination = (3, 2), deadline = 20
Simulating trial. . . 
epsilon = 0.5500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.55
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: right, reward: 1.68635218766
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlrl&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.6863521876581817, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlrl
Agent drove right instead of left. (rewarded 1.69)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.55
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: forward, reward: -39.4278119598
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNf&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.42781195981951, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.43)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.55
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: None, reward: 1.54224259314
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: None, &#39;reward&#39;: 1.542242593143363, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNN
Agent properly idled at a red light. (rewarded 1.54)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.55
Environment.act() [POST]: location: (8, 3), heading: (1, 0), action: forward, reward: 2.12448418902
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.1244841890217536, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfNN
Agent followed the waypoint forward. (rewarded 2.12)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.55
Environment.act() [POST]: location: (8, 3), heading: (1, 0), action: forward, reward: -40.034754995
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNff&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.034754995007034, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNff
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.03)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.55
Environment.act() [POST]: location: (8, 4), heading: (0, 1), action: right, reward: 0.491865053728
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.4918650537284319, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent drove right instead of forward. (rewarded 0.49)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.55
Environment.act() [POST]: location: (8, 4), heading: (0, 1), action: None, reward: 1.05022065764
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNff&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: None, &#39;reward&#39;: 1.0502206576406894, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNff
Agent properly idled at a red light. (rewarded 1.05)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.55
Environment.act() [POST]: location: (8, 4), heading: (0, 1), action: None, reward: 2.72856449705
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: None, &#39;reward&#39;: 2.72856449704941, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.73)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.55
Environment.act() [POST]: location: (8, 4), heading: (0, 1), action: forward, reward: -10.4449979338
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNrN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.444997933779897, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNrN
Agent attempted driving forward through a red light. (rewarded -10.44)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.55
Environment.act() [POST]: location: (7, 4), heading: (-1, 0), action: right, reward: 1.15874475667
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNr&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.1587447566721383, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNr
Agent drove right instead of left. (rewarded 1.16)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.55
Environment.act() [POST]: location: (7, 4), heading: (-1, 0), action: None, reward: 2.64163651363
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: None, &#39;reward&#39;: 2.641636513633755, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 2.64)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.55
Environment.act() [POST]: location: (6, 4), heading: (-1, 0), action: forward, reward: 0.697773592623
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.6977735926225579, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent drove forward instead of right. (rewarded 0.70)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.55
Environment.act() [POST]: location: (6, 4), heading: (-1, 0), action: None, reward: -5.40890197557
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNll&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: None, &#39;reward&#39;: -5.408901975568643, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNll
Agent idled at a green light with no oncoming traffic. (rewarded -5.41)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.55
Environment.act() [POST]: location: (6, 4), heading: (-1, 0), action: forward, reward: -9.46012729261
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNll&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.460127292611991, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNll
Agent attempted driving forward through a red light. (rewarded -9.46)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.55
Environment.act() [POST]: location: (6, 4), heading: (-1, 0), action: None, reward: 1.75222119007
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frllN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 14, &#39;action&#39;: None, &#39;reward&#39;: 1.7522211900723736, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frllN
Agent properly idled at a red light. (rewarded 1.75)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.55
Environment.act() [POST]: location: (6, 4), heading: (-1, 0), action: None, reward: 2.1503412412
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frllN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 15, &#39;action&#39;: None, &#39;reward&#39;: 2.150341241198338, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frllN
Agent properly idled at a red light. (rewarded 2.15)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.55
Environment.act() [POST]: location: (6, 4), heading: (-1, 0), action: None, reward: 2.2271398261
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 16, &#39;action&#39;: None, &#39;reward&#39;: 2.227139826099034, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 2.23)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.55
Environment.act() [POST]: location: (5, 4), heading: (-1, 0), action: forward, reward: 0.816496359242
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 17, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.8164963592418755, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 0.82)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.55
Environment.act() [POST]: location: (5, 4), heading: (-1, 0), action: None, reward: -5.57721819513
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNl&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 18, &#39;action&#39;: None, &#39;reward&#39;: -5.577218195125557, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNl
Agent idled at a green light with no oncoming traffic. (rewarded -5.58)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.55
Environment.act() [POST]: location: (5, 3), heading: (0, -1), action: right, reward: -0.412810147805
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNll&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 19, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.41281014780471426, &#39;waypoint&#39;: &#39;forward&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: frNll
Agent drove right instead of forward. (rewarded -0.41)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 10
\-------------------------

Environment.reset(): Trial set up with start = (3, 3), destination = (6, 7), deadline = 25
Simulating trial. . . 
epsilon = 0.5000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.5
Environment.act() [POST]: location: (3, 4), heading: (0, 1), action: forward, reward: 1.53098439501
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNfN&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.5309843950091122, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNfN
Agent drove forward instead of left. (rewarded 1.53)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.5
Environment.act() [POST]: location: (3, 5), heading: (0, 1), action: forward, reward: 1.87529584644
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglff&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.875295846442059, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglff
Agent drove forward instead of left. (rewarded 1.88)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.5
Environment.act() [POST]: location: (2, 5), heading: (-1, 0), action: right, reward: 1.81842995716
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNfl&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 2, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.8184299571632914, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNfl
Agent drove right instead of left. (rewarded 1.82)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.5
Environment.act() [POST]: location: (2, 5), heading: (-1, 0), action: None, reward: -4.39816062347
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNff&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: -4.398160623473956, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNff
Agent idled at a green light with no oncoming traffic. (rewarded -4.40)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.5
Environment.act() [POST]: location: (2, 5), heading: (-1, 0), action: None, reward: 1.36095918425
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNff&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 1.3609591842467315, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNff
Agent properly idled at a red light. (rewarded 1.36)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.5
Environment.act() [POST]: location: (2, 5), heading: (-1, 0), action: None, reward: 1.92567560174
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNfN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: 1.9256756017363503, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNfN
Agent properly idled at a red light. (rewarded 1.93)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.5
Environment.act() [POST]: location: (2, 5), heading: (-1, 0), action: None, reward: 2.4744742587
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 6, &#39;action&#39;: None, &#39;reward&#39;: 2.4744742586953574, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.47)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.5
Environment.act() [POST]: location: (1, 5), heading: (-1, 0), action: forward, reward: 2.22089229325
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNl&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 7, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.220892293253997, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNl
Agent followed the waypoint forward. (rewarded 2.22)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.5
Environment.act() [POST]: location: (1, 4), heading: (0, -1), action: right, reward: 0.475488961824
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNfN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.475488961824028, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNfN
Agent drove right instead of forward. (rewarded 0.48)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.5
Environment.act() [POST]: location: (1, 4), heading: (0, -1), action: left, reward: -10.006362841
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 9, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.006362841029288, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent attempted driving left through a red light. (rewarded -10.01)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.5
Environment.act() [POST]: location: (1, 3), heading: (0, -1), action: forward, reward: 0.107273367134
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 10, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.10727336713379143, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNN
Agent drove forward instead of left. (rewarded 0.11)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.5
Environment.act() [POST]: location: (1, 2), heading: (0, -1), action: forward, reward: 0.714277727919
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgrNf&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 11, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.7142777279189535, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgrNf
Agent drove forward instead of left. (rewarded 0.71)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.5
Environment.act() [POST]: location: (1, 2), heading: (0, -1), action: forward, reward: -9.74910062485
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlrN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 12, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.749100624854323, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlrN
Agent attempted driving forward through a red light. (rewarded -9.75)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.5
Environment.act() [POST]: location: (1, 2), heading: (0, -1), action: left, reward: -9.25057095272
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNl&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 13, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -9.250570952724706, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNl
Agent attempted driving left through a red light. (rewarded -9.25)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.5
Environment.act() [POST]: location: (2, 2), heading: (1, 0), action: right, reward: 0.0923560196609
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrllN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 14, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.0923560196609029, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrllN
Agent drove right instead of left. (rewarded 0.09)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.5
Environment.act() [POST]: location: (3, 2), heading: (1, 0), action: forward, reward: 0.00288592594999
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNl&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 15, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.0028859259499909307, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNl
Agent drove forward instead of left. (rewarded 0.00)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.5
Environment.act() [POST]: location: (3, 2), heading: (1, 0), action: None, reward: 2.31722373866
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNfN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 16, &#39;action&#39;: None, &#39;reward&#39;: 2.3172237386639196, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNfN
Agent properly idled at a red light. (rewarded 2.32)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.5
Environment.act() [POST]: location: (3, 2), heading: (1, 0), action: None, reward: 2.28400115162
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNfN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 17, &#39;action&#39;: None, &#39;reward&#39;: 2.2840011516240613, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNfN
Agent properly idled at a red light. (rewarded 2.28)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.5
Environment.act() [POST]: location: (3, 3), heading: (0, 1), action: right, reward: 0.419153702729
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 18, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.41915370272855124, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNN
Agent drove right instead of forward. (rewarded 0.42)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.5
Environment.act() [POST]: location: (3, 3), heading: (0, 1), action: forward, reward: -39.799786967
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNf&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 19, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.79978696696718, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.80)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.5
Environment.act() [POST]: location: (3, 3), heading: (0, 1), action: left, reward: -39.9153931344
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNfl&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 20, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -39.915393134423624, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNfl
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -39.92)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.5
Environment.act() [POST]: location: (4, 3), heading: (1, 0), action: left, reward: 1.8093002836
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNl&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 21, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.8093002835998198, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNl
Agent followed the waypoint left. (rewarded 1.81)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.5
Environment.act() [POST]: location: (4, 3), heading: (1, 0), action: None, reward: 2.05383673789
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNf&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 22, &#39;action&#39;: None, &#39;reward&#39;: 2.053836737891554, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNf
Agent properly idled at a red light. (rewarded 2.05)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0.5
Environment.act() [POST]: location: (4, 3), heading: (1, 0), action: None, reward: 1.3265569736
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNl&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 23, &#39;action&#39;: None, &#39;reward&#39;: 1.3265569736004261, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNl
Agent properly idled at a red light. (rewarded 1.33)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0.5
Environment.act() [POST]: location: (4, 3), heading: (1, 0), action: None, reward: 1.83789319995
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 24, &#39;action&#39;: None, &#39;reward&#39;: 1.8378931999508379, &#39;waypoint&#39;: &#39;forward&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 1.84)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 11
\-------------------------

Environment.reset(): Trial set up with start = (2, 4), destination = (6, 3), deadline = 25
Simulating trial. . . 
epsilon = 0.4500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.45
Environment.act() [POST]: location: (2, 4), heading: (1, 0), action: forward, reward: -39.2444938466
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrrff&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.244493846618695, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrrff
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.24)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.45
Environment.act() [POST]: location: (2, 4), heading: (1, 0), action: None, reward: 1.69272670832
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 1, &#39;action&#39;: None, &#39;reward&#39;: 1.6927267083234905, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.69)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.45
Environment.act() [POST]: location: (2, 4), heading: (1, 0), action: forward, reward: -10.3272243108
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.327224310792507, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent attempted driving forward through a red light. (rewarded -10.33)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.45
Environment.act() [POST]: location: (2, 4), heading: (1, 0), action: None, reward: 2.83435850005
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 2.8343585000493725, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.83)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.45
Environment.act() [POST]: location: (2, 4), heading: (1, 0), action: None, reward: 2.36740321103
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 2.3674032110286114, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.37)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.45
Environment.act() [POST]: location: (2, 4), heading: (1, 0), action: None, reward: 1.65310712703
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNr&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: 1.653107127030659, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNr
Agent properly idled at a red light. (rewarded 1.65)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.45
Environment.act() [POST]: location: (3, 4), heading: (1, 0), action: forward, reward: 0.798168681221
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNrN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.7981686812207237, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNrN
Agent drove forward instead of left. (rewarded 0.80)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.45
Environment.act() [POST]: location: (4, 4), heading: (1, 0), action: forward, reward: 2.06124650813
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNf&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 7, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.061246508127854, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNf
Agent followed the waypoint forward. (rewarded 2.06)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.45
Environment.act() [POST]: location: (4, 4), heading: (1, 0), action: forward, reward: -9.8490251922
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlrr&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 8, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.849025192200873, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlrr
Agent attempted driving forward through a red light. (rewarded -9.85)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.45
Environment.act() [POST]: location: (4, 4), heading: (1, 0), action: forward, reward: -10.3122647206
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.312264720582375, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent attempted driving forward through a red light. (rewarded -10.31)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.45
Environment.act() [POST]: location: (4, 4), heading: (1, 0), action: None, reward: 1.9399019447
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 10, &#39;action&#39;: None, &#39;reward&#39;: 1.939901944701582, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 1.94)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.45
Environment.act() [POST]: location: (5, 4), heading: (1, 0), action: forward, reward: 2.66336217775
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgllN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 11, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.6633621777483603, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgllN
Agent followed the waypoint forward. (rewarded 2.66)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.45
Environment.act() [POST]: location: (6, 4), heading: (1, 0), action: forward, reward: 1.80034008755
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 12, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.8003400875462015, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 1.80)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.45
Environment.act() [POST]: location: (6, 5), heading: (0, 1), action: right, reward: 0.351304615745
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNlN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 13, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.35130461574528704, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNlN
Agent drove right instead of left. (rewarded 0.35)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.45
Environment.act() [POST]: location: (6, 5), heading: (0, 1), action: None, reward: -5.06842400833
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNll&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 14, &#39;action&#39;: None, &#39;reward&#39;: -5.068424008333896, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNll
Agent idled at a green light with no oncoming traffic. (rewarded -5.07)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.45
Environment.act() [POST]: location: (6, 6), heading: (0, 1), action: forward, reward: 0.817123457079
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNll&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 15, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.8171234570793695, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNll
Agent drove forward instead of right. (rewarded 0.82)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.45
Environment.act() [POST]: location: (6, 7), heading: (0, 1), action: forward, reward: 0.756012402661
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 16, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.756012402661443, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 0.76)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.45
Environment.act() [POST]: location: (6, 2), heading: (0, 1), action: forward, reward: 1.29679099728
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 17, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.296790997275677, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 1.30)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.45
Environment.act() [POST]: location: (6, 2), heading: (0, 1), action: forward, reward: -10.7826470489
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNrr&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 18, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.782647048857218, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNrr
Agent attempted driving forward through a red light. (rewarded -10.78)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.45
Environment.act() [POST]: location: (6, 2), heading: (0, 1), action: left, reward: -10.279433571
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 19, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.279433570974927, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlN
Agent attempted driving left through a red light. (rewarded -10.28)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.45
Environment.act() [POST]: location: (6, 2), heading: (0, 1), action: None, reward: 1.35480635146
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 20, &#39;action&#39;: None, &#39;reward&#39;: 1.354806351464347, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.35)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.45
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (6, 3), heading: (0, 1), action: forward, reward: 1.94382692909
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNrN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 21, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.9438269290945973, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNrN
Agent followed the waypoint forward. (rewarded 1.94)
12% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Training trial 12
\-------------------------

Environment.reset(): Trial set up with start = (4, 2), destination = (2, 5), deadline = 25
Simulating trial. . . 
epsilon = 0.4000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.4
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: forward, reward: 0.229679392541
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgrfr&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.22967939254116754, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgrfr
Agent drove forward instead of left. (rewarded 0.23)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.4
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: forward, reward: -39.9391703565
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNfl&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.93917035651612, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNfl
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.94)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.4
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: None, reward: 1.87589482123
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNl&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 2, &#39;action&#39;: None, &#39;reward&#39;: 1.875894821225025, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNl
Agent properly idled at a red light. (rewarded 1.88)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.4
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: forward, reward: -10.012107191
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNrl&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 3, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.012107190984311, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNrl
Agent attempted driving forward through a red light. (rewarded -10.01)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.4
Environment.act() [POST]: location: (4, 6), heading: (0, -1), action: forward, reward: 1.20736851351
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNfr&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 4, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.2073685135084662, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNfr
Agent drove forward instead of left. (rewarded 1.21)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.4
Environment.act() [POST]: location: (3, 6), heading: (-1, 0), action: left, reward: 2.79958081162
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 5, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.799580811620626, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent followed the waypoint left. (rewarded 2.80)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.4
Environment.act() [POST]: location: (3, 6), heading: (-1, 0), action: None, reward: 1.45428395289
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNll&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 6, &#39;action&#39;: None, &#39;reward&#39;: 1.4542839528946636, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNll
Agent properly idled at a red light. (rewarded 1.45)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.4
Environment.act() [POST]: location: (3, 6), heading: (-1, 0), action: None, reward: 2.86940060627
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 7, &#39;action&#39;: None, &#39;reward&#39;: 2.8694006062730404, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.87)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.4
Environment.act() [POST]: location: (3, 5), heading: (0, -1), action: right, reward: 0.667275368266
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.6672753682664233, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent drove right instead of forward. (rewarded 0.67)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.4
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (2, 5), heading: (-1, 0), action: left, reward: 1.85917094716
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 9, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.8591709471648472, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 1.86)
60% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Training trial 13
\-------------------------

Environment.reset(): Trial set up with start = (3, 3), destination = (6, 4), deadline = 20
Simulating trial. . . 
epsilon = 0.3500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.35
Environment.act() [POST]: location: (3, 4), heading: (0, 1), action: right, reward: 0.930306425155
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNf&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.9303064251547806, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNf
Agent drove right instead of forward. (rewarded 0.93)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.35
Environment.act() [POST]: location: (3, 4), heading: (0, 1), action: None, reward: 2.92140533059
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: None, &#39;reward&#39;: 2.9214053305856726, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 2.92)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.35
Environment.act() [POST]: location: (3, 4), heading: (0, 1), action: forward, reward: -40.9796784072
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlfN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.97967840722368, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlfN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.98)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.35
Environment.act() [POST]: location: (3, 4), heading: (0, 1), action: None, reward: 2.95286849892
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 2.9528684989153273, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 2.95)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.35
Environment.act() [POST]: location: (3, 4), heading: (0, 1), action: None, reward: 1.69015396895
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 1.6901539689457288, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.69)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.35
Environment.act() [POST]: location: (2, 4), heading: (-1, 0), action: right, reward: 1.32382273659
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNf&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.3238227365925437, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNf
Agent drove right instead of left. (rewarded 1.32)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.35
Environment.act() [POST]: location: (2, 4), heading: (-1, 0), action: forward, reward: -40.1105507211
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNfl&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.11055072107812, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNfl
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.11)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.35
Environment.act() [POST]: location: (2, 4), heading: (-1, 0), action: None, reward: 2.00430951098
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNl&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: None, &#39;reward&#39;: 2.004309510984332, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNl
Agent properly idled at a red light. (rewarded 2.00)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.35
Environment.act() [POST]: location: (2, 3), heading: (0, -1), action: right, reward: 1.09525616843
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNr&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.0952561684289979, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNr
Agent drove right instead of forward. (rewarded 1.10)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.35
Environment.act() [POST]: location: (2, 3), heading: (0, -1), action: None, reward: 1.0902650714
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: None, &#39;reward&#39;: 1.0902650714008206, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.09)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.35
Environment.act() [POST]: location: (3, 3), heading: (1, 0), action: right, reward: -0.140909542352
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNlN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.14090954235249586, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNlN
Agent drove right instead of left. (rewarded -0.14)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.35
Environment.act() [POST]: location: (4, 3), heading: (1, 0), action: forward, reward: 1.51869223539
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgrlr&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.5186922353909265, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgrlr
Agent followed the waypoint forward. (rewarded 1.52)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.35
Environment.act() [POST]: location: (4, 4), heading: (0, 1), action: right, reward: 1.40501360005
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.4050136000497386, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNN
Agent drove right instead of forward. (rewarded 1.41)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.35
Environment.act() [POST]: location: (4, 5), heading: (0, 1), action: forward, reward: -0.131768381371
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNl&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -0.1317683813708025, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNl
Agent drove forward instead of left. (rewarded -0.13)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.35
Environment.act() [POST]: location: (4, 5), heading: (0, 1), action: forward, reward: -10.2705352257
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 14, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.270535225687036, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent attempted driving forward through a red light. (rewarded -10.27)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.35
Environment.act() [POST]: location: (4, 5), heading: (0, 1), action: None, reward: 1.15691978664
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 15, &#39;action&#39;: None, &#39;reward&#39;: 1.1569197866432863, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.16)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.35
Environment.act() [POST]: location: (4, 5), heading: (0, 1), action: None, reward: -4.06411939118
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNrN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 16, &#39;action&#39;: None, &#39;reward&#39;: -4.064119391176952, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNrN
Agent idled at a green light with no oncoming traffic. (rewarded -4.06)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.35
Environment.act() [POST]: location: (3, 5), heading: (-1, 0), action: right, reward: -0.0251551136277
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNr&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 17, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.02515511362768763, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNr
Agent drove right instead of left. (rewarded -0.03)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.35
Environment.act() [POST]: location: (3, 5), heading: (-1, 0), action: forward, reward: -9.95349686089
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNrN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 18, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.953496860891269, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNrN
Agent attempted driving forward through a red light. (rewarded -9.95)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.35
Environment.act() [POST]: location: (3, 4), heading: (0, -1), action: right, reward: 2.07276103545
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 19, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.0727610354511317, &#39;waypoint&#39;: &#39;right&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 2.07)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 14
\-------------------------

Environment.reset(): Trial set up with start = (8, 7), destination = (3, 2), deadline = 20
Simulating trial. . . 
epsilon = 0.3000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.3
Environment.act() [POST]: location: (8, 2), heading: (0, 1), action: forward, reward: 0.301827574386
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfrr&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.3018275743864578, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfrr
Agent drove forward instead of left. (rewarded 0.30)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.3
Environment.act() [POST]: location: (8, 3), heading: (0, 1), action: forward, reward: 1.92550235386
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNll&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.9255023538588065, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNll
Agent drove forward instead of left. (rewarded 1.93)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.3
Environment.act() [POST]: location: (8, 3), heading: (0, 1), action: None, reward: 2.90456511838
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: None, &#39;reward&#39;: 2.904565118376926, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.90)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.3
Environment.act() [POST]: location: (8, 3), heading: (0, 1), action: None, reward: 0.974385929902
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 0.9743859299017334, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 0.97)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.3
Environment.act() [POST]: location: (7, 3), heading: (-1, 0), action: right, reward: 1.00723757029
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.0072375702877268, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNN
Agent drove right instead of left. (rewarded 1.01)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.3
Environment.act() [POST]: location: (7, 3), heading: (-1, 0), action: forward, reward: -9.13282468303
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNl&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.132824683030321, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNl
Agent attempted driving forward through a red light. (rewarded -9.13)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.3
Environment.act() [POST]: location: (7, 3), heading: (-1, 0), action: None, reward: 1.2356005332
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: None, &#39;reward&#39;: 1.2356005331978317, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 1.24)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.3
Environment.act() [POST]: location: (6, 3), heading: (-1, 0), action: forward, reward: 0.687648639739
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.6876486397390664, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent drove forward instead of right. (rewarded 0.69)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.3
Environment.act() [POST]: location: (5, 3), heading: (-1, 0), action: forward, reward: 1.04124988686
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNrf&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.0412498868610007, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNrf
Agent followed the waypoint forward. (rewarded 1.04)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.3
Environment.act() [POST]: location: (5, 3), heading: (-1, 0), action: None, reward: 1.20537964434
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: None, &#39;reward&#39;: 1.205379644344849, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.21)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.3
Environment.act() [POST]: location: (4, 3), heading: (-1, 0), action: forward, reward: 2.10088602647
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.1008860264732974, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 2.10)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.3
Environment.act() [POST]: location: (4, 3), heading: (-1, 0), action: right, reward: -20.2644662694
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 3, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlfN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -20.264466269351853, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlfN
Agent attempted driving right through traffic and cause a minor accident. (rewarded -20.26)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.3
Environment.act() [POST]: location: (4, 3), heading: (-1, 0), action: None, reward: 1.00010078941
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: None, &#39;reward&#39;: 1.0001007894139744, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 1.00)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.3
Environment.act() [POST]: location: (3, 3), heading: (-1, 0), action: forward, reward: 1.63430702314
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNr&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.6343070231416295, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNr
Agent followed the waypoint forward. (rewarded 1.63)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.3
Environment.act() [POST]: location: (2, 3), heading: (-1, 0), action: forward, reward: 0.88455402463
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgflN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 14, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.8845540246302132, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgflN
Agent drove forward instead of right. (rewarded 0.88)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.3
Environment.act() [POST]: location: (2, 3), heading: (-1, 0), action: None, reward: 1.748693722
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 15, &#39;action&#39;: None, &#39;reward&#39;: 1.7486937219992487, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 1.75)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.3
Environment.act() [POST]: location: (2, 3), heading: (-1, 0), action: None, reward: 0.760965586519
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 16, &#39;action&#39;: None, &#39;reward&#39;: 0.7609655865190377, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 0.76)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.3
Environment.act() [POST]: location: (2, 3), heading: (-1, 0), action: None, reward: 0.330651494836
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNf&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 17, &#39;action&#39;: None, &#39;reward&#39;: 0.33065149483595613, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNf
Agent idled at a green light with oncoming traffic. (rewarded 0.33)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.3
Environment.act() [POST]: location: (2, 2), heading: (0, -1), action: right, reward: 2.00289277814
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNf&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 18, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.0028927781449157, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNf
Agent followed the waypoint right. (rewarded 2.00)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.3
Environment.act() [POST]: location: (2, 7), heading: (0, -1), action: forward, reward: 0.138135009951
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 19, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.1381350099514097, &#39;waypoint&#39;: &#39;right&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: rgNNN
Agent drove forward instead of right. (rewarded 0.14)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 15
\-------------------------

Environment.reset(): Trial set up with start = (5, 6), destination = (7, 3), deadline = 25
Simulating trial. . . 
epsilon = 0.2500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.25
Environment.act() [POST]: location: (4, 6), heading: (-1, 0), action: left, reward: 1.05997128058
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNfN&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 0, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.059971280580441, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNfN
Agent drove left instead of right. (rewarded 1.06)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.25
Environment.act() [POST]: location: (4, 6), heading: (-1, 0), action: None, reward: 2.13338745964
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 1, &#39;action&#39;: None, &#39;reward&#39;: 2.133387459637377, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.13)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.25
Environment.act() [POST]: location: (4, 5), heading: (0, -1), action: right, reward: 1.86910074705
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNf&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 2, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.8691007470484993, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNf
Agent drove right instead of left. (rewarded 1.87)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.25
Environment.act() [POST]: location: (4, 5), heading: (0, -1), action: None, reward: 2.56494286903
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 2.564942869031783, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 2.56)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.25
Environment.act() [POST]: location: (4, 5), heading: (0, -1), action: forward, reward: -9.19033210434
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrllN&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 4, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.190332104339149, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrllN
Agent attempted driving forward through a red light. (rewarded -9.19)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.25
Environment.act() [POST]: location: (4, 5), heading: (0, -1), action: None, reward: 2.03044477422
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: 2.0304447742223317, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 2.03)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.25
Environment.act() [POST]: location: (4, 4), heading: (0, -1), action: forward, reward: 0.517402409171
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.5174024091705453, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent drove forward instead of right. (rewarded 0.52)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.25
Environment.act() [POST]: location: (4, 4), heading: (0, -1), action: forward, reward: -39.6759159988
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNfl&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 7, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.67591599884978, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNfl
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.68)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.25
Environment.act() [POST]: location: (5, 4), heading: (1, 0), action: right, reward: 1.79742532125
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNl&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.79742532125172, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNl
Agent followed the waypoint right. (rewarded 1.80)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.25
Environment.act() [POST]: location: (5, 4), heading: (1, 0), action: forward, reward: -40.41435533
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNrf&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.41435532997027, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNrf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.41)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.25
Environment.act() [POST]: location: (6, 4), heading: (1, 0), action: forward, reward: 1.63159587673
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglfl&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 10, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.6315958767285683, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglfl
Agent followed the waypoint forward. (rewarded 1.63)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.25
Environment.act() [POST]: location: (6, 5), heading: (0, 1), action: right, reward: 0.534176485871
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 11, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.5341764858705546, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNN
Agent drove right instead of forward. (rewarded 0.53)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.25
Environment.act() [POST]: location: (6, 5), heading: (0, 1), action: forward, reward: -10.8146691045
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 12, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.814669104548994, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent attempted driving forward through a red light. (rewarded -10.81)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.25
Environment.act() [POST]: location: (7, 5), heading: (1, 0), action: left, reward: 2.2689726784
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 13, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.2689726783993462, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 2.27)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.25
Environment.act() [POST]: location: (7, 5), heading: (1, 0), action: forward, reward: -10.9961780492
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 14, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.996178049160383, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNN
Agent attempted driving forward through a red light. (rewarded -11.00)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.25
Environment.act() [POST]: location: (7, 6), heading: (0, 1), action: right, reward: 1.06506956906
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 15, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.065069569057812, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNN
Agent drove right instead of left. (rewarded 1.07)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.25
Environment.act() [POST]: location: (7, 6), heading: (0, 1), action: None, reward: 2.16168746631
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNfl&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 16, &#39;action&#39;: None, &#39;reward&#39;: 2.1616874663133205, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNfl
Agent properly idled at a red light. (rewarded 2.16)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.25
Environment.act() [POST]: location: (7, 7), heading: (0, 1), action: forward, reward: 0.735029518078
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNr&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 17, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.7350295180780866, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNr
Agent followed the waypoint forward. (rewarded 0.74)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.25
Environment.act() [POST]: location: (7, 7), heading: (0, 1), action: forward, reward: -10.7545056217
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlr&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 18, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.754505621727931, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlr
Agent attempted driving forward through a red light. (rewarded -10.75)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.25
Environment.act() [POST]: location: (7, 7), heading: (0, 1), action: forward, reward: -10.2203362079
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 19, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.220336207881012, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlN
Agent attempted driving forward through a red light. (rewarded -10.22)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.25
Environment.act() [POST]: location: (7, 7), heading: (0, 1), action: None, reward: 1.77460932143
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 20, &#39;action&#39;: None, &#39;reward&#39;: 1.7746093214291316, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.77)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.25
Environment.act() [POST]: location: (7, 2), heading: (0, 1), action: forward, reward: 0.687497024304
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNlN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 21, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.6874970243040639, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNlN
Agent followed the waypoint forward. (rewarded 0.69)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.25
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (7, 3), heading: (0, 1), action: forward, reward: 0.8821246516
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglrl&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 22, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.8821246515999694, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglrl
Agent followed the waypoint forward. (rewarded 0.88)
8% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Training trial 16
\-------------------------

Environment.reset(): Trial set up with start = (6, 5), destination = (1, 6), deadline = 20
Simulating trial. . . 
epsilon = 0.2000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.2
Environment.act() [POST]: location: (6, 5), heading: (0, 1), action: forward, reward: -40.4526408508
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNf&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.45264085084381, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.45)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.2
Environment.act() [POST]: location: (6, 5), heading: (0, 1), action: left, reward: -10.2437702458
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.243770245826921, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent attempted driving left through a red light. (rewarded -10.24)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.2
Environment.act() [POST]: location: (6, 5), heading: (0, 1), action: left, reward: -9.59639320062
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -9.596393200619358, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent attempted driving left through a red light. (rewarded -9.60)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.2
Environment.act() [POST]: location: (6, 5), heading: (0, 1), action: None, reward: 1.66022659666
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 1.660226596658727, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.66)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.2
Environment.act() [POST]: location: (7, 5), heading: (1, 0), action: left, reward: 1.4499369068
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.4499369067975025, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 1.45)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.2
Environment.act() [POST]: location: (7, 5), heading: (1, 0), action: None, reward: 2.24012945661
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: 2.2401294566061605, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 2.24)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.2
Environment.act() [POST]: location: (8, 5), heading: (1, 0), action: forward, reward: 2.78033901694
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNl&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.7803390169381443, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNl
Agent followed the waypoint forward. (rewarded 2.78)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.2
Environment.act() [POST]: location: (1, 5), heading: (1, 0), action: forward, reward: 0.919923202033
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.9199232020326717, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 0.92)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.2
Environment.act() [POST]: location: (1, 5), heading: (1, 0), action: forward, reward: -10.6566391239
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNr&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.656639123870123, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNr
Agent attempted driving forward through a red light. (rewarded -10.66)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.2
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (1, 6), heading: (0, 1), action: right, reward: 2.09597876031
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNl&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.095978760313878, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNl
Agent followed the waypoint right. (rewarded 2.10)
50% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Training trial 17
\-------------------------

Environment.reset(): Trial set up with start = (2, 3), destination = (5, 5), deadline = 25
Simulating trial. . . 
epsilon = 0.1500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.15
Environment.act() [POST]: location: (2, 4), heading: (0, 1), action: forward, reward: 1.23931657664
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNlN&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.2393165766398628, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNlN
Agent drove forward instead of left. (rewarded 1.24)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.15
Environment.act() [POST]: location: (3, 4), heading: (1, 0), action: left, reward: 1.17043931144
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNf&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 1, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.1704393114387093, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNf
Agent followed the waypoint left. (rewarded 1.17)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.15
Environment.act() [POST]: location: (3, 4), heading: (1, 0), action: None, reward: 1.97998032183
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 2, &#39;action&#39;: None, &#39;reward&#39;: 1.979980321828317, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.98)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.15
Environment.act() [POST]: location: (3, 4), heading: (1, 0), action: None, reward: 1.37244050686
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNl&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 1.3724405068563483, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNl
Agent properly idled at a red light. (rewarded 1.37)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.15
Environment.act() [POST]: location: (3, 4), heading: (1, 0), action: None, reward: 2.48534299189
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNll&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 2.4853429918935657, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNll
Agent properly idled at a red light. (rewarded 2.49)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.15
Environment.act() [POST]: location: (3, 4), heading: (1, 0), action: forward, reward: -9.76663471581
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frflr&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 5, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.766634715809891, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frflr
Agent attempted driving forward through a red light. (rewarded -9.77)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.15
Environment.act() [POST]: location: (4, 4), heading: (1, 0), action: forward, reward: 2.59668298305
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfrN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.596682983050111, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfrN
Agent followed the waypoint forward. (rewarded 2.60)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.15
Environment.act() [POST]: location: (4, 5), heading: (0, 1), action: right, reward: 0.389993870574
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlr&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 7, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.38999387057421364, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlr
Agent drove right instead of forward. (rewarded 0.39)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.15
Environment.act() [POST]: location: (4, 5), heading: (0, 1), action: None, reward: 2.51263792671
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNfN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 8, &#39;action&#39;: None, &#39;reward&#39;: 2.5126379267122636, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNfN
Agent properly idled at a red light. (rewarded 2.51)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.15
Environment.act() [POST]: location: (4, 5), heading: (0, 1), action: forward, reward: -9.1106428412
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrrNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.110642841204932, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrrNN
Agent attempted driving forward through a red light. (rewarded -9.11)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.15
Environment.act() [POST]: location: (3, 5), heading: (-1, 0), action: right, reward: 0.132286469748
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNrN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 10, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.1322864697477163, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNrN
Agent drove right instead of left. (rewarded 0.13)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.15
Environment.act() [POST]: location: (3, 5), heading: (-1, 0), action: None, reward: 2.29051045335
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 11, &#39;action&#39;: None, &#39;reward&#39;: 2.290510453351503, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 2.29)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.15
Environment.act() [POST]: location: (3, 4), heading: (0, -1), action: right, reward: 2.21610648135
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNf&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 12, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.2161064813476723, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNf
Agent followed the waypoint right. (rewarded 2.22)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.15
Environment.act() [POST]: location: (4, 4), heading: (1, 0), action: right, reward: 2.023065875
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 13, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.0230658749975796, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 2.02)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.15
Environment.act() [POST]: location: (5, 4), heading: (1, 0), action: forward, reward: 2.25631793874
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfff&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 14, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.256317938740713, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfff
Agent followed the waypoint forward. (rewarded 2.26)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.15
Environment.act() [POST]: location: (5, 4), heading: (1, 0), action: None, reward: 1.34377764582
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 15, &#39;action&#39;: None, &#39;reward&#39;: 1.3437776458211845, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 1.34)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.15
Environment.act() [POST]: location: (5, 3), heading: (0, -1), action: left, reward: 1.35435498153
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 16, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.3543549815316807, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent drove left instead of right. (rewarded 1.35)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.15
Environment.act() [POST]: location: (6, 3), heading: (1, 0), action: right, reward: 0.86264563767
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNf&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 17, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.8626456376704397, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNf
Agent followed the waypoint right. (rewarded 0.86)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.15
Environment.act() [POST]: location: (6, 4), heading: (0, 1), action: right, reward: 2.15802094019
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 18, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.158020940186293, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 2.16)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.15
Environment.act() [POST]: location: (6, 4), heading: (0, 1), action: None, reward: 1.60079761618
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 19, &#39;action&#39;: None, &#39;reward&#39;: 1.6007976161760853, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 1.60)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.15
Environment.act() [POST]: location: (6, 4), heading: (0, 1), action: None, reward: 1.35087057089
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 20, &#39;action&#39;: None, &#39;reward&#39;: 1.350870570894937, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 1.35)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.15
Environment.act() [POST]: location: (6, 4), heading: (0, 1), action: None, reward: 0.459633213064
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNf&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 21, &#39;action&#39;: None, &#39;reward&#39;: 0.4596332130636075, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNf
Agent idled at a green light with oncoming traffic. (rewarded 0.46)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.15
Environment.act() [POST]: location: (5, 4), heading: (-1, 0), action: right, reward: 1.49948693912
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNf&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 22, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.4994869391176142, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNf
Agent followed the waypoint right. (rewarded 1.50)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0.15
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (5, 5), heading: (0, 1), action: left, reward: 1.34685465771
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNfl&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 23, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.3468546577108622, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNfl
Agent followed the waypoint left. (rewarded 1.35)
4% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Training trial 18
\-------------------------

Environment.reset(): Trial set up with start = (7, 5), destination = (2, 4), deadline = 20
Simulating trial. . . 
epsilon = 0.1000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.1
Environment.act() [POST]: location: (8, 5), heading: (1, 0), action: forward, reward: 2.97167329592
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgrrl&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.9716732959203354, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgrrl
Agent followed the waypoint forward. (rewarded 2.97)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.1
Environment.act() [POST]: location: (1, 5), heading: (1, 0), action: forward, reward: 1.23831452557
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglfr&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.2383145255739603, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglfr
Agent followed the waypoint forward. (rewarded 1.24)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.1
Environment.act() [POST]: location: (1, 5), heading: (1, 0), action: None, reward: 2.74692883945
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: None, &#39;reward&#39;: 2.74692883944876, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 2.75)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.1
Environment.act() [POST]: location: (1, 5), heading: (1, 0), action: None, reward: 1.50801254547
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 1.5080125454708397, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 1.51)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.1
Environment.act() [POST]: location: (1, 6), heading: (0, 1), action: right, reward: 1.68116873035
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNr&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.68116873035056, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNr
Agent drove right instead of forward. (rewarded 1.68)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.1
Environment.act() [POST]: location: (1, 7), heading: (0, 1), action: forward, reward: 0.635057636699
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglff&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.6350576366985254, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglff
Agent drove forward instead of left. (rewarded 0.64)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.1
Environment.act() [POST]: location: (1, 7), heading: (0, 1), action: None, reward: 1.36713592163
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: None, &#39;reward&#39;: 1.3671359216310803, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.37)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.1
Environment.act() [POST]: location: (8, 7), heading: (-1, 0), action: right, reward: -0.0941510497323
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.09415104973231192, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNN
Agent drove right instead of left. (rewarded -0.09)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.1
Environment.act() [POST]: location: (7, 7), heading: (-1, 0), action: forward, reward: 0.561875247738
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgrfN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.5618752477378323, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgrfN
Agent drove forward instead of left. (rewarded 0.56)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.1
Environment.act() [POST]: location: (7, 7), heading: (-1, 0), action: None, reward: 1.84658307782
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: None, &#39;reward&#39;: 1.8465830778155636, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.85)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.1
Environment.act() [POST]: location: (7, 7), heading: (-1, 0), action: None, reward: 1.67307526649
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: None, &#39;reward&#39;: 1.673075266491595, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.67)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.1
Environment.act() [POST]: location: (6, 7), heading: (-1, 0), action: forward, reward: 1.50365295726
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgllN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.503652957259452, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgllN
Agent drove forward instead of left. (rewarded 1.50)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.1
Environment.act() [POST]: location: (6, 2), heading: (0, 1), action: left, reward: 2.39450174455
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.394501744546367, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 2.39)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.1
Environment.act() [POST]: location: (6, 3), heading: (0, 1), action: forward, reward: -0.143581151592
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgrNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -0.1435811515917923, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgrNN
Agent drove forward instead of left. (rewarded -0.14)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.1
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: left, reward: 2.40270764083
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNff&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 14, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.402707640828506, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNff
Agent followed the waypoint left. (rewarded 2.40)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.1
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: None, reward: 2.11288388493
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNfN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 15, &#39;action&#39;: None, &#39;reward&#39;: 2.1128838849279807, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNfN
Agent properly idled at a red light. (rewarded 2.11)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.1
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: left, reward: -10.7962403416
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 16, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.796240341618583, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent attempted driving left through a red light. (rewarded -10.80)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.1
Environment.act() [POST]: location: (8, 3), heading: (1, 0), action: forward, reward: 0.994110780181
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 17, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.9941107801806937, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 0.99)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.1
Environment.act() [POST]: location: (1, 3), heading: (1, 0), action: forward, reward: 1.10107235917
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglff&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 18, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.1010723591708917, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglff
Agent followed the waypoint forward. (rewarded 1.10)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.1
Environment.act() [POST]: location: (1, 4), heading: (0, 1), action: right, reward: 0.997711234095
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNf&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 19, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.9977112340949724, &#39;waypoint&#39;: &#39;forward&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: fgNNf
Agent drove right instead of forward. (rewarded 1.00)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 19
\-------------------------

Environment.reset(): Trial set up with start = (1, 7), destination = (2, 4), deadline = 20
Simulating trial. . . 
epsilon = 0.0500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.05
Environment.act() [POST]: location: (1, 6), heading: (0, -1), action: forward, reward: 0.873716042757
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglrl&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.8737160427572368, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglrl
Agent drove forward instead of right. (rewarded 0.87)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.05
Environment.act() [POST]: location: (1, 6), heading: (0, -1), action: None, reward: 1.8870626952
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: None, &#39;reward&#39;: 1.8870626951974345, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 1.89)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.05
Environment.act() [POST]: location: (1, 6), heading: (0, -1), action: None, reward: 1.18018504178
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: None, &#39;reward&#39;: 1.1801850417828048, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 1.18)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.05
Environment.act() [POST]: location: (2, 6), heading: (1, 0), action: right, reward: 1.87994658058
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.8799465805782303, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 1.88)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.05
Environment.act() [POST]: location: (2, 5), heading: (0, -1), action: left, reward: 2.0751869863
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.075186986300232, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent followed the waypoint left. (rewarded 2.08)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.05
Environment.act() [POST]: location: (2, 5), heading: (0, -1), action: None, reward: 1.35855944957
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: 1.3585594495741269, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.36)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.05
Environment.act() [POST]: location: (2, 5), heading: (0, -1), action: None, reward: 2.77010097056
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: None, &#39;reward&#39;: 2.77010097055741, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.77)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.05
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (2, 4), heading: (0, -1), action: forward, reward: 2.40158817389
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.4015881738881304, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 2.40)
60% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Training trial 20
\-------------------------

Environment.reset(): Trial set up with start = (5, 3), destination = (7, 5), deadline = 20
Simulating trial. . . 
epsilon = -0.0000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
-3.1918911958e-16
Environment.act() [POST]: location: (4, 3), heading: (-1, 0), action: forward, reward: 1.24083539441
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglll&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.2408353944077672, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglll
Agent drove forward instead of left. (rewarded 1.24)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
-3.1918911958e-16
Environment.act() [POST]: location: (4, 3), heading: (-1, 0), action: forward, reward: -10.829027424
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfrN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.829027424002156, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfrN
Agent attempted driving forward through a red light. (rewarded -10.83)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
-3.1918911958e-16
Environment.act() [POST]: location: (4, 2), heading: (0, -1), action: right, reward: 1.43357822735
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.4335782273492002, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNN
Agent drove right instead of left. (rewarded 1.43)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
-3.1918911958e-16
Environment.act() [POST]: location: (5, 2), heading: (1, 0), action: right, reward: 1.61561260515
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNrN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.6156126051503341, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNrN
Agent followed the waypoint right. (rewarded 1.62)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
-3.1918911958e-16
Environment.act() [POST]: location: (6, 2), heading: (1, 0), action: forward, reward: 1.55340698043
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNl&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.5534069804320314, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNl
Agent followed the waypoint forward. (rewarded 1.55)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
-3.1918911958e-16
Environment.act() [POST]: location: (6, 2), heading: (1, 0), action: None, reward: 2.86575235122
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: 2.8657523512242316, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 2.87)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
-3.1918911958e-16
Environment.act() [POST]: location: (7, 2), heading: (1, 0), action: forward, reward: 0.955902109944
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.9559021099444398, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 0.96)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
-3.1918911958e-16
Environment.act() [POST]: location: (7, 2), heading: (1, 0), action: None, reward: 1.2738291143
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: None, &#39;reward&#39;: 1.2738291143025688, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.27)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
-3.1918911958e-16
Environment.act() [POST]: location: (7, 2), heading: (1, 0), action: None, reward: 1.42142356839
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: None, &#39;reward&#39;: 1.421423568386783, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.42)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
-3.1918911958e-16
Environment.act() [POST]: location: (7, 2), heading: (1, 0), action: None, reward: 1.17530916577
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: None, &#39;reward&#39;: 1.1753091657709753, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.18)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
-3.1918911958e-16
Environment.act() [POST]: location: (7, 2), heading: (1, 0), action: None, reward: 0.819833495521
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: None, &#39;reward&#39;: 0.8198334955211517, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 0.82)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
-3.1918911958e-16
Environment.act() [POST]: location: (7, 7), heading: (0, -1), action: left, reward: 2.68196506577
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.6819650657650143, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent followed the waypoint left. (rewarded 2.68)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
-3.1918911958e-16
Environment.act() [POST]: location: (7, 7), heading: (0, -1), action: None, reward: 1.37154167759
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frllN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: None, &#39;reward&#39;: 1.3715416775901617, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frllN
Agent properly idled at a red light. (rewarded 1.37)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
-3.1918911958e-16
Environment.act() [POST]: location: (7, 7), heading: (0, -1), action: forward, reward: -40.6458793619
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlfN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.64587936185812, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlfN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.65)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
-3.1918911958e-16
Environment.act() [POST]: location: (8, 7), heading: (1, 0), action: right, reward: -0.35297102317
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNl&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 14, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.3529710231703119, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNl
Agent drove right instead of forward. (rewarded -0.35)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
-3.1918911958e-16
Environment.act() [POST]: location: (8, 6), heading: (0, -1), action: left, reward: 1.38180010778
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 15, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.3818001077831235, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 1.38)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
-3.1918911958e-16
Environment.act() [POST]: location: (7, 6), heading: (-1, 0), action: left, reward: 1.38741117323
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 16, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.3874111732337486, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 1.39)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
-3.1918911958e-16
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (7, 5), heading: (0, -1), action: right, reward: 0.731941635944
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 17, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.7319416359440352, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfNN
Agent followed the waypoint right. (rewarded 0.73)
10% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Testing trial 1
\-------------------------

Environment.reset(): Trial set up with start = (1, 6), destination = (6, 4), deadline = 25
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (8, 6), heading: (-1, 0), action: left, reward: 1.05359022846
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 0, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.0535902284565561, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 1.05)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (7, 6), heading: (-1, 0), action: forward, reward: 1.15002955317
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNfN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.15002955317052, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNfN
Agent followed the waypoint forward. (rewarded 1.15)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (7, 6), heading: (-1, 0), action: None, reward: 1.12450512047
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 2, &#39;action&#39;: None, &#39;reward&#39;: 1.124505120468035, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.12)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (6, 6), heading: (-1, 0), action: forward, reward: 1.94038859099
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 3, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.9403885909876395, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 1.94)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act() [POST]: location: (6, 6), heading: (-1, 0), action: None, reward: 2.50854742275
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 2.5085474227501168, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 2.51)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0
Environment.act() [POST]: location: (6, 6), heading: (-1, 0), action: None, reward: 1.17356452202
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: 1.1735645220224564, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 1.17)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0
Environment.act() [POST]: location: (5, 6), heading: (-1, 0), action: forward, reward: -0.0819647990981
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -0.08196479909807464, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent drove forward instead of right. (rewarded -0.08)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0
Environment.act() [POST]: location: (4, 6), heading: (-1, 0), action: forward, reward: 0.986732800125
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglfN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 7, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.9867328001251545, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglfN
Agent drove forward instead of right. (rewarded 0.99)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0
Environment.act() [POST]: location: (4, 5), heading: (0, -1), action: right, reward: 2.46919294638
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrllN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.469192946380331, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrllN
Agent followed the waypoint right. (rewarded 2.47)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0
Environment.act() [POST]: location: (5, 5), heading: (1, 0), action: right, reward: 2.15200221427
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 9, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.1520022142675517, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 2.15)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0
Environment.act() [POST]: location: (5, 5), heading: (1, 0), action: None, reward: 1.51054033756
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNl&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 10, &#39;action&#39;: None, &#39;reward&#39;: 1.5105403375605928, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNl
Agent properly idled at a red light. (rewarded 1.51)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0
Environment.act() [POST]: location: (6, 5), heading: (1, 0), action: forward, reward: 1.54853375535
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNfN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 11, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.5485337553494958, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNfN
Agent followed the waypoint forward. (rewarded 1.55)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (6, 4), heading: (0, -1), action: left, reward: 2.46570360025
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNff&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 12, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.465703600253626, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNff
Agent followed the waypoint left. (rewarded 2.47)
48% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Testing trial 2
\-------------------------

Environment.reset(): Trial set up with start = (3, 4), destination = (7, 4), deadline = 20
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (3, 4), heading: (0, -1), action: forward, reward: -9.01645250665
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfrl&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.016452506653161, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfrl
Agent attempted driving forward through a red light. (rewarded -9.02)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (3, 4), heading: (0, -1), action: forward, reward: -40.6679146829
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrffl&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.66791468292839, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrffl
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.67)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (3, 4), heading: (0, -1), action: forward, reward: -39.5538205296
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNf&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.55382052964884, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.55)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (4, 4), heading: (1, 0), action: right, reward: 1.78950333125
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.78950333124949, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNN
Agent drove right instead of left. (rewarded 1.79)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act() [POST]: location: (4, 4), heading: (1, 0), action: None, reward: 2.20557036232
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 2.2055703623183653, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 2.21)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0
Environment.act() [POST]: location: (4, 4), heading: (1, 0), action: None, reward: 1.75903276127
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: 1.75903276126789, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 1.76)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0
Environment.act() [POST]: location: (5, 4), heading: (1, 0), action: forward, reward: 2.51535911122
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.5153591112234666, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 2.52)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0
Environment.act() [POST]: location: (5, 4), heading: (1, 0), action: None, reward: 2.53574190074
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNl&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: None, &#39;reward&#39;: 2.535741900735373, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNl
Agent properly idled at a red light. (rewarded 2.54)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0
Environment.act() [POST]: location: (5, 5), heading: (0, 1), action: right, reward: 0.818381095178
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.8183810951775418, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlN
Agent drove right instead of forward. (rewarded 0.82)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0
Environment.act() [POST]: location: (6, 5), heading: (1, 0), action: left, reward: 2.49234366862
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNl&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.4923436686206983, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNl
Agent followed the waypoint left. (rewarded 2.49)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0
Environment.act() [POST]: location: (7, 5), heading: (1, 0), action: forward, reward: 0.933388246873
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglrN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.9333882468727142, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglrN
Agent followed the waypoint forward. (rewarded 0.93)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0
Environment.act() [POST]: location: (7, 5), heading: (1, 0), action: right, reward: -20.4777754717
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 3, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNfl&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -20.477775471735224, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNfl
Agent attempted driving right through traffic and cause a minor accident. (rewarded -20.48)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0
Environment.act() [POST]: location: (7, 5), heading: (1, 0), action: None, reward: 2.11123056088
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: None, &#39;reward&#39;: 2.111230560877128, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.11)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0
Environment.act() [POST]: location: (7, 5), heading: (1, 0), action: None, reward: 2.45735553725
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: None, &#39;reward&#39;: 2.4573555372496427, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.46)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0
Environment.act() [POST]: location: (7, 5), heading: (1, 0), action: forward, reward: -39.647427253
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNfr&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 14, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.64742725301444, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNfr
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.65)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0
Environment.act() [POST]: location: (7, 6), heading: (0, 1), action: right, reward: -0.196764089397
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrflN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 15, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.19676408939737944, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrflN
Agent drove right instead of left. (rewarded -0.20)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0
Environment.act() [POST]: location: (7, 6), heading: (0, 1), action: None, reward: 1.23164652055
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 16, &#39;action&#39;: None, &#39;reward&#39;: 1.2316465205469065, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 1.23)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0
Environment.act() [POST]: location: (7, 7), heading: (0, 1), action: forward, reward: 0.183854836254
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgfrr&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 17, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.18385483625420995, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgfrr
Agent drove forward instead of right. (rewarded 0.18)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0
Environment.act() [POST]: location: (7, 7), heading: (0, 1), action: forward, reward: -10.2070010103
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNr&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 18, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.207001010271581, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNr
Agent attempted driving forward through a red light. (rewarded -10.21)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0
Environment.act() [POST]: location: (6, 7), heading: (-1, 0), action: right, reward: 0.231690903202
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 19, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.23169090320215113, &#39;waypoint&#39;: &#39;forward&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: frfNN
Agent drove right instead of forward. (rewarded 0.23)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Testing trial 3
\-------------------------

Environment.reset(): Trial set up with start = (3, 6), destination = (7, 4), deadline = 30
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (2, 6), heading: (-1, 0), action: forward, reward: 1.75557278558
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNrl&#39;, &#39;deadline&#39;: 30, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.755572785575277, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNrl
Agent followed the waypoint forward. (rewarded 1.76)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (1, 6), heading: (-1, 0), action: forward, reward: 1.05533651198
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNll&#39;, &#39;deadline&#39;: 29, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.0553365119848162, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNll
Agent followed the waypoint forward. (rewarded 1.06)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (8, 6), heading: (-1, 0), action: forward, reward: 2.67984694333
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNlN&#39;, &#39;deadline&#39;: 28, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.679846943326945, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNlN
Agent followed the waypoint forward. (rewarded 2.68)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (7, 6), heading: (-1, 0), action: forward, reward: 1.10011064915
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfNN&#39;, &#39;deadline&#39;: 27, &#39;t&#39;: 3, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.1001106491473907, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfNN
Agent followed the waypoint forward. (rewarded 1.10)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act() [POST]: location: (7, 6), heading: (-1, 0), action: None, reward: 2.81070604074
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 26, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 2.810706040742569, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 2.81)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0
Environment.act() [POST]: location: (7, 5), heading: (0, -1), action: right, reward: 1.37295150155
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 5, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.3729515015503493, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 1.37)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (7, 4), heading: (0, -1), action: forward, reward: 2.49157828692
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglfN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.491578286919997, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglfN
Agent followed the waypoint forward. (rewarded 2.49)
77% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Testing trial 4
\-------------------------

Environment.reset(): Trial set up with start = (4, 3), destination = (1, 2), deadline = 20
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (4, 3), heading: (0, -1), action: forward, reward: -40.1195127485
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrrlf&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.1195127485029, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrrlf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.12)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (4, 3), heading: (0, -1), action: right, reward: -20.6056731242
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 3, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNfl&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -20.60567312418011, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNfl
Agent attempted driving right through traffic and cause a minor accident. (rewarded -20.61)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (4, 3), heading: (0, -1), action: None, reward: 2.00721486101
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNl&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: None, &#39;reward&#39;: 2.007214861008121, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNl
Agent properly idled at a red light. (rewarded 2.01)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (4, 3), heading: (0, -1), action: None, reward: 2.56833311423
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 2.5683331142252905, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.57)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act() [POST]: location: (3, 3), heading: (-1, 0), action: left, reward: 2.57207010372
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.5720701037180227, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 2.57)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0
Environment.act() [POST]: location: (3, 3), heading: (-1, 0), action: None, reward: 1.68636433516
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: 1.686364335161642, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.69)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0
Environment.act() [POST]: location: (3, 3), heading: (-1, 0), action: None, reward: 1.57944616094
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNfN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: None, &#39;reward&#39;: 1.5794461609385664, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNfN
Agent properly idled at a red light. (rewarded 1.58)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0
Environment.act() [POST]: location: (2, 3), heading: (-1, 0), action: forward, reward: 2.57545189875
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgrlN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.5754518987469845, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgrlN
Agent followed the waypoint forward. (rewarded 2.58)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0
Environment.act() [POST]: location: (1, 3), heading: (-1, 0), action: forward, reward: 1.23659267671
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNl&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.2365926767137247, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNl
Agent followed the waypoint forward. (rewarded 1.24)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (1, 2), heading: (0, -1), action: right, reward: 2.2722471032
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNf&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.2722471032046605, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNf
Agent followed the waypoint right. (rewarded 2.27)
50% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Testing trial 5
\-------------------------

Environment.reset(): Trial set up with start = (8, 5), destination = (2, 7), deadline = 20
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (7, 5), heading: (-1, 0), action: forward, reward: 1.06185804148
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgrNf&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.0618580414818926, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgrNf
Agent drove forward instead of left. (rewarded 1.06)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (6, 5), heading: (-1, 0), action: forward, reward: 0.00590231426232
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNfN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.005902314262320796, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNfN
Agent drove forward instead of left. (rewarded 0.01)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (5, 5), heading: (-1, 0), action: forward, reward: 0.716601544152
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfrf&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.7166015441519419, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfrf
Agent drove forward instead of left. (rewarded 0.72)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (4, 5), heading: (-1, 0), action: forward, reward: 1.43999548843
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.4399954884341994, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 1.44)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act() [POST]: location: (4, 5), heading: (-1, 0), action: None, reward: 1.03570511684
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 1.035705116837898, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 1.04)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0
Environment.act() [POST]: location: (4, 5), heading: (-1, 0), action: None, reward: 2.48237890435
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNl&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: 2.4823789043540567, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNl
Agent properly idled at a red light. (rewarded 2.48)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0
Environment.act() [POST]: location: (3, 5), heading: (-1, 0), action: forward, reward: 1.18440522923
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.184405229230042, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 1.18)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0
Environment.act() [POST]: location: (2, 5), heading: (-1, 0), action: forward, reward: 1.14172774285
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNl&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.1417277428533272, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNl
Agent followed the waypoint forward. (rewarded 1.14)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0
Environment.act() [POST]: location: (2, 4), heading: (0, -1), action: right, reward: 1.41377728607
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.4137772860670301, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNN
Agent drove right instead of left. (rewarded 1.41)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0
Environment.act() [POST]: location: (2, 4), heading: (0, -1), action: None, reward: 1.10436502422
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: None, &#39;reward&#39;: 1.1043650242203162, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.10)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0
Environment.act() [POST]: location: (2, 4), heading: (0, -1), action: None, reward: 1.3687921294
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: None, &#39;reward&#39;: 1.368792129396313, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 1.37)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0
Environment.act() [POST]: location: (2, 3), heading: (0, -1), action: forward, reward: 0.74642358091
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.7464235809102333, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 0.75)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0
Environment.act() [POST]: location: (2, 2), heading: (0, -1), action: forward, reward: 1.47800790769
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNfl&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.478007907691477, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNfl
Agent followed the waypoint forward. (rewarded 1.48)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (2, 7), heading: (0, -1), action: forward, reward: 1.50290255753
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.5029025575300001, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 1.50)
30% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Testing trial 6
\-------------------------

Environment.reset(): Trial set up with start = (5, 4), destination = (8, 7), deadline = 30
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (6, 4), heading: (1, 0), action: right, reward: 2.24576215289
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrrNf&#39;, &#39;deadline&#39;: 30, &#39;t&#39;: 0, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.2457621528902534, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrrNf
Agent followed the waypoint right. (rewarded 2.25)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (6, 4), heading: (1, 0), action: None, reward: 1.31788318131
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 29, &#39;t&#39;: 1, &#39;action&#39;: None, &#39;reward&#39;: 1.3178831813072718, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 1.32)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (6, 4), heading: (1, 0), action: None, reward: 2.59639724106
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 28, &#39;t&#39;: 2, &#39;action&#39;: None, &#39;reward&#39;: 2.5963972410601084, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 2.60)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (6, 4), heading: (1, 0), action: None, reward: 2.6982594134
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 27, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 2.6982594133987536, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 2.70)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act() [POST]: location: (6, 4), heading: (1, 0), action: None, reward: 1.14790460069
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 26, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 1.1479046006914284, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 1.15)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0
Environment.act() [POST]: location: (7, 4), heading: (1, 0), action: forward, reward: 1.18248249496
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 5, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.1824824949638786, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 1.18)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0
Environment.act() [POST]: location: (8, 4), heading: (1, 0), action: forward, reward: 2.73960614788
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgrlN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.739606147880534, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgrlN
Agent followed the waypoint forward. (rewarded 2.74)
77% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0
Environment.act() [POST]: location: (8, 4), heading: (1, 0), action: None, reward: 2.0954796466
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNl&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 7, &#39;action&#39;: None, &#39;reward&#39;: 2.0954796465977283, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNl
Agent properly idled at a red light. (rewarded 2.10)
73% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0
Environment.act() [POST]: location: (8, 5), heading: (0, 1), action: right, reward: 0.43872113533
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNrl&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.43872113533001234, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNrl
Agent drove right instead of left. (rewarded 0.44)
70% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0
Environment.act() [POST]: location: (8, 6), heading: (0, 1), action: forward, reward: 1.83319959805
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNrl&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.8331995980547293, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNrl
Agent followed the waypoint forward. (rewarded 1.83)
67% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0
Environment.act() [POST]: location: (7, 6), heading: (-1, 0), action: right, reward: 0.166393733456
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 10, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.1663937334562502, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlN
Agent drove right instead of forward. (rewarded 0.17)
63% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0
Environment.act() [POST]: location: (6, 6), heading: (-1, 0), action: forward, reward: 1.37786055724
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNr&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 11, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.3778605572376392, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNr
Agent drove forward instead of left. (rewarded 1.38)
60% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0
Environment.act() [POST]: location: (5, 6), heading: (-1, 0), action: forward, reward: -0.119542782048
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgllN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 12, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -0.11954278204755509, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgllN
Agent drove forward instead of left. (rewarded -0.12)
57% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0
Environment.act() [POST]: location: (5, 6), heading: (-1, 0), action: None, reward: 2.00791855329
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNr&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 13, &#39;action&#39;: None, &#39;reward&#39;: 2.0079185532920873, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNr
Agent properly idled at a red light. (rewarded 2.01)
53% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0
Environment.act() [POST]: location: (5, 6), heading: (-1, 0), action: None, reward: 1.17397209571
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 14, &#39;action&#39;: None, &#39;reward&#39;: 1.1739720957091042, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.17)
50% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0
Environment.act() [POST]: location: (5, 7), heading: (0, 1), action: left, reward: 1.35435171031
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNf&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 15, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.3543517103113027, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNf
Agent followed the waypoint left. (rewarded 1.35)
47% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0
Environment.act() [POST]: location: (6, 7), heading: (1, 0), action: left, reward: 2.27605950231
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 16, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.276059502311379, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent followed the waypoint left. (rewarded 2.28)
43% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0
Environment.act() [POST]: location: (6, 7), heading: (1, 0), action: forward, reward: -39.4846638647
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlf&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 17, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.48466386467398, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.48)
40% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0
Environment.act() [POST]: location: (6, 2), heading: (0, 1), action: right, reward: 0.112447212559
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 18, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.11244721255923484, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlN
Agent drove right instead of forward. (rewarded 0.11)
37% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0
Environment.act() [POST]: location: (5, 2), heading: (-1, 0), action: right, reward: -0.130852271031
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 19, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.13085227103139874, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNN
Agent drove right instead of left. (rewarded -0.13)
33% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0
Environment.act() [POST]: location: (5, 2), heading: (-1, 0), action: None, reward: 2.26958551475
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 20, &#39;action&#39;: None, &#39;reward&#39;: 2.2695855147491955, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 2.27)
30% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0
Environment.act() [POST]: location: (5, 7), heading: (0, -1), action: right, reward: 0.830357994354
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 21, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.830357994354294, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 0.83)
27% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0
Environment.act() [POST]: location: (5, 7), heading: (0, -1), action: None, reward: 1.1833739888
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 22, &#39;action&#39;: None, &#39;reward&#39;: 1.1833739888030526, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 1.18)
23% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0
Environment.act() [POST]: location: (6, 7), heading: (1, 0), action: right, reward: 2.23827752029
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNf&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 23, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.238277520287549, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNf
Agent followed the waypoint right. (rewarded 2.24)
20% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0
Environment.act() [POST]: location: (7, 7), heading: (1, 0), action: forward, reward: 1.00104115018
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 24, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.0010411501824092, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfNN
Agent followed the waypoint forward. (rewarded 1.00)
17% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Environment.step(): t = 25
0
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (8, 7), heading: (1, 0), action: forward, reward: 2.11036428157
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglfl&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 25, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.11036428157493, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglfl
Agent followed the waypoint forward. (rewarded 2.11)
13% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Testing trial 7
\-------------------------

Environment.reset(): Trial set up with start = (1, 3), destination = (5, 6), deadline = 35
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (8, 3), heading: (-1, 0), action: forward, reward: 1.09639130096
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglfl&#39;, &#39;deadline&#39;: 35, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.0963913009589714, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglfl
Agent followed the waypoint forward. (rewarded 1.10)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (8, 3), heading: (-1, 0), action: forward, reward: -40.6726195205
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frffN&#39;, &#39;deadline&#39;: 34, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.67261952045375, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frffN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.67)
94% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (8, 3), heading: (-1, 0), action: forward, reward: -10.4433207689
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlrN&#39;, &#39;deadline&#39;: 33, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.443320768892576, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlrN
Agent attempted driving forward through a red light. (rewarded -10.44)
91% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (8, 3), heading: (-1, 0), action: None, reward: 2.15992049276
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 32, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 2.1599204927602584, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 2.16)
89% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act() [POST]: location: (7, 3), heading: (-1, 0), action: forward, reward: 1.54610613271
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 31, &#39;t&#39;: 4, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.546106132709274, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 1.55)
86% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0
Environment.act() [POST]: location: (6, 3), heading: (-1, 0), action: forward, reward: 2.92245959142
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNr&#39;, &#39;deadline&#39;: 30, &#39;t&#39;: 5, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.9224595914232294, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNr
Agent followed the waypoint forward. (rewarded 2.92)
83% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0
Environment.act() [POST]: location: (6, 3), heading: (-1, 0), action: forward, reward: -9.48365241244
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlll&#39;, &#39;deadline&#39;: 29, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.483652412438747, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlll
Agent attempted driving forward through a red light. (rewarded -9.48)
80% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0
Environment.act() [POST]: location: (6, 3), heading: (-1, 0), action: None, reward: 1.96996252209
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 28, &#39;t&#39;: 7, &#39;action&#39;: None, &#39;reward&#39;: 1.969962522091417, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 1.97)
77% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0
Environment.act() [POST]: location: (6, 3), heading: (-1, 0), action: None, reward: 1.70477216976
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frllN&#39;, &#39;deadline&#39;: 27, &#39;t&#39;: 8, &#39;action&#39;: None, &#39;reward&#39;: 1.7047721697597595, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frllN
Agent properly idled at a red light. (rewarded 1.70)
74% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0
Environment.act() [POST]: location: (6, 3), heading: (-1, 0), action: None, reward: 1.9131085307
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 26, &#39;t&#39;: 9, &#39;action&#39;: None, &#39;reward&#39;: 1.9131085306978843, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 1.91)
71% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0
Environment.act() [POST]: location: (6, 3), heading: (-1, 0), action: None, reward: 2.83329796904
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 10, &#39;action&#39;: None, &#39;reward&#39;: 2.8332979690412063, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent properly idled at a red light. (rewarded 2.83)
69% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0
Environment.act() [POST]: location: (5, 3), heading: (-1, 0), action: forward, reward: 2.06658162598
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNl&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 11, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.066581625975351, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNl
Agent followed the waypoint forward. (rewarded 2.07)
66% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0
Environment.act() [POST]: location: (5, 2), heading: (0, -1), action: right, reward: 1.79828498096
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrllN&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 12, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.7982849809649348, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrllN
Agent followed the waypoint right. (rewarded 1.80)
63% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0
Environment.act() [POST]: location: (5, 2), heading: (0, -1), action: None, reward: 1.84930117762
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNll&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 13, &#39;action&#39;: None, &#39;reward&#39;: 1.8493011776228672, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNll
Agent properly idled at a red light. (rewarded 1.85)
60% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0
Environment.act() [POST]: location: (5, 2), heading: (0, -1), action: None, reward: 1.65968328412
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNff&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 14, &#39;action&#39;: None, &#39;reward&#39;: 1.6596832841212796, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNff
Agent properly idled at a red light. (rewarded 1.66)
57% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0
Environment.act() [POST]: location: (5, 2), heading: (0, -1), action: None, reward: 1.92313854973
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 15, &#39;action&#39;: None, &#39;reward&#39;: 1.9231385497268185, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.92)
54% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0
Environment.act() [POST]: location: (5, 2), heading: (0, -1), action: None, reward: 1.12003055222
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 16, &#39;action&#39;: None, &#39;reward&#39;: 1.1200305522182021, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.12)
51% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0
Environment.act() [POST]: location: (5, 7), heading: (0, -1), action: forward, reward: 1.40369123725
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 17, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.4036912372541392, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 1.40)
49% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0
Environment.act() [POST]: location: (5, 7), heading: (0, -1), action: None, reward: 2.59546549011
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNl&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 18, &#39;action&#39;: None, &#39;reward&#39;: 2.5954654901058536, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNl
Agent properly idled at a red light. (rewarded 2.60)
46% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0
Environment.act() [POST]: location: (5, 7), heading: (0, -1), action: None, reward: 0.764547188466
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 19, &#39;action&#39;: None, &#39;reward&#39;: 0.7645471884661912, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 0.76)
43% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0
Environment.act() [POST]: location: (5, 7), heading: (0, -1), action: None, reward: 2.24066167469
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 20, &#39;action&#39;: None, &#39;reward&#39;: 2.240661674687371, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.24)
40% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (5, 6), heading: (0, -1), action: forward, reward: 0.720033549244
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNr&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 21, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.7200335492436356, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNr
Agent followed the waypoint forward. (rewarded 0.72)
37% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Testing trial 8
\-------------------------

Environment.reset(): Trial set up with start = (6, 6), destination = (1, 5), deadline = 20
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (6, 5), heading: (0, -1), action: forward, reward: 0.00769768700063
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglll&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.00769768700062623, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglll
Agent drove forward instead of right. (rewarded 0.01)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (6, 4), heading: (0, -1), action: forward, reward: 0.303190739013
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNlN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.3031907390133183, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNlN
Agent drove forward instead of right. (rewarded 0.30)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (6, 4), heading: (0, -1), action: None, reward: 2.85471977796
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: None, &#39;reward&#39;: 2.854719777955135, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 2.85)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (6, 4), heading: (0, -1), action: forward, reward: -40.6319572336
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlrf&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.631957233558765, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlrf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.63)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act() [POST]: location: (6, 4), heading: (0, -1), action: None, reward: 1.94015384589
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 1.9401538458867775, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 1.94)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0
Environment.act() [POST]: location: (6, 3), heading: (0, -1), action: forward, reward: 0.108986163928
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.10898616392842375, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent drove forward instead of right. (rewarded 0.11)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0
Environment.act() [POST]: location: (6, 2), heading: (0, -1), action: forward, reward: 0.608458108371
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNlN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.6084581083711631, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNlN
Agent drove forward instead of right. (rewarded 0.61)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0
Environment.act() [POST]: location: (6, 2), heading: (0, -1), action: None, reward: 1.73197857991
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNf&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: None, &#39;reward&#39;: 1.7319785799136418, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNf
Agent idled at a green light with oncoming traffic. (rewarded 1.73)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0
Environment.act() [POST]: location: (7, 2), heading: (1, 0), action: right, reward: 1.29214833455
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNf&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.292148334553159, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNf
Agent followed the waypoint right. (rewarded 1.29)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0
Environment.act() [POST]: location: (8, 2), heading: (1, 0), action: forward, reward: 1.58418304684
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNfl&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.5841830468407805, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNfl
Agent followed the waypoint forward. (rewarded 1.58)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0
Environment.act() [POST]: location: (1, 2), heading: (1, 0), action: forward, reward: 2.45946752027
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.459467520270405, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 2.46)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0
Environment.act() [POST]: location: (1, 3), heading: (0, 1), action: right, reward: 0.739393401076
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNf&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.7393934010759768, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNf
Agent drove right instead of left. (rewarded 0.74)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0
Environment.act() [POST]: location: (1, 4), heading: (0, 1), action: forward, reward: 1.10783773731
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNlN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.1078377373083537, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNlN
Agent followed the waypoint forward. (rewarded 1.11)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0
Environment.act() [POST]: location: (8, 4), heading: (-1, 0), action: right, reward: 0.642829682508
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.6428296825079797, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNN
Agent drove right instead of forward. (rewarded 0.64)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0
Environment.act() [POST]: location: (8, 3), heading: (0, -1), action: right, reward: -0.163073416852
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 14, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.1630734168519331, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNN
Agent drove right instead of left. (rewarded -0.16)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0
Environment.act() [POST]: location: (8, 3), heading: (0, -1), action: None, reward: 1.63771675896
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 15, &#39;action&#39;: None, &#39;reward&#39;: 1.6377167589562203, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 1.64)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0
Environment.act() [POST]: location: (8, 2), heading: (0, -1), action: forward, reward: -0.0117045695848
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNrN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 16, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -0.011704569584778834, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNrN
Agent drove forward instead of right. (rewarded -0.01)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0
Environment.act() [POST]: location: (1, 2), heading: (1, 0), action: right, reward: 0.419571202655
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrllN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 17, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.4195712026545282, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrllN
Agent followed the waypoint right. (rewarded 0.42)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0
Environment.act() [POST]: location: (1, 7), heading: (0, -1), action: left, reward: 0.328413577805
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNl&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 18, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.328413577804914, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNl
Agent followed the waypoint left. (rewarded 0.33)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0
Environment.act() [POST]: location: (1, 7), heading: (0, -1), action: None, reward: 1.84051379416
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNff&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 19, &#39;action&#39;: None, &#39;reward&#39;: 1.84051379416239, &#39;waypoint&#39;: &#39;forward&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: frNff
Agent properly idled at a red light. (rewarded 1.84)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Testing trial 9
\-------------------------

Environment.reset(): Trial set up with start = (6, 4), destination = (1, 5), deadline = 20
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (7, 4), heading: (1, 0), action: forward, reward: 2.8915807495
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.8915807494954415, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfNN
Agent followed the waypoint forward. (rewarded 2.89)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (7, 5), heading: (0, 1), action: right, reward: 1.78902159362
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.7890215936210367, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNN
Agent drove right instead of forward. (rewarded 1.79)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (7, 5), heading: (0, 1), action: None, reward: 1.8326472293
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: None, &#39;reward&#39;: 1.8326472293036193, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.83)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (7, 5), heading: (0, 1), action: None, reward: 1.39561339371
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 1.395613393709457, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.40)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act() [POST]: location: (7, 5), heading: (0, 1), action: None, reward: 2.67179418575
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 2.6717941857490093, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 2.67)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0
Environment.act() [POST]: location: (7, 5), heading: (0, 1), action: None, reward: 1.55279471417
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: 1.552794714169406, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.55)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0
Environment.act() [POST]: location: (8, 5), heading: (1, 0), action: left, reward: 2.55994995449
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.559949954490154, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent followed the waypoint left. (rewarded 2.56)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0
Environment.act() [POST]: location: (8, 5), heading: (1, 0), action: None, reward: 1.85244873226
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: None, &#39;reward&#39;: 1.8524487322580725, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.85)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0
Environment.act() [POST]: location: (8, 5), heading: (1, 0), action: None, reward: 0.903573339738
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: None, &#39;reward&#39;: 0.9035733397383079, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 0.90)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0
Environment.act() [POST]: location: (8, 5), heading: (1, 0), action: None, reward: 2.78952478257
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: None, &#39;reward&#39;: 2.789524782570565, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.79)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0
Environment.act() [POST]: location: (8, 6), heading: (0, 1), action: right, reward: 1.00453235405
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.0045323540534765, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlN
Agent drove right instead of forward. (rewarded 1.00)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0
Environment.act() [POST]: location: (8, 6), heading: (0, 1), action: forward, reward: -39.4398066751
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNlf&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.43980667514842, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNlf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.44)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0
Environment.act() [POST]: location: (8, 6), heading: (0, 1), action: None, reward: 2.18761312261
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNlN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: None, &#39;reward&#39;: 2.1876131226064164, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNlN
Agent properly idled at a red light. (rewarded 2.19)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0
Environment.act() [POST]: location: (8, 7), heading: (0, 1), action: forward, reward: -0.379344950304
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglrN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -0.37934495030390736, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglrN
Agent drove forward instead of left. (rewarded -0.38)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0
Environment.act() [POST]: location: (8, 2), heading: (0, 1), action: forward, reward: 0.84718978023
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgffN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 14, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.8471897802302196, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgffN
Agent drove forward instead of left. (rewarded 0.85)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0
Environment.act() [POST]: location: (8, 2), heading: (0, 1), action: forward, reward: -9.7620316427
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNr&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 15, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.762031642704645, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNr
Agent attempted driving forward through a red light. (rewarded -9.76)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0
Environment.act() [POST]: location: (7, 2), heading: (-1, 0), action: right, reward: -0.471527410214
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 16, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.47152741021444466, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNN
Agent drove right instead of left. (rewarded -0.47)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0
Environment.act() [POST]: location: (7, 7), heading: (0, -1), action: right, reward: 2.13826528856
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNlN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 17, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.1382652885631366, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNlN
Agent followed the waypoint right. (rewarded 2.14)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0
Environment.act() [POST]: location: (7, 6), heading: (0, -1), action: forward, reward: 1.14789159497
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglfN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 18, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.1478915949722666, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglfN
Agent drove forward instead of right. (rewarded 1.15)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0
Environment.act() [POST]: location: (7, 5), heading: (0, -1), action: forward, reward: 0.812171468727
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgfNf&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 19, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.812171468726835, &#39;waypoint&#39;: &#39;right&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: rgfNf
Agent drove forward instead of right. (rewarded 0.81)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Testing trial 10
\-------------------------

Environment.reset(): Trial set up with start = (2, 5), destination = (6, 3), deadline = 30
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (2, 5), heading: (0, 1), action: None, reward: 1.20507043866
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 30, &#39;t&#39;: 0, &#39;action&#39;: None, &#39;reward&#39;: 1.2050704386635476, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 1.21)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (2, 5), heading: (0, 1), action: None, reward: 1.0473962376
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 29, &#39;t&#39;: 1, &#39;action&#39;: None, &#39;reward&#39;: 1.0473962375982413, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 1.05)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (2, 5), heading: (0, 1), action: None, reward: 1.47253154542
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 28, &#39;t&#39;: 2, &#39;action&#39;: None, &#39;reward&#39;: 1.472531545417319, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 1.47)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (2, 5), heading: (0, 1), action: None, reward: 2.5003325548
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 27, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 2.500332554804013, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 2.50)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act() [POST]: location: (2, 6), heading: (0, 1), action: forward, reward: 1.0174791017
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglfl&#39;, &#39;deadline&#39;: 26, &#39;t&#39;: 4, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.0174791016972797, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglfl
Agent drove forward instead of right. (rewarded 1.02)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0
Environment.act() [POST]: location: (1, 6), heading: (-1, 0), action: right, reward: 2.32043003528
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNl&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 5, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.320430035282283, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNl
Agent followed the waypoint right. (rewarded 2.32)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0
Environment.act() [POST]: location: (1, 6), heading: (-1, 0), action: None, reward: 1.49472235097
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 6, &#39;action&#39;: None, &#39;reward&#39;: 1.4947223509697658, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.49)
77% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0
Environment.act() [POST]: location: (8, 6), heading: (-1, 0), action: forward, reward: 1.62854640853
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 7, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.6285464085277601, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 1.63)
73% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0
Environment.act() [POST]: location: (8, 6), heading: (-1, 0), action: None, reward: 2.57811816395
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frrNr&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 8, &#39;action&#39;: None, &#39;reward&#39;: 2.578118163945298, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frrNr
Agent properly idled at a red light. (rewarded 2.58)
70% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0
Environment.act() [POST]: location: (7, 6), heading: (-1, 0), action: forward, reward: 1.08471374391
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.084713743906956, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 1.08)
67% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0
Environment.act() [POST]: location: (7, 6), heading: (-1, 0), action: forward, reward: -10.8999072944
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlrN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 10, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.899907294431777, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlrN
Agent attempted driving forward through a red light. (rewarded -10.90)
63% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0
Environment.act() [POST]: location: (6, 6), heading: (-1, 0), action: forward, reward: 2.81840993805
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 11, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.8184099380467122, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 2.82)
60% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0
Environment.act() [POST]: location: (6, 6), heading: (-1, 0), action: None, reward: 1.19700977912
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 12, &#39;action&#39;: None, &#39;reward&#39;: 1.1970097791192043, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.20)
57% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0
Environment.act() [POST]: location: (6, 6), heading: (-1, 0), action: None, reward: 2.7835355491
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 13, &#39;action&#39;: None, &#39;reward&#39;: 2.783535549096568, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 2.78)
53% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0
Environment.act() [POST]: location: (6, 6), heading: (-1, 0), action: forward, reward: -40.2498091519
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlrf&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 14, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.249809151904834, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlrf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.25)
50% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0
Environment.act() [POST]: location: (6, 5), heading: (0, -1), action: right, reward: -0.00193943025745
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNf&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 15, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.0019394302574481381, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNf
Agent drove right instead of left. (rewarded -0.00)
47% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0
Environment.act() [POST]: location: (7, 5), heading: (1, 0), action: right, reward: 0.772807276489
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 16, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.7728072764890184, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlN
Agent drove right instead of forward. (rewarded 0.77)
43% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0
Environment.act() [POST]: location: (8, 5), heading: (1, 0), action: forward, reward: 0.572031713078
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNrN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 17, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.5720317130783912, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNrN
Agent drove forward instead of left. (rewarded 0.57)
40% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0
Environment.act() [POST]: location: (1, 5), heading: (1, 0), action: forward, reward: 0.921214585907
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfff&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 18, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.9212145859072907, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfff
Agent drove forward instead of left. (rewarded 0.92)
37% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0
Environment.act() [POST]: location: (1, 6), heading: (0, 1), action: right, reward: -0.122779209142
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 19, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.12277920914176998, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNN
Agent drove right instead of left. (rewarded -0.12)
33% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0
Environment.act() [POST]: location: (8, 6), heading: (-1, 0), action: right, reward: 2.13250350073
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNf&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 20, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.1325035007253805, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNf
Agent followed the waypoint right. (rewarded 2.13)
30% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0
Environment.act() [POST]: location: (7, 6), heading: (-1, 0), action: forward, reward: 2.20262624916
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 21, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.202626249161523, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfNN
Agent followed the waypoint forward. (rewarded 2.20)
27% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0
Environment.act() [POST]: location: (7, 6), heading: (-1, 0), action: forward, reward: -9.53854292716
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frrNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 22, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.53854292715978, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frrNN
Agent attempted driving forward through a red light. (rewarded -9.54)
23% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0
Environment.act() [POST]: location: (6, 6), heading: (-1, 0), action: forward, reward: 1.72900958836
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 23, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.7290095883645207, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 1.73)
20% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0
Environment.act() [POST]: location: (6, 5), heading: (0, -1), action: right, reward: 0.634994625766
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 24, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.6349946257659658, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNN
Agent drove right instead of left. (rewarded 0.63)
17% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Environment.step(): t = 25
0
Environment.act() [POST]: location: (6, 4), heading: (0, -1), action: forward, reward: 1.62055147517
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 25, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.620551475172238, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 1.62)
13% of time remaining to reach destination.

/-------------------
| Step 26 Results
\-------------------

Environment.step(): t = 26
0
Environment.act() [POST]: location: (7, 4), heading: (1, 0), action: right, reward: 0.711790611292
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frflN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 26, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.7117906112923176, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frflN
Agent drove right instead of forward. (rewarded 0.71)
10% of time remaining to reach destination.

/-------------------
| Step 27 Results
\-------------------

Environment.step(): t = 27
0
Environment.act() [POST]: location: (7, 5), heading: (0, 1), action: right, reward: 0.772494382714
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrllN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 27, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.7724943827142152, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrllN
Agent drove right instead of left. (rewarded 0.77)
7% of time remaining to reach destination.

/-------------------
| Step 28 Results
\-------------------

Environment.step(): t = 28
0
Environment.act() [POST]: location: (6, 5), heading: (-1, 0), action: right, reward: 1.92138873951
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfNN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 28, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.9213887395057798, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfNN
Agent followed the waypoint right. (rewarded 1.92)
3% of time remaining to reach destination.

/-------------------
| Step 29 Results
\-------------------

Environment.step(): t = 29
0
Environment.act() [POST]: location: (5, 5), heading: (-1, 0), action: forward, reward: -0.143803056813
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 29, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -0.1438030568125348, &#39;waypoint&#39;: &#39;right&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: rglNN
Agent drove forward instead of right. (rewarded -0.14)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

Simulation ended. . . 
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Answer:</strong>
firstly, the agent is not moving, because of that the state of the agent does not update. However, it get reward as float values and it changed between positive and negative depended on the situation; for example, if the light sign is red and the agent is stop in its place the reward is positive but if light is greena and it stay in its place the reward will be a negative value. So, the reward depended on the many values other the other cars like the light color.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Understand-the-Code">Understand the Code<a class="anchor-link" href="#Understand-the-Code">&#182;</a></h3><p>In addition to understanding the world, it is also necessary to understand the code itself that governs how the world, simulation, and so on operate. Attempting to create a driving agent would be difficult without having at least explored the <em>"hidden"</em> devices that make everything work. In the <code>/smartcab/</code> top-level directory, there are two folders: <code>/logs/</code> (which will be used later) and <code>/smartcab/</code>. Open the <code>/smartcab/</code> folder and explore each Python file included, then answer the following question.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Question-2">Question 2<a class="anchor-link" href="#Question-2">&#182;</a></h3><ul>
<li><em>In the </em><code>agent.py</code><em> Python file, choose three flags that can be set and explain how they change the simulation.</em></li>
<li><em>In the </em><code>environment.py</code><em> Python file, what Environment class function is called when an agent performs an action?</em></li>
<li><em>In the </em><code>simulator.py</code><em> Python file, what is the difference between the </em><code>'render_text()'</code><em> function and the </em><code>'render()'</code><em> function?</em></li>
<li><em>In the </em><code>planner.py</code><em> Python file, will the </em><code>'next_waypoint()</code><em> function consider the North-South or East-West direction first?</em></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Answer:</strong></p>
<ul>
<li>In the file agent.py three flags changed their values, which are "update_delay = 0.1", "log_metrics = True", and "learning = True". Starting from "update_delay" Which change the time between each update from 2 which is the default value to 0.1 secand and this make the udate faster. "learning = True" there is not obvious changing happend from this flag except now two loger files. "log_metrics = True" by this flag new loger files created the first one ""sim_no-learning.csv which has one raw of values : 
<img src="attachment:image.png" alt="image.png"></li>
</ul>
<p>Howevere, after chage the value of the flag "learning" to True new loger files created "sim_default-learning.csv" and   "sim_defualt-learning.txt".
the values of the first one is:
<img src="attachment:image.png" alt="image.png">
and the value of the text file is:</p>
<p>/-----------------------------------------
| State-action rewards from Q-Learning
-----------------------------------------</p>
<ul>
<li><p>The method for the prformed the agent actions is "act" which take three arguments (self, agent, action) and return the rewared of that action.</p>
</li>
<li><p>The render_txt() method is for render txt output from the envermenint by the text values but the render method is return the enviremnint status like GUI in pyGame window. However, the both method are return the same data but in diffrent ways.</p>
</li>
<li><p>The 'next_waypoint() function is looking for the East-West diction before the North-South direction.</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Implement-a-Basic-Driving-Agent">Implement a Basic Driving Agent<a class="anchor-link" href="#Implement-a-Basic-Driving-Agent">&#182;</a></h2><p>The first step to creating an optimized Q-Learning driving agent is getting the agent to actually take valid actions. In this case, a valid action is one of <code>None</code>, (do nothing) <code>'Left'</code> (turn left), <code>'Right'</code> (turn right), or <code>'Forward'</code> (go forward). For your first implementation, navigate to the <code>'choose_action()'</code> agent function and make the driving agent randomly choose one of these actions. Note that you have access to several class variables that will help you write this functionality, such as <code>'self.learning'</code> and <code>'self.valid_actions'</code>. Once implemented, run the agent file and simulation briefly to confirm that your driving agent is taking a random action each time step.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Basic-Agent-Simulation-Results">Basic Agent Simulation Results<a class="anchor-link" href="#Basic-Agent-Simulation-Results">&#182;</a></h3><p>To obtain results from the initial simulation, you will need to adjust following flags:</p>
<ul>
<li><code>'enforce_deadline'</code> - Set this to <code>True</code> to force the driving agent to capture whether it reaches the destination in time.</li>
<li><code>'update_delay'</code> - Set this to a small value (such as <code>0.01</code>) to reduce the time between steps in each trial.</li>
<li><code>'log_metrics'</code> - Set this to <code>True</code> to log the simluation results as a <code>.csv</code> file in <code>/logs/</code>.</li>
<li><code>'n_test'</code> - Set this to <code>'10'</code> to perform 10 testing trials.</li>
</ul>
<p>Optionally, you may disable to the visual simulation (which can make the trials go faster) by setting the <code>'display'</code> flag to <code>False</code>. Flags that have been set here should be returned to their default setting when debugging. It is important that you understand what each flag does and how it affects the simulation!</p>
<p>Once you have successfully completed the initial simulation (there should have been 20 training trials and 10 testing trials), run the code cell below to visualize the results. Note that log files are overwritten when identical simulations are run, so be careful with what log file is being loaded!
Run the agent.py file after setting the flags from projects/smartcab folder instead of projects/smartcab/smartcab.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Load the &#39;sim_no-learning&#39; log file from the initial simulation results</span>
<span class="n">vs</span><span class="o">.</span><span class="n">plot_trials</span><span class="p">(</span><span class="s1">&#39;sim_no-learning.csv&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA1gAAAI4CAYAAAB3HEhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Question-3">Question 3<a class="anchor-link" href="#Question-3">&#182;</a></h3><p>Using the visualization above that was produced from your initial simulation, provide an analysis and make several observations about the driving agent. Be sure that you are making at least one observation about each panel present in the visualization. Some things you could consider:</p>
<ul>
<li><em>How frequently is the driving agent making bad decisions? How many of those bad decisions cause accidents?</em></li>
<li><em>Given that the agent is driving randomly, does the rate of reliabilty make sense?</em></li>
<li><em>What kind of rewards is the agent receiving for its actions? Do the rewards suggest it has been penalized heavily?</em></li>
<li><em>As the number of trials increases, does the outcome of results change significantly?</em></li>
<li><em>Would this Smartcab be considered safe and/or reliable for its passengers? Why or why not?</em></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Answer:</strong></p>
<ul>
<li>About 0.45 is the frequently of the bad decisions and over 0.05 for that dicisions make accidents.</li>
<li>The reliability of the agent is about 30% which is very bad but comparing to the dicisions made randomly so is make sense.</li>
<li>for the 20 trials the agent did the avarge is less than -4 which right because the dicision was bad.</li>
<li>By the increasing of the trials the outcome from result did not changed because until now there is not any learning to the agent and decision came rendomly.</li>
<li>Of course, the agent is not reliable or is safe for passangers and that because of its decisions made reandomly and there is not any mechanism to choose the better action in each move.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Inform-the-Driving-Agent">Inform the Driving Agent<a class="anchor-link" href="#Inform-the-Driving-Agent">&#182;</a></h2><p>The second step to creating an optimized Q-learning driving agent is defining a set of states that the agent can occupy in the environment. Depending on the input, sensory data, and additional variables available to the driving agent, a set of states can be defined for the agent so that it can eventually <em>learn</em> what action it should take when occupying a state. The condition of <code>'if state then action'</code> for each state is called a <strong>policy</strong>, and is ultimately what the driving agent is expected to learn. Without defining states, the driving agent would never understand which action is most optimal -- or even what environmental variables and conditions it cares about!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Identify-States">Identify States<a class="anchor-link" href="#Identify-States">&#182;</a></h3><p>Inspecting the <code>'build_state()'</code> agent function shows that the driving agent is given the following data from the environment:</p>
<ul>
<li><code>'waypoint'</code>, which is the direction the <em>Smartcab</em> should drive leading to the destination, relative to the <em>Smartcab</em>'s heading.</li>
<li><code>'inputs'</code>, which is the sensor data from the <em>Smartcab</em>. It includes <ul>
<li><code>'light'</code>, the color of the light.</li>
<li><code>'left'</code>, the intended direction of travel for a vehicle to the <em>Smartcab</em>'s left. Returns <code>None</code> if no vehicle is present.</li>
<li><code>'right'</code>, the intended direction of travel for a vehicle to the <em>Smartcab</em>'s right. Returns <code>None</code> if no vehicle is present.</li>
<li><code>'oncoming'</code>, the intended direction of travel for a vehicle across the intersection from the <em>Smartcab</em>. Returns <code>None</code> if no vehicle is present.</li>
</ul>
</li>
<li><code>'deadline'</code>, which is the number of actions remaining for the <em>Smartcab</em> to reach the destination before running out of time.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Question-4">Question 4<a class="anchor-link" href="#Question-4">&#182;</a></h3><p><em>Which features available to the agent are most relevant for learning both <strong>safety</strong> and <strong>efficiency</strong>? Why are these features appropriate for modeling the </em>Smartcab<em> in the environment? If you did not choose some features, why are those features</em> not <em>appropriate?</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Answer:</strong></p>
<ul>
<li><p>All that feature are rilated to the safety and efficiency, but to be specific, 'waypoint' and 'deadline' are rilated to the efficiency because the efficte on the time of reich the goal location. and the inputs {'light', 'left', 'right', 'oncoming'} are more rilated to the safety because is considring if there other cars in that location of next step.</p>
</li>
<li><p>Those feature are appropriate for modeling the Smartcab in the enviroment because we need those to make decision about next action, and find the fast and best way to rich the goal location befor the end of the deadline.</p>
</li>
<li>In case we should choose some of that feature, I will choose to delete the 'waypoint' and 'deadline' because rish the gaol safety is important than the efficiency. Beside, the input reprisent the status of that time.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Define-a-State-Space">Define a State Space<a class="anchor-link" href="#Define-a-State-Space">&#182;</a></h3><p>When defining a set of states that the agent can occupy, it is necessary to consider the <em>size</em> of the state space. That is to say, if you expect the driving agent to learn a <strong>policy</strong> for each state, you would need to have an optimal action for <em>every</em> state the agent can occupy. If the number of all possible states is very large, it might be the case that the driving agent never learns what to do in some states, which can lead to uninformed decisions. For example, consider a case where the following features are used to define the state of the <em>Smartcab</em>:</p>
<p><code>('is_raining', 'is_foggy', 'is_red_light', 'turn_left', 'no_traffic', 'previous_turn_left', 'time_of_day')</code>.</p>
<p>How frequently would the agent occupy a state like <code>(False, True, True, True, False, False, '3AM')</code>? Without a near-infinite amount of time for training, it's doubtful the agent would ever learn the proper action!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Question-5">Question 5<a class="anchor-link" href="#Question-5">&#182;</a></h3><p><em>If a state is defined using the features you've selected from <strong>Question 4</strong>, what would be the size of the state space? Given what you know about the evironment and how it is simulated, do you think the driving agent could learn a policy for each possible state within a reasonable number of training trials?</em><br>
<strong>Hint:</strong> Consider the <em>combinations</em> of features to calculate the total number of states!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Answer:</strong></p>
<ul>
<li>From the environment, the state spaece will be like this ('direction','is_red','left_available','right_available', 'oncoming_available','deadline') and the value of the 'direction' is 0-3 and each one of them rilated to on of (North,East,South,West), boolean values for the {'is_red','left_available','right_available', 'oncoming_available'} and int value for the 'deadline' for the remining time. </li>
<li>I think the number of possible state is 4*2*2*2*2 = 64 a small number for the status to the agent. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Update-the-Driving-Agent-State">Update the Driving Agent State<a class="anchor-link" href="#Update-the-Driving-Agent-State">&#182;</a></h3><p>For your second implementation, navigate to the <code>'build_state()'</code> agent function. With the justification you've provided in <strong>Question 4</strong>, you will now set the <code>'state'</code> variable to a tuple of all the features necessary for Q-Learning. Confirm your driving agent is updating its state by running the agent file and simulation briefly and note whether the state is displaying. If the visual simulation is used, confirm that the updated state corresponds with what is seen in the simulation.</p>
<p><strong>Note:</strong> Remember to reset simulation flags to their default setting when making this observation!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Implement-a-Q-Learning-Driving-Agent">Implement a Q-Learning Driving Agent<a class="anchor-link" href="#Implement-a-Q-Learning-Driving-Agent">&#182;</a></h2><p>The third step to creating an optimized Q-Learning agent is to begin implementing the functionality of Q-Learning itself. The concept of Q-Learning is fairly straightforward: For every state the agent visits, create an entry in the Q-table for all state-action pairs available. Then, when the agent encounters a state and performs an action, update the Q-value associated with that state-action pair based on the reward received and the interative update rule implemented. Of course, additional benefits come from Q-Learning, such that we can have the agent choose the <em>best</em> action for each state based on the Q-values of each state-action pair possible. For this project, you will be implementing a <em>decaying,</em> $\epsilon$<em>-greedy</em> Q-learning algorithm with <em>no</em> discount factor. Follow the implementation instructions under each <strong>TODO</strong> in the agent functions.</p>
<p>Note that the agent attribute <code>self.Q</code> is a dictionary: This is how the Q-table will be formed. Each state will be a key of the <code>self.Q</code> dictionary, and each value will then be another dictionary that holds the <em>action</em> and <em>Q-value</em>. Here is an example:</p>

<pre><code>{ 'state-1': { 
    'action-1' : Qvalue-1,
    'action-2' : Qvalue-2,
     ...
   },
  'state-2': {
    'action-1' : Qvalue-1,
     ...
   },
   ...
}</code></pre>
<p>Furthermore, note that you are expected to use a <em>decaying</em> $\epsilon$ <em>(exploration) factor</em>. Hence, as the number of trials increases, $\epsilon$ should decrease towards 0. This is because the agent is expected to learn from its behavior and begin acting on its learned behavior. Additionally, The agent will be tested on what it has learned after $\epsilon$ has passed a certain threshold (the default threshold is 0.01). For the initial Q-Learning implementation, you will be implementing a linear decaying function for $\epsilon$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Q-Learning-Simulation-Results">Q-Learning Simulation Results<a class="anchor-link" href="#Q-Learning-Simulation-Results">&#182;</a></h3><p>To obtain results from the initial Q-Learning implementation, you will need to adjust the following flags and setup:</p>
<ul>
<li><code>'enforce_deadline'</code> - Set this to <code>True</code> to force the driving agent to capture whether it reaches the destination in time.</li>
<li><code>'update_delay'</code> - Set this to a small value (such as <code>0.01</code>) to reduce the time between steps in each trial.</li>
<li><code>'log_metrics'</code> - Set this to <code>True</code> to log the simluation results as a <code>.csv</code> file and the Q-table as a <code>.txt</code> file in <code>/logs/</code>.</li>
<li><code>'n_test'</code> - Set this to <code>'10'</code> to perform 10 testing trials.</li>
<li><code>'learning'</code> - Set this to <code>'True'</code> to tell the driving agent to use your Q-Learning implementation.</li>
</ul>
<p>In addition, use the following decay function for $\epsilon$:</p>
$$ \epsilon_{t+1} = \epsilon_{t} - 0.05, \hspace{10px}\textrm{for trial number } t$$<p>If you have difficulty getting your implementation to work, try setting the <code>'verbose'</code> flag to <code>True</code> to help debug. Flags that have been set here should be returned to their default setting when debugging. It is important that you understand what each flag does and how it affects the simulation!</p>
<p>Once you have successfully completed the initial Q-Learning simulation, run the code cell below to visualize the results. Note that log files are overwritten when identical simulations are run, so be careful with what log file is being loaded!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[34]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="o">%</span><span class="k">run</span>  smartcab/agent.py
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>
/-------------------------
| Training trial 1
\-------------------------

Environment.reset(): Trial set up with start = (1, 3), destination = (7, 6), deadline = 25
Simulating trial. . . 
epsilon = 0.9500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.95
Environment.act() [POST]: location: (1, 3), heading: (0, -1), action: forward, reward: -10.6776239957
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlrl&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.67762399574318, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlrl
Agent attempted driving forward through a red light. (rewarded -10.68)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.95
Environment.act() [POST]: location: (1, 3), heading: (0, -1), action: None, reward: 1.73690278659
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlfl&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 1, &#39;action&#39;: None, &#39;reward&#39;: 1.736902786590918, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlfl
Agent properly idled at a red light. (rewarded 1.74)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.95
Environment.act() [POST]: location: (1, 3), heading: (0, -1), action: None, reward: 1.29549331789
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlrf&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 2, &#39;action&#39;: None, &#39;reward&#39;: 1.2954933178940529, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlrf
Agent properly idled at a red light. (rewarded 1.30)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.95
Environment.act() [POST]: location: (1, 3), heading: (0, -1), action: forward, reward: -9.44730342776
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 3, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.447303427755925, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent attempted driving forward through a red light. (rewarded -9.45)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.95
Environment.act() [POST]: location: (2, 3), heading: (1, 0), action: right, reward: 0.722296615211
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 4, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.7222966152113971, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent drove right instead of left. (rewarded 0.72)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.95
Environment.act() [POST]: location: (2, 3), heading: (1, 0), action: None, reward: -5.91636393696
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: -5.9163639369582794, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent idled at a green light with no oncoming traffic. (rewarded -5.92)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.95
Environment.act() [POST]: location: (2, 2), heading: (0, -1), action: left, reward: 2.81368165702
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 6, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.813681657022048, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 2.81)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.95
Environment.act() [POST]: location: (2, 2), heading: (0, -1), action: forward, reward: -10.8727642084
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNl&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 7, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.872764208421316, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNl
Agent attempted driving forward through a red light. (rewarded -10.87)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.95
Environment.act() [POST]: location: (3, 2), heading: (1, 0), action: right, reward: -0.0898272439775
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNl&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.0898272439775406, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNl
Agent drove right instead of left. (rewarded -0.09)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.95
Environment.act() [POST]: location: (4, 2), heading: (1, 0), action: forward, reward: 0.848240464984
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNf&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.8482404649837656, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNf
Agent drove forward instead of left. (rewarded 0.85)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.95
Environment.act() [POST]: location: (4, 3), heading: (0, 1), action: right, reward: 0.624485197376
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgllN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 10, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.6244851973761615, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgllN
Agent drove right instead of forward. (rewarded 0.62)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.95
Environment.act() [POST]: location: (4, 4), heading: (0, 1), action: forward, reward: 1.50529143901
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNfN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 11, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.5052914390139724, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNfN
Agent drove forward instead of left. (rewarded 1.51)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.95
Environment.act() [POST]: location: (4, 4), heading: (0, 1), action: left, reward: -10.0729832275
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNll&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 12, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.072983227497755, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNll
Agent attempted driving left through a red light. (rewarded -10.07)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.95
Environment.act() [POST]: location: (5, 4), heading: (1, 0), action: left, reward: 1.70780331727
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 13, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.707803317267121, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 1.71)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.95
Environment.act() [POST]: location: (6, 4), heading: (1, 0), action: forward, reward: 1.97316979249
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 14, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.9731697924857312, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 1.97)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.95
Environment.act() [POST]: location: (6, 3), heading: (0, -1), action: left, reward: -0.26778729164
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNlf&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 15, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -0.2677872916399182, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNlf
Agent drove left instead of forward. (rewarded -0.27)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.95
Environment.act() [POST]: location: (6, 3), heading: (0, -1), action: None, reward: 0.66645110589
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlrl&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 16, &#39;action&#39;: None, &#39;reward&#39;: 0.6664511058898539, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlrl
Agent properly idled at a red light. (rewarded 0.67)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.95
Environment.act() [POST]: location: (6, 3), heading: (0, -1), action: None, reward: 0.0782163865335
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 17, &#39;action&#39;: None, &#39;reward&#39;: 0.07821638653350216, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent idled at a green light with oncoming traffic. (rewarded 0.08)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.95
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: right, reward: 2.35271992123
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgrNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 18, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.3527199212264747, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgrNN
Agent followed the waypoint right. (rewarded 2.35)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.95
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: forward, reward: -39.7913626076
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrrNf&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 19, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.79136260762033, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrrNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.79)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.95
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: forward, reward: -10.6060065156
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNlN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 20, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.606006515551522, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNlN
Agent attempted driving forward through a red light. (rewarded -10.61)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.95
Environment.act() [POST]: location: (7, 2), heading: (0, -1), action: left, reward: 0.378166196607
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNl&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 21, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.37816619660707684, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNl
Agent followed the waypoint left. (rewarded 0.38)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.95
Environment.act() [POST]: location: (7, 2), heading: (0, -1), action: None, reward: -4.73360806521
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 22, &#39;action&#39;: None, &#39;reward&#39;: -4.7336080652073855, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent idled at a green light with no oncoming traffic. (rewarded -4.73)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0.95
Environment.act() [POST]: location: (7, 2), heading: (0, -1), action: forward, reward: -9.24948686065
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 23, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.249486860654482, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent attempted driving forward through a red light. (rewarded -9.25)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0.95
Environment.act() [POST]: location: (7, 2), heading: (0, -1), action: left, reward: -9.29558843996
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 24, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -9.295588439959309, &#39;waypoint&#39;: &#39;forward&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: frNNN
Agent attempted driving left through a red light. (rewarded -9.30)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 2
\-------------------------

Environment.reset(): Trial set up with start = (4, 4), destination = (8, 6), deadline = 30
Simulating trial. . . 
epsilon = 0.9000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.9
Environment.act() [POST]: location: (4, 4), heading: (0, -1), action: None, reward: -5.70664488909
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 30, &#39;t&#39;: 0, &#39;action&#39;: None, &#39;reward&#39;: -5.706644889089745, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent idled at a green light with no oncoming traffic. (rewarded -5.71)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.9
Environment.act() [POST]: location: (4, 3), heading: (0, -1), action: forward, reward: 1.11003336749
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 29, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.1100333674856002, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 1.11)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.9
Environment.act() [POST]: location: (3, 3), heading: (-1, 0), action: left, reward: 2.67067159762
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNlN&#39;, &#39;deadline&#39;: 28, &#39;t&#39;: 2, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.6706715976150184, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNlN
Agent followed the waypoint left. (rewarded 2.67)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.9
Environment.act() [POST]: location: (3, 2), heading: (0, -1), action: right, reward: 1.2011514445
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNf&#39;, &#39;deadline&#39;: 27, &#39;t&#39;: 3, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.201151444498012, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNf
Agent drove right instead of forward. (rewarded 1.20)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.9
Environment.act() [POST]: location: (3, 7), heading: (0, -1), action: forward, reward: 1.68468930538
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNll&#39;, &#39;deadline&#39;: 26, &#39;t&#39;: 4, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.6846893053841079, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNll
Agent drove forward instead of left. (rewarded 1.68)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.9
Environment.act() [POST]: location: (3, 7), heading: (0, -1), action: None, reward: 2.0712534387
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNf&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: 2.0712534386998107, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNf
Agent properly idled at a red light. (rewarded 2.07)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.9
Environment.act() [POST]: location: (4, 7), heading: (1, 0), action: right, reward: -0.0618853475354
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 6, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.06188534753537478, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNN
Agent drove right instead of left. (rewarded -0.06)
77% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.9
Environment.act() [POST]: location: (4, 2), heading: (0, 1), action: right, reward: 0.961476296377
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNl&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 7, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.9614762963768607, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNl
Agent drove right instead of left. (rewarded 0.96)
73% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.9
Environment.act() [POST]: location: (4, 2), heading: (0, 1), action: left, reward: -9.86686937279
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 8, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -9.866869372793108, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent attempted driving left through a red light. (rewarded -9.87)
70% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.9
Environment.act() [POST]: location: (4, 2), heading: (0, 1), action: forward, reward: -10.012372543
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.012372543048825, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent attempted driving forward through a red light. (rewarded -10.01)
67% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.9
Environment.act() [POST]: location: (4, 2), heading: (0, 1), action: None, reward: 1.28730567328
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrllN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 10, &#39;action&#39;: None, &#39;reward&#39;: 1.2873056732808184, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrllN
Agent properly idled at a red light. (rewarded 1.29)
63% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.9
Environment.act() [POST]: location: (4, 2), heading: (0, 1), action: None, reward: 1.21840130588
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNl&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 11, &#39;action&#39;: None, &#39;reward&#39;: 1.21840130588176, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNl
Agent idled at a green light with oncoming traffic. (rewarded 1.22)
60% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.9
Environment.act() [POST]: location: (5, 2), heading: (1, 0), action: left, reward: 1.64047471108
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNl&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 12, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.6404747110792868, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNl
Agent drove left instead of right. (rewarded 1.64)
57% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.9
Environment.act() [POST]: location: (5, 3), heading: (0, 1), action: right, reward: 0.492037523223
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 13, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.4920375232227936, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 0.49)
53% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.9
Environment.act() [POST]: location: (4, 3), heading: (-1, 0), action: right, reward: -0.141182048599
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNrN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 14, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.1411820485989681, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNrN
Agent drove right instead of left. (rewarded -0.14)
50% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.9
Environment.act() [POST]: location: (3, 3), heading: (-1, 0), action: forward, reward: 2.49036281889
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgffN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 15, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.4903628188881095, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgffN
Agent followed the waypoint forward. (rewarded 2.49)
47% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.9
Environment.act() [POST]: location: (3, 3), heading: (-1, 0), action: None, reward: 2.63720353947
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 16, &#39;action&#39;: None, &#39;reward&#39;: 2.637203539470695, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.64)
43% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.9
Environment.act() [POST]: location: (2, 3), heading: (-1, 0), action: forward, reward: 2.1775357404
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfNf&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 17, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.177535740398575, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfNf
Agent followed the waypoint forward. (rewarded 2.18)
40% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.9
Environment.act() [POST]: location: (1, 3), heading: (-1, 0), action: forward, reward: 2.00076306077
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 18, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.0007630607691786, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 2.00)
37% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.9
Environment.act() [POST]: location: (1, 2), heading: (0, -1), action: right, reward: 0.998653011303
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNl&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 19, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.9986530113026751, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNl
Agent drove right instead of forward. (rewarded 1.00)
33% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.9
Environment.act() [POST]: location: (2, 2), heading: (1, 0), action: right, reward: 1.10390122954
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 20, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.1039012295444603, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNN
Agent drove right instead of left. (rewarded 1.10)
30% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.9
Environment.act() [POST]: location: (2, 2), heading: (1, 0), action: None, reward: -5.2579230532
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfrN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 21, &#39;action&#39;: None, &#39;reward&#39;: -5.257923053202367, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfrN
Agent idled at a green light with no oncoming traffic. (rewarded -5.26)
27% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.9
Environment.act() [POST]: location: (2, 3), heading: (0, 1), action: right, reward: 0.810028724246
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 22, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.8100287242464783, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent drove right instead of left. (rewarded 0.81)
23% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0.9
Environment.act() [POST]: location: (2, 3), heading: (0, 1), action: forward, reward: -40.5974513636
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNf&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 23, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.59745136355388, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.60)
20% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0.9
Environment.act() [POST]: location: (2, 3), heading: (0, 1), action: forward, reward: -9.67013148945
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 24, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.670131489446433, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent attempted driving forward through a red light. (rewarded -9.67)
17% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Environment.step(): t = 25
0.9
Environment.act() [POST]: location: (3, 3), heading: (1, 0), action: left, reward: 0.804823495551
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 25, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.8048234955511466, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent drove left instead of right. (rewarded 0.80)
13% of time remaining to reach destination.

/-------------------
| Step 26 Results
\-------------------

Environment.step(): t = 26
0.9
Environment.act() [POST]: location: (3, 2), heading: (0, -1), action: left, reward: 0.888303081918
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 26, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.8883030819181006, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 0.89)
10% of time remaining to reach destination.

/-------------------
| Step 27 Results
\-------------------

Environment.step(): t = 27
0.9
Environment.act() [POST]: location: (3, 2), heading: (0, -1), action: forward, reward: -9.75821589838
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 27, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.758215898377921, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent attempted driving forward through a red light. (rewarded -9.76)
7% of time remaining to reach destination.

/-------------------
| Step 28 Results
\-------------------

Environment.step(): t = 28
0.9
Environment.act() [POST]: location: (3, 2), heading: (0, -1), action: left, reward: -10.7222932683
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 28, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.722293268314866, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent attempted driving left through a red light. (rewarded -10.72)
3% of time remaining to reach destination.

/-------------------
| Step 29 Results
\-------------------

Environment.step(): t = 29
0.9
Environment.act() [POST]: location: (3, 2), heading: (0, -1), action: forward, reward: -40.0701772233
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNfN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 29, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.07017722329346, &#39;waypoint&#39;: &#39;left&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: lrNfN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.07)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 3
\-------------------------

Environment.reset(): Trial set up with start = (4, 5), destination = (7, 3), deadline = 25
Simulating trial. . . 
epsilon = 0.8500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.85
Environment.act() [POST]: location: (4, 5), heading: (-1, 0), action: left, reward: -40.1567897718
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNfN&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 0, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -40.15678977175046, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNfN
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -40.16)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.85
Environment.act() [POST]: location: (4, 5), heading: (-1, 0), action: None, reward: 1.62142817167
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNlN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 1, &#39;action&#39;: None, &#39;reward&#39;: 1.6214281716693504, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNlN
Agent properly idled at a red light. (rewarded 1.62)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.85
Environment.act() [POST]: location: (4, 5), heading: (-1, 0), action: forward, reward: -9.51588704632
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.515887046318186, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent attempted driving forward through a red light. (rewarded -9.52)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.85
Environment.act() [POST]: location: (4, 5), heading: (-1, 0), action: left, reward: -10.6658999467
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 3, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.66589994668653, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent attempted driving left through a red light. (rewarded -10.67)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.85
Environment.act() [POST]: location: (4, 5), heading: (-1, 0), action: forward, reward: -10.7120385657
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 4, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.712038565680471, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent attempted driving forward through a red light. (rewarded -10.71)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.85
Environment.act() [POST]: location: (4, 6), heading: (0, 1), action: left, reward: 1.21066239273
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 5, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.2106623927323952, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent drove left instead of right. (rewarded 1.21)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.85
Environment.act() [POST]: location: (4, 6), heading: (0, 1), action: forward, reward: -9.36654798309
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNll&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.36654798309165, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNll
Agent attempted driving forward through a red light. (rewarded -9.37)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.85
Environment.act() [POST]: location: (4, 6), heading: (0, 1), action: None, reward: 1.78096110119
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 7, &#39;action&#39;: None, &#39;reward&#39;: 1.7809611011919895, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.78)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.85
Environment.act() [POST]: location: (4, 6), heading: (0, 1), action: None, reward: 2.54405352177
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrffN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 8, &#39;action&#39;: None, &#39;reward&#39;: 2.544053521774763, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrffN
Agent properly idled at a red light. (rewarded 2.54)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.85
Environment.act() [POST]: location: (3, 6), heading: (-1, 0), action: right, reward: 0.529085498831
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 9, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.5290854988312104, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNN
Agent drove right instead of left. (rewarded 0.53)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.85
Environment.act() [POST]: location: (2, 6), heading: (-1, 0), action: forward, reward: 2.50736769938
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNr&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 10, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.5073676993831544, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNr
Agent followed the waypoint forward. (rewarded 2.51)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.85
Environment.act() [POST]: location: (2, 6), heading: (-1, 0), action: None, reward: 1.86930346842
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 11, &#39;action&#39;: None, &#39;reward&#39;: 1.8693034684173944, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.87)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.85
Environment.act() [POST]: location: (2, 6), heading: (-1, 0), action: None, reward: 1.63094755932
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNfN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 12, &#39;action&#39;: None, &#39;reward&#39;: 1.6309475593170502, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNfN
Agent properly idled at a red light. (rewarded 1.63)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.85
Environment.act() [POST]: location: (2, 6), heading: (-1, 0), action: None, reward: -4.39342653259
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 13, &#39;action&#39;: None, &#39;reward&#39;: -4.393426532593812, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent idled at a green light with no oncoming traffic. (rewarded -4.39)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.85
Environment.act() [POST]: location: (2, 5), heading: (0, -1), action: right, reward: 0.886311316564
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNlN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 14, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.8863113165644542, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNlN
Agent drove right instead of forward. (rewarded 0.89)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.85
Environment.act() [POST]: location: (3, 5), heading: (1, 0), action: right, reward: -0.0360026454958
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 15, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.036002645495765595, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent drove right instead of left. (rewarded -0.04)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.85
Environment.act() [POST]: location: (3, 6), heading: (0, 1), action: right, reward: 0.980909746024
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 16, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.9809097460238786, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent drove right instead of left. (rewarded 0.98)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.85
Environment.act() [POST]: location: (3, 6), heading: (0, 1), action: None, reward: 1.43023264427
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 17, &#39;action&#39;: None, &#39;reward&#39;: 1.4302326442653899, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 1.43)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.85
Environment.act() [POST]: location: (2, 6), heading: (-1, 0), action: right, reward: 1.08596918563
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 18, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.0859691856334133, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent followed the waypoint right. (rewarded 1.09)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.85
Environment.act() [POST]: location: (1, 6), heading: (-1, 0), action: forward, reward: 1.55930685697
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 19, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.5593068569707544, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfNN
Agent followed the waypoint forward. (rewarded 1.56)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.85
Environment.act() [POST]: location: (1, 6), heading: (-1, 0), action: left, reward: -10.5844231213
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 20, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.58442312131339, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent attempted driving left through a red light. (rewarded -10.58)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.85
Environment.act() [POST]: location: (1, 6), heading: (-1, 0), action: forward, reward: -9.34844107468
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 21, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.348441074684233, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent attempted driving forward through a red light. (rewarded -9.35)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.85
Environment.act() [POST]: location: (1, 6), heading: (-1, 0), action: None, reward: -5.22790329345
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNr&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 22, &#39;action&#39;: None, &#39;reward&#39;: -5.227903293452432, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNr
Agent idled at a green light with no oncoming traffic. (rewarded -5.23)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0.85
Environment.act() [POST]: location: (1, 5), heading: (0, -1), action: right, reward: -0.128889037025
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNr&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 23, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.12888903702499266, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNr
Agent drove right instead of forward. (rewarded -0.13)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0.85
Environment.act() [POST]: location: (2, 5), heading: (1, 0), action: right, reward: -0.81568721071
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNl&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 24, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.8156872107104352, &#39;waypoint&#39;: &#39;left&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: lrlNl
Agent drove right instead of left. (rewarded -0.82)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 4
\-------------------------

Environment.reset(): Trial set up with start = (5, 3), destination = (8, 7), deadline = 25
Simulating trial. . . 
epsilon = 0.8000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.8
Environment.act() [POST]: location: (5, 3), heading: (0, -1), action: None, reward: 1.4768152375
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 0, &#39;action&#39;: None, &#39;reward&#39;: 1.476815237498342, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 1.48)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.8
Environment.act() [POST]: location: (5, 3), heading: (0, -1), action: left, reward: -10.9987202254
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 1, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.998720225387684, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent attempted driving left through a red light. (rewarded -11.00)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.8
Environment.act() [POST]: location: (5, 3), heading: (0, -1), action: forward, reward: -40.6066363566
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNfN&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.606636356611595, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNfN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.61)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.8
Environment.act() [POST]: location: (6, 3), heading: (1, 0), action: right, reward: 1.20778356105
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 3, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.2077835610540286, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 1.21)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.8
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: forward, reward: 1.34872327391
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 4, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.3487232739101513, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 1.35)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.8
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: None, reward: -5.11654091282
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: -5.1165409128156725, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent idled at a green light with no oncoming traffic. (rewarded -5.12)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.8
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: None, reward: 0.00862478630694
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 6, &#39;action&#39;: None, &#39;reward&#39;: 0.00862478630694119, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent idled at a green light with oncoming traffic. (rewarded 0.01)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.8
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: None, reward: 1.61172165939
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlr&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 7, &#39;action&#39;: None, &#39;reward&#39;: 1.6117216593915646, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlr
Agent properly idled at a red light. (rewarded 1.61)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.8
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: forward, reward: -9.45183268691
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNl&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 8, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.451832686908169, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNl
Agent attempted driving forward through a red light. (rewarded -9.45)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.8
Environment.act() [POST]: location: (7, 4), heading: (0, 1), action: right, reward: 1.8268847771
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 9, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.826884777100373, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 1.83)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.8
Environment.act() [POST]: location: (6, 4), heading: (-1, 0), action: right, reward: 1.11974945863
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 10, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.1197494586332555, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent drove right instead of left. (rewarded 1.12)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.8
Environment.act() [POST]: location: (6, 3), heading: (0, -1), action: right, reward: 1.88543641755
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 11, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.8854364175541345, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 1.89)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.8
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: right, reward: 0.833058582683
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 12, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.8330585826825654, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent followed the waypoint right. (rewarded 0.83)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.8
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: None, reward: -4.66172327177
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNrN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 13, &#39;action&#39;: None, &#39;reward&#39;: -4.661723271773822, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNrN
Agent idled at a green light with no oncoming traffic. (rewarded -4.66)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.8
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: None, reward: -4.79933252147
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNlf&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 14, &#39;action&#39;: None, &#39;reward&#39;: -4.799332521468682, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNlf
Agent idled at a green light with no oncoming traffic. (rewarded -4.80)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.8
Environment.act() [POST]: location: (7, 4), heading: (0, 1), action: right, reward: 1.35632878669
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlf&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 15, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.3563287866947593, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlf
Agent drove right instead of forward. (rewarded 1.36)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.8
Environment.act() [POST]: location: (7, 5), heading: (0, 1), action: forward, reward: 1.28544457657
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNf&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 16, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.28544457656501, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNf
Agent drove forward instead of left. (rewarded 1.29)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.8
Environment.act() [POST]: location: (7, 5), heading: (0, 1), action: None, reward: -5.45551661569
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNlN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 17, &#39;action&#39;: None, &#39;reward&#39;: -5.455516615690571, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNlN
Agent idled at a green light with no oncoming traffic. (rewarded -5.46)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.8
Environment.act() [POST]: location: (8, 5), heading: (1, 0), action: left, reward: 0.998743425951
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNlN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 18, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.9987434259514161, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNlN
Agent followed the waypoint left. (rewarded 1.00)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.8
Environment.act() [POST]: location: (1, 5), heading: (1, 0), action: forward, reward: 1.43442963145
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgrNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 19, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.4344296314508291, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgrNN
Agent drove forward instead of right. (rewarded 1.43)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.8
Environment.act() [POST]: location: (2, 5), heading: (1, 0), action: forward, reward: 0.221751595042
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNlN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 20, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.22175159504204145, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNlN
Agent drove forward instead of right. (rewarded 0.22)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.8
Environment.act() [POST]: location: (2, 6), heading: (0, 1), action: right, reward: 0.855948068363
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgfNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 21, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.8559480683625871, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgfNN
Agent followed the waypoint right. (rewarded 0.86)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.8
Environment.act() [POST]: location: (2, 6), heading: (0, 1), action: None, reward: -4.36835554429
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 22, &#39;action&#39;: None, &#39;reward&#39;: -4.368355544287559, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent idled at a green light with no oncoming traffic. (rewarded -4.37)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0.8
Environment.act() [POST]: location: (1, 6), heading: (-1, 0), action: right, reward: 0.754084780383
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgrNf&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 23, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.7540847803834447, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgrNf
Agent followed the waypoint right. (rewarded 0.75)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0.8
Environment.act() [POST]: location: (1, 5), heading: (0, -1), action: right, reward: 0.0462760326926
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgllf&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 24, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.04627603269257197, &#39;waypoint&#39;: &#39;forward&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: fgllf
Agent drove right instead of forward. (rewarded 0.05)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 5
\-------------------------

Environment.reset(): Trial set up with start = (3, 2), destination = (7, 6), deadline = 30
Simulating trial. . . 
epsilon = 0.7500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.75
Environment.act() [POST]: location: (2, 2), heading: (-1, 0), action: right, reward: 1.28768615232
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 30, &#39;t&#39;: 0, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.2876861523211118, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent followed the waypoint right. (rewarded 1.29)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.75
Environment.act() [POST]: location: (1, 2), heading: (-1, 0), action: forward, reward: 2.76780689619
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 29, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.767806896190413, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 2.77)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.75
Environment.act() [POST]: location: (1, 2), heading: (-1, 0), action: forward, reward: -10.6381346101
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNN&#39;, &#39;deadline&#39;: 28, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.638134610136976, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNN
Agent attempted driving forward through a red light. (rewarded -10.64)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.75
Environment.act() [POST]: location: (1, 7), heading: (0, -1), action: right, reward: 0.719355302444
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNN&#39;, &#39;deadline&#39;: 27, &#39;t&#39;: 3, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.7193553024439255, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNN
Agent drove right instead of forward. (rewarded 0.72)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.75
Environment.act() [POST]: location: (1, 6), heading: (0, -1), action: forward, reward: 0.282327403478
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNl&#39;, &#39;deadline&#39;: 26, &#39;t&#39;: 4, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.28232740347773577, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNl
Agent drove forward instead of left. (rewarded 0.28)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.75
Environment.act() [POST]: location: (1, 6), heading: (0, -1), action: left, reward: -10.3918241147
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 5, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.391824114653305, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent attempted driving left through a red light. (rewarded -10.39)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.75
Environment.act() [POST]: location: (1, 6), heading: (0, -1), action: left, reward: -40.7869280413
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNfN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 6, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -40.78692804130972, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNfN
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -40.79)
77% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.75
Environment.act() [POST]: location: (8, 6), heading: (-1, 0), action: left, reward: 1.84218887886
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 7, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.842188878860801, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 1.84)
73% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.75
Environment.act() [POST]: location: (8, 6), heading: (-1, 0), action: None, reward: -5.38500641547
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNlN&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 8, &#39;action&#39;: None, &#39;reward&#39;: -5.385006415466827, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNlN
Agent idled at a green light with no oncoming traffic. (rewarded -5.39)
70% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.75
Environment.act() [POST]: location: (8, 6), heading: (-1, 0), action: None, reward: 1.25712215026
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frllf&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 9, &#39;action&#39;: None, &#39;reward&#39;: 1.2571221502643406, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frllf
Agent properly idled at a red light. (rewarded 1.26)
67% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.75
Environment.act() [POST]: location: (8, 6), heading: (-1, 0), action: None, reward: 1.41822909371
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frllf&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 10, &#39;action&#39;: None, &#39;reward&#39;: 1.4182290937109452, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frllf
Agent properly idled at a red light. (rewarded 1.42)
63% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.75
Environment.act() [POST]: location: (8, 6), heading: (-1, 0), action: None, reward: 1.55353340846
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frllN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 11, &#39;action&#39;: None, &#39;reward&#39;: 1.5535334084562151, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frllN
Agent properly idled at a red light. (rewarded 1.55)
60% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.75
Environment.act() [POST]: location: (8, 6), heading: (-1, 0), action: left, reward: -9.14224415299
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 12, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -9.142244152989907, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent attempted driving left through a red light. (rewarded -9.14)
57% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.75
Environment.act() [POST]: location: (8, 5), heading: (0, -1), action: right, reward: 1.8088044313
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglff&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 13, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.8088044312951719, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglff
Agent drove right instead of forward. (rewarded 1.81)
53% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.75
Environment.act() [POST]: location: (8, 5), heading: (0, -1), action: left, reward: -10.5524110472
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 14, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.55241104724109, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent attempted driving left through a red light. (rewarded -10.55)
50% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.75
Environment.act() [POST]: location: (8, 5), heading: (0, -1), action: forward, reward: -40.5777475897
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNf&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 15, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.57774758969178, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.58)
47% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.75
Environment.act() [POST]: location: (1, 5), heading: (1, 0), action: right, reward: 1.40478029893
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 16, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.4047802989295248, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent drove right instead of left. (rewarded 1.40)
43% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.75
Environment.act() [POST]: location: (1, 5), heading: (1, 0), action: left, reward: -39.4472119143
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNf&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 17, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -39.44721191427695, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNf
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -39.45)
40% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.75
Environment.act() [POST]: location: (1, 5), heading: (1, 0), action: forward, reward: -9.4709613169
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 18, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.470961316901509, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent attempted driving forward through a red light. (rewarded -9.47)
37% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.75
Environment.act() [POST]: location: (2, 5), heading: (1, 0), action: forward, reward: 0.59361876299
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 19, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.5936187629900288, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent drove forward instead of right. (rewarded 0.59)
33% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.75
Environment.act() [POST]: location: (2, 5), heading: (1, 0), action: forward, reward: -10.3917011226
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 20, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.391701122607794, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent attempted driving forward through a red light. (rewarded -10.39)
30% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.75
Environment.act() [POST]: location: (2, 6), heading: (0, 1), action: right, reward: 0.820017370826
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 21, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.8200173708262526, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent followed the waypoint right. (rewarded 0.82)
27% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.75
Environment.act() [POST]: location: (3, 6), heading: (1, 0), action: left, reward: -0.46727667916
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 22, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -0.46727667915951754, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent drove left instead of right. (rewarded -0.47)
23% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0.75
Environment.act() [POST]: location: (3, 6), heading: (1, 0), action: None, reward: 1.72109832775
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrrNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 23, &#39;action&#39;: None, &#39;reward&#39;: 1.7210983277522496, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrrNN
Agent properly idled at a red light. (rewarded 1.72)
20% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0.75
Environment.act() [POST]: location: (3, 6), heading: (1, 0), action: forward, reward: -9.03402164614
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 24, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.034021646136033, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent attempted driving forward through a red light. (rewarded -9.03)
17% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Environment.step(): t = 25
0.75
Environment.act() [POST]: location: (3, 6), heading: (1, 0), action: forward, reward: -10.2231609615
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 25, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.223160961459355, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent attempted driving forward through a red light. (rewarded -10.22)
13% of time remaining to reach destination.

/-------------------
| Step 26 Results
\-------------------

Environment.step(): t = 26
0.75
Environment.act() [POST]: location: (3, 7), heading: (0, 1), action: right, reward: 1.65160433213
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 26, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.6516043321273128, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 1.65)
10% of time remaining to reach destination.

/-------------------
| Step 27 Results
\-------------------

Environment.step(): t = 27
0.75
Environment.act() [POST]: location: (3, 7), heading: (0, 1), action: forward, reward: -9.94531186969
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNrN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 27, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.945311869693654, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNrN
Agent attempted driving forward through a red light. (rewarded -9.95)
7% of time remaining to reach destination.

/-------------------
| Step 28 Results
\-------------------

Environment.step(): t = 28
0.75
Environment.act() [POST]: location: (2, 7), heading: (-1, 0), action: right, reward: 1.02196070266
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 28, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.021960702663977, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent followed the waypoint right. (rewarded 1.02)
3% of time remaining to reach destination.

/-------------------
| Step 29 Results
\-------------------

Environment.step(): t = 29
0.75
Environment.act() [POST]: location: (2, 7), heading: (-1, 0), action: None, reward: 1.60235494056
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNfN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 29, &#39;action&#39;: None, &#39;reward&#39;: 1.6023549405556377, &#39;waypoint&#39;: &#39;forward&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: frNfN
Agent properly idled at a red light. (rewarded 1.60)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 6
\-------------------------

Environment.reset(): Trial set up with start = (5, 3), destination = (3, 6), deadline = 25
Simulating trial. . . 
epsilon = 0.7000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.7
Environment.act() [POST]: location: (4, 3), heading: (-1, 0), action: forward, reward: 1.26331565675
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNlr&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.2633156567525001, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNlr
Agent followed the waypoint forward. (rewarded 1.26)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.7
Environment.act() [POST]: location: (4, 2), heading: (0, -1), action: right, reward: 1.10276942248
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNl&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 1, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.1027694224811286, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNl
Agent drove right instead of forward. (rewarded 1.10)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.7
Environment.act() [POST]: location: (4, 2), heading: (0, -1), action: None, reward: -5.79507702323
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNff&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 2, &#39;action&#39;: None, &#39;reward&#39;: -5.795077023234179, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNff
Agent idled at a green light with no oncoming traffic. (rewarded -5.80)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.7
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: forward, reward: 0.575479004204
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNff&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 3, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.5754790042041316, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNff
Agent drove forward instead of left. (rewarded 0.58)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.7
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: forward, reward: -40.0410330415
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNff&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 4, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.041033041488404, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNff
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.04)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.7
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: None, reward: 2.89057739766
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: 2.8905773976597953, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.89)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.7
Environment.act() [POST]: location: (5, 7), heading: (1, 0), action: right, reward: 1.66113158843
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 6, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.6611315884311533, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent drove right instead of left. (rewarded 1.66)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.7
Environment.act() [POST]: location: (5, 7), heading: (1, 0), action: forward, reward: -40.8093591824
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNlf&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 7, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.809359182445576, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNlf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.81)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.7
Environment.act() [POST]: location: (5, 2), heading: (0, 1), action: right, reward: 0.373989274946
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNlf&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.3739892749457022, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNlf
Agent drove right instead of left. (rewarded 0.37)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.7
Environment.act() [POST]: location: (5, 3), heading: (0, 1), action: forward, reward: 0.95484234265
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNfN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.9548423426501784, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNfN
Agent drove forward instead of right. (rewarded 0.95)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.7
Environment.act() [POST]: location: (4, 3), heading: (-1, 0), action: right, reward: 1.50191591232
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 10, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.501915912317388, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent followed the waypoint right. (rewarded 1.50)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.7
Environment.act() [POST]: location: (4, 3), heading: (-1, 0), action: left, reward: -10.5198163196
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 11, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.519816319587951, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent attempted driving left through a red light. (rewarded -10.52)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.7
Environment.act() [POST]: location: (4, 3), heading: (-1, 0), action: forward, reward: -39.503648004
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlfN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 12, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.50364800404262, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlfN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.50)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.7
Environment.act() [POST]: location: (3, 3), heading: (-1, 0), action: forward, reward: 1.60001709379
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNl&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.600017093787568, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNl
Agent followed the waypoint forward. (rewarded 1.60)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.7
Environment.act() [POST]: location: (3, 3), heading: (-1, 0), action: left, reward: -10.010515489
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNr&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 14, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.010515489020388, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNr
Agent attempted driving left through a red light. (rewarded -10.01)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.7
Environment.act() [POST]: location: (3, 3), heading: (-1, 0), action: None, reward: 1.66102678642
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 15, &#39;action&#39;: None, &#39;reward&#39;: 1.6610267864165973, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 1.66)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.7
Environment.act() [POST]: location: (3, 2), heading: (0, -1), action: right, reward: 1.29966390303
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 16, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.2996639030302841, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfNN
Agent followed the waypoint right. (rewarded 1.30)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.7
Environment.act() [POST]: location: (3, 2), heading: (0, -1), action: left, reward: -10.6106437066
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNrl&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 17, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.610643706573661, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNrl
Agent attempted driving left through a red light. (rewarded -10.61)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.7
Environment.act() [POST]: location: (3, 2), heading: (0, -1), action: forward, reward: -9.73049657535
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 18, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.730496575354449, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent attempted driving forward through a red light. (rewarded -9.73)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.7
Environment.act() [POST]: location: (3, 2), heading: (0, -1), action: right, reward: -19.024772653
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 3, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNfN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 19, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -19.024772652959744, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNfN
Agent attempted driving right through traffic and cause a minor accident. (rewarded -19.02)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.7
Environment.act() [POST]: location: (3, 2), heading: (0, -1), action: forward, reward: -40.0863344994
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNf&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 20, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.08633449935807, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.09)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.7
Environment.act() [POST]: location: (3, 7), heading: (0, -1), action: forward, reward: 0.737461880505
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 21, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.737461880504974, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 0.74)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.7
Environment.act() [POST]: location: (3, 7), heading: (0, -1), action: forward, reward: -10.0361413765
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frrNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 22, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.036141376489395, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frrNN
Agent attempted driving forward through a red light. (rewarded -10.04)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0.7
Environment.act() [POST]: location: (3, 7), heading: (0, -1), action: None, reward: 0.44732805946
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 23, &#39;action&#39;: None, &#39;reward&#39;: 0.44732805945995935, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 0.45)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0.7
Environment.act() [POST]: location: (3, 7), heading: (0, -1), action: left, reward: -10.0092448031
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 24, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.00924480313056, &#39;waypoint&#39;: &#39;forward&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: frNNN
Agent attempted driving left through a red light. (rewarded -10.01)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 7
\-------------------------

Environment.reset(): Trial set up with start = (7, 6), destination = (1, 4), deadline = 20
Simulating trial. . . 
epsilon = 0.6500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.65
Environment.act() [POST]: location: (6, 6), heading: (-1, 0), action: forward, reward: 1.60803819038
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNlN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.6080381903843193, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNlN
Agent drove forward instead of right. (rewarded 1.61)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.65
Environment.act() [POST]: location: (6, 6), heading: (-1, 0), action: None, reward: -5.36093259836
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNfl&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: None, &#39;reward&#39;: -5.360932598357397, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNfl
Agent idled at a green light with no oncoming traffic. (rewarded -5.36)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.65
Environment.act() [POST]: location: (6, 7), heading: (0, 1), action: left, reward: 0.0579966160624
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNfl&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.05799661606241957, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNfl
Agent drove left instead of right. (rewarded 0.06)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.65
Environment.act() [POST]: location: (5, 7), heading: (-1, 0), action: right, reward: 0.862161873801
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrrNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.8621618738007907, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrrNN
Agent drove right instead of left. (rewarded 0.86)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.65
Environment.act() [POST]: location: (5, 2), heading: (0, 1), action: left, reward: 2.90520385675
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.905203856746083, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 2.91)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.65
Environment.act() [POST]: location: (5, 2), heading: (0, 1), action: None, reward: 1.59723848953
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: 1.5972384895307719, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.60)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.65
Environment.act() [POST]: location: (5, 2), heading: (0, 1), action: None, reward: 2.67723332962
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: None, &#39;reward&#39;: 2.6772333296161426, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.68)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.65
Environment.act() [POST]: location: (4, 2), heading: (-1, 0), action: right, reward: 1.50848158812
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.508481588118593, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNN
Agent drove right instead of left. (rewarded 1.51)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.65
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: right, reward: 0.00315523009215
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNf&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.0031552300921530163, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNf
Agent drove right instead of forward. (rewarded 0.00)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.65
Environment.act() [POST]: location: (4, 6), heading: (0, -1), action: forward, reward: 0.745352330838
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNr&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.7453523308377115, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNr
Agent drove forward instead of left. (rewarded 0.75)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.65
Environment.act() [POST]: location: (4, 6), heading: (0, -1), action: None, reward: -5.95453096532
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNff&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: None, &#39;reward&#39;: -5.954530965322377, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNff
Agent idled at a green light with no oncoming traffic. (rewarded -5.95)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.65
Environment.act() [POST]: location: (4, 6), heading: (0, -1), action: left, reward: -39.1929577564
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfff&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -39.19295775639665, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfff
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -39.19)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.65
Environment.act() [POST]: location: (5, 6), heading: (1, 0), action: right, reward: 0.022347436475
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfrN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.02234743647495896, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfrN
Agent drove right instead of left. (rewarded 0.02)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.65
Environment.act() [POST]: location: (5, 7), heading: (0, 1), action: right, reward: 0.625761142707
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglfN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.6257611427072932, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglfN
Agent drove right instead of forward. (rewarded 0.63)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.65
Environment.act() [POST]: location: (5, 2), heading: (0, 1), action: forward, reward: -0.270353060001
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNf&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 14, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -0.2703530600012195, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNf
Agent drove forward instead of left. (rewarded -0.27)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.65
Environment.act() [POST]: location: (5, 2), heading: (0, 1), action: left, reward: -10.8014763623
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 15, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.80147636233818, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent attempted driving left through a red light. (rewarded -10.80)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.65
Environment.act() [POST]: location: (5, 2), heading: (0, 1), action: None, reward: 2.0060526154
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 16, &#39;action&#39;: None, &#39;reward&#39;: 2.0060526153972855, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.01)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.65
Environment.act() [POST]: location: (5, 3), heading: (0, 1), action: forward, reward: -0.408138767998
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNll&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 17, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -0.4081387679976701, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNll
Agent drove forward instead of left. (rewarded -0.41)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.65
Environment.act() [POST]: location: (4, 3), heading: (-1, 0), action: right, reward: 1.20812428143
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 18, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.2081242814272686, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent drove right instead of left. (rewarded 1.21)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.65
Environment.act() [POST]: location: (4, 3), heading: (-1, 0), action: forward, reward: -9.51823831711
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 19, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.51823831710959, &#39;waypoint&#39;: &#39;forward&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: frNNN
Agent attempted driving forward through a red light. (rewarded -9.52)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 8
\-------------------------

Environment.reset(): Trial set up with start = (3, 2), destination = (8, 5), deadline = 30
Simulating trial. . . 
epsilon = 0.6000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.6
Environment.act() [POST]: location: (4, 2), heading: (1, 0), action: forward, reward: 1.65530601944
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNll&#39;, &#39;deadline&#39;: 30, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.6553060194368985, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNll
Agent drove forward instead of left. (rewarded 1.66)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.6
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: left, reward: 2.57173568887
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNlN&#39;, &#39;deadline&#39;: 29, &#39;t&#39;: 1, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.571735688872253, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNlN
Agent followed the waypoint left. (rewarded 2.57)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.6
Environment.act() [POST]: location: (5, 7), heading: (1, 0), action: right, reward: 1.18271095356
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNlN&#39;, &#39;deadline&#39;: 28, &#39;t&#39;: 2, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.1827109535625104, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNlN
Agent drove right instead of left. (rewarded 1.18)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.6
Environment.act() [POST]: location: (5, 7), heading: (1, 0), action: None, reward: 2.81819051889
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNr&#39;, &#39;deadline&#39;: 27, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 2.8181905188944825, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNr
Agent properly idled at a red light. (rewarded 2.82)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.6
Environment.act() [POST]: location: (6, 7), heading: (1, 0), action: forward, reward: 1.33686642303
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfNN&#39;, &#39;deadline&#39;: 26, &#39;t&#39;: 4, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.336866423029334, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfNN
Agent followed the waypoint forward. (rewarded 1.34)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.6
Environment.act() [POST]: location: (6, 2), heading: (0, 1), action: right, reward: 0.961401778945
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNl&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 5, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.9614017789450132, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNl
Agent drove right instead of forward. (rewarded 0.96)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.6
Environment.act() [POST]: location: (6, 2), heading: (0, 1), action: forward, reward: -10.7020214237
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNr&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.702021423707688, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNr
Agent attempted driving forward through a red light. (rewarded -10.70)
77% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.6
Environment.act() [POST]: location: (5, 2), heading: (-1, 0), action: right, reward: 1.35995255353
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 7, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.359952553532123, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent drove right instead of left. (rewarded 1.36)
73% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.6
Environment.act() [POST]: location: (5, 2), heading: (-1, 0), action: None, reward: 0.321662535047
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 8, &#39;action&#39;: None, &#39;reward&#39;: 0.321662535046929, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent idled at a green light with oncoming traffic. (rewarded 0.32)
70% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.6
Environment.act() [POST]: location: (5, 7), heading: (0, -1), action: right, reward: 2.59041918357
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 9, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.5904191835716874, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent followed the waypoint right. (rewarded 2.59)
67% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.6
Environment.act() [POST]: location: (5, 7), heading: (0, -1), action: forward, reward: -9.99626895815
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfNl&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 10, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.9962689581455, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfNl
Agent attempted driving forward through a red light. (rewarded -10.00)
63% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.6
Environment.act() [POST]: location: (5, 7), heading: (0, -1), action: left, reward: -10.9556435761
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 11, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.95564357612455, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfNN
Agent attempted driving left through a red light. (rewarded -10.96)
60% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.6
Environment.act() [POST]: location: (6, 7), heading: (1, 0), action: right, reward: 0.873303736514
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNr&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 12, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.8733037365138081, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNr
Agent followed the waypoint right. (rewarded 0.87)
57% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.6
Environment.act() [POST]: location: (6, 7), heading: (1, 0), action: None, reward: 1.19492571218
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNfN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 13, &#39;action&#39;: None, &#39;reward&#39;: 1.194925712179627, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNfN
Agent properly idled at a red light. (rewarded 1.19)
53% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.6
Environment.act() [POST]: location: (6, 7), heading: (1, 0), action: forward, reward: -9.56762946144
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 14, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.567629461435454, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlN
Agent attempted driving forward through a red light. (rewarded -9.57)
50% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.6
Environment.act() [POST]: location: (6, 7), heading: (1, 0), action: forward, reward: -10.9693032388
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 15, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.969303238805239, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent attempted driving forward through a red light. (rewarded -10.97)
47% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.6
Environment.act() [POST]: location: (7, 7), heading: (1, 0), action: forward, reward: 2.0094281186
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 16, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.0094281185984286, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 2.01)
43% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.6
Environment.act() [POST]: location: (7, 2), heading: (0, 1), action: right, reward: 1.13586992027
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 17, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.1358699202672866, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 1.14)
40% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.6
Environment.act() [POST]: location: (7, 2), heading: (0, 1), action: left, reward: -40.7015735801
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNfN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 18, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -40.701573580139076, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNfN
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -40.70)
37% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.6
Environment.act() [POST]: location: (7, 3), heading: (0, 1), action: forward, reward: 1.46806081248
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNl&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 19, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.4680608124830061, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNl
Agent drove forward instead of left. (rewarded 1.47)
33% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.6
Environment.act() [POST]: location: (7, 3), heading: (0, 1), action: None, reward: 1.63748967223
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNl&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 20, &#39;action&#39;: None, &#39;reward&#39;: 1.6374896722268382, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNl
Agent properly idled at a red light. (rewarded 1.64)
30% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.6
Environment.act() [POST]: location: (7, 4), heading: (0, 1), action: forward, reward: 1.11071091376
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 21, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.110710913755565, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNN
Agent drove forward instead of left. (rewarded 1.11)
27% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.6
Environment.act() [POST]: location: (7, 5), heading: (0, 1), action: forward, reward: 1.48730024651
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNfN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 22, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.4873002465146656, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNfN
Agent drove forward instead of left. (rewarded 1.49)
23% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0.6
Environment.act() [POST]: location: (6, 5), heading: (-1, 0), action: right, reward: 0.202311862429
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 23, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.20231186242884147, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent drove right instead of left. (rewarded 0.20)
20% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0.6
Environment.act() [POST]: location: (6, 4), heading: (0, -1), action: right, reward: 0.842611414764
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 24, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.8426114147635759, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent followed the waypoint right. (rewarded 0.84)
17% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Environment.step(): t = 25
0.6
Environment.act() [POST]: location: (6, 4), heading: (0, -1), action: forward, reward: -10.7196738683
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfNl&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 25, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.719673868336809, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfNl
Agent attempted driving forward through a red light. (rewarded -10.72)
13% of time remaining to reach destination.

/-------------------
| Step 26 Results
\-------------------

Environment.step(): t = 26
0.6
Environment.act() [POST]: location: (6, 4), heading: (0, -1), action: forward, reward: -10.3494665606
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 26, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.349466560557481, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfNN
Agent attempted driving forward through a red light. (rewarded -10.35)
10% of time remaining to reach destination.

/-------------------
| Step 27 Results
\-------------------

Environment.step(): t = 27
0.6
Environment.act() [POST]: location: (7, 4), heading: (1, 0), action: right, reward: 1.34169798565
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 27, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.3416979856462419, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfNN
Agent followed the waypoint right. (rewarded 1.34)
7% of time remaining to reach destination.

/-------------------
| Step 28 Results
\-------------------

Environment.step(): t = 28
0.6
Environment.act() [POST]: location: (8, 4), heading: (1, 0), action: forward, reward: 1.12008032301
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgffN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 28, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.1200803230074996, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgffN
Agent followed the waypoint forward. (rewarded 1.12)
3% of time remaining to reach destination.

/-------------------
| Step 29 Results
\-------------------

Environment.step(): t = 29
0.6
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (8, 5), heading: (0, 1), action: right, reward: 1.81244223081
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 29, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.8124422308090393, &#39;waypoint&#39;: &#39;right&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: rrlNN
Agent followed the waypoint right. (rewarded 1.81)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 9
\-------------------------

Environment.reset(): Trial set up with start = (7, 4), destination = (3, 3), deadline = 25
Simulating trial. . . 
epsilon = 0.5500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.55
Environment.act() [POST]: location: (7, 5), heading: (0, 1), action: forward, reward: 1.33227785241
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNN&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.332277852405864, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNN
Agent drove forward instead of left. (rewarded 1.33)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.55
Environment.act() [POST]: location: (6, 5), heading: (-1, 0), action: right, reward: 1.37583585186
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 1, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.3758358518649394, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent drove right instead of left. (rewarded 1.38)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.55
Environment.act() [POST]: location: (6, 5), heading: (-1, 0), action: forward, reward: -10.271401108
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frrNr&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.271401108007613, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frrNr
Agent attempted driving forward through a red light. (rewarded -10.27)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.55
Environment.act() [POST]: location: (6, 4), heading: (0, -1), action: right, reward: 1.53280703319
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNN&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 3, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.5328070331872015, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNN
Agent drove right instead of forward. (rewarded 1.53)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.55
Environment.act() [POST]: location: (7, 4), heading: (1, 0), action: right, reward: 0.95740885199
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 4, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.9574088519897058, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent drove right instead of left. (rewarded 0.96)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.55
Environment.act() [POST]: location: (7, 5), heading: (0, 1), action: right, reward: 0.388424592007
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 5, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.38842459200691415, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlN
Agent drove right instead of forward. (rewarded 0.39)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.55
Environment.act() [POST]: location: (7, 5), heading: (0, 1), action: forward, reward: -40.6773531665
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNfr&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.67735316651753, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNfr
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.68)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.55
Environment.act() [POST]: location: (7, 5), heading: (0, 1), action: None, reward: -4.47263332315
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 7, &#39;action&#39;: None, &#39;reward&#39;: -4.472633323152169, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent idled at a green light with no oncoming traffic. (rewarded -4.47)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.55
Environment.act() [POST]: location: (6, 5), heading: (-1, 0), action: right, reward: 0.890845035824
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.8908450358241434, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNN
Agent drove right instead of left. (rewarded 0.89)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.55
Environment.act() [POST]: location: (6, 5), heading: (-1, 0), action: None, reward: 1.05264395436
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNfN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 9, &#39;action&#39;: None, &#39;reward&#39;: 1.0526439543611115, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNfN
Agent properly idled at a red light. (rewarded 1.05)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.55
Environment.act() [POST]: location: (6, 5), heading: (-1, 0), action: left, reward: -40.2795522163
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frffN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 10, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -40.27955221632993, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frffN
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -40.28)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.55
Environment.act() [POST]: location: (6, 5), heading: (-1, 0), action: forward, reward: -10.0748482318
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 11, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.074848231822205, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNN
Agent attempted driving forward through a red light. (rewarded -10.07)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.55
Environment.act() [POST]: location: (6, 5), heading: (-1, 0), action: None, reward: 2.61661739988
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfrN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 12, &#39;action&#39;: None, &#39;reward&#39;: 2.6166173998781272, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfrN
Agent properly idled at a red light. (rewarded 2.62)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.55
Environment.act() [POST]: location: (6, 4), heading: (0, -1), action: right, reward: 1.07466885247
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfNN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 13, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.074668852471792, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfNN
Agent drove right instead of forward. (rewarded 1.07)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.55
Environment.act() [POST]: location: (7, 4), heading: (1, 0), action: right, reward: 0.581491356607
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 14, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.5814913566068297, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent drove right instead of left. (rewarded 0.58)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.55
Environment.act() [POST]: location: (7, 5), heading: (0, 1), action: right, reward: 1.37760637968
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNl&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 15, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.3776063796764213, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNl
Agent drove right instead of forward. (rewarded 1.38)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.55
Environment.act() [POST]: location: (6, 5), heading: (-1, 0), action: right, reward: 1.23993152049
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 16, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.2399315204940446, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNN
Agent drove right instead of left. (rewarded 1.24)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.55
Environment.act() [POST]: location: (6, 4), heading: (0, -1), action: right, reward: -0.0688617313047
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNl&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 17, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.06886173130466422, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNl
Agent drove right instead of forward. (rewarded -0.07)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.55
Environment.act() [POST]: location: (6, 4), heading: (0, -1), action: left, reward: -40.8876482545
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrrNf&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 18, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -40.88764825446685, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrrNf
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -40.89)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.55
Environment.act() [POST]: location: (6, 3), heading: (0, -1), action: forward, reward: 0.0175169506656
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgrNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 19, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.017516950665609543, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgrNN
Agent drove forward instead of left. (rewarded 0.02)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.55
Environment.act() [POST]: location: (6, 2), heading: (0, -1), action: forward, reward: -0.137876558988
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNr&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 20, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -0.1378765589875437, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNr
Agent drove forward instead of left. (rewarded -0.14)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.55
Environment.act() [POST]: location: (7, 2), heading: (1, 0), action: right, reward: 1.01230443159
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 21, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.012304431589202, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent drove right instead of left. (rewarded 1.01)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.55
Environment.act() [POST]: location: (8, 2), heading: (1, 0), action: forward, reward: 0.896158688547
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 22, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.8961586885469173, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 0.90)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0.55
Environment.act() [POST]: location: (8, 2), heading: (1, 0), action: None, reward: -5.16751791831
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgrNN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 23, &#39;action&#39;: None, &#39;reward&#39;: -5.167517918312077, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgrNN
Agent idled at a green light with no oncoming traffic. (rewarded -5.17)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0.55
Environment.act() [POST]: location: (1, 2), heading: (1, 0), action: forward, reward: 2.09376160872
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 24, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.0937616087168056, &#39;waypoint&#39;: &#39;forward&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 2.09)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 10
\-------------------------

Environment.reset(): Trial set up with start = (2, 6), destination = (7, 3), deadline = 30
Simulating trial. . . 
epsilon = 0.5000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.5
Environment.act() [POST]: location: (2, 6), heading: (0, 1), action: forward, reward: -39.48059123
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrrlf&#39;, &#39;deadline&#39;: 30, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.480591230015534, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrrlf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.48)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.5
Environment.act() [POST]: location: (2, 6), heading: (0, 1), action: None, reward: 2.38355073578
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 29, &#39;t&#39;: 1, &#39;action&#39;: None, &#39;reward&#39;: 2.3835507357776815, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 2.38)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.5
Environment.act() [POST]: location: (2, 6), heading: (0, 1), action: forward, reward: -9.35019305375
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNl&#39;, &#39;deadline&#39;: 28, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.350193053745137, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNl
Agent attempted driving forward through a red light. (rewarded -9.35)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.5
Environment.act() [POST]: location: (2, 6), heading: (0, 1), action: None, reward: 1.8507894833
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlrl&#39;, &#39;deadline&#39;: 27, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 1.8507894832989105, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlrl
Agent properly idled at a red light. (rewarded 1.85)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.5
Environment.act() [POST]: location: (3, 6), heading: (1, 0), action: left, reward: 1.61284168571
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 26, &#39;t&#39;: 4, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.6128416857123704, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent drove left instead of right. (rewarded 1.61)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.5
Environment.act() [POST]: location: (4, 6), heading: (1, 0), action: forward, reward: 0.0849836554589
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNll&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 5, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.08498365545893771, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNll
Agent drove forward instead of right. (rewarded 0.08)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.5
Environment.act() [POST]: location: (4, 6), heading: (1, 0), action: None, reward: 2.65034963955
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNl&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 6, &#39;action&#39;: None, &#39;reward&#39;: 2.650349639552001, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNl
Agent properly idled at a red light. (rewarded 2.65)
77% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.5
Environment.act() [POST]: location: (4, 6), heading: (1, 0), action: None, reward: 1.6724698029
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 7, &#39;action&#39;: None, &#39;reward&#39;: 1.6724698028984164, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.67)
73% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.5
Environment.act() [POST]: location: (4, 6), heading: (1, 0), action: None, reward: 2.85546852839
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNr&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 8, &#39;action&#39;: None, &#39;reward&#39;: 2.855468528385072, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNr
Agent properly idled at a red light. (rewarded 2.86)
70% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.5
Environment.act() [POST]: location: (4, 7), heading: (0, 1), action: right, reward: 0.521198982248
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlN&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 9, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.5211989822481766, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlN
Agent drove right instead of forward. (rewarded 0.52)
67% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.5
Environment.act() [POST]: location: (3, 7), heading: (-1, 0), action: right, reward: 0.548008339888
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 10, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.5480083398879789, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent drove right instead of left. (rewarded 0.55)
63% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.5
Environment.act() [POST]: location: (3, 6), heading: (0, -1), action: right, reward: 0.820348848506
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfrN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 11, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.8203488485058444, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfrN
Agent drove right instead of forward. (rewarded 0.82)
60% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.5
Environment.act() [POST]: location: (4, 6), heading: (1, 0), action: right, reward: 1.43014432233
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNf&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 12, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.4301443223326755, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNf
Agent drove right instead of left. (rewarded 1.43)
57% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.5
Environment.act() [POST]: location: (5, 6), heading: (1, 0), action: forward, reward: 2.54442900286
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNll&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.5444290028635663, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNll
Agent followed the waypoint forward. (rewarded 2.54)
53% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.5
Environment.act() [POST]: location: (5, 5), heading: (0, -1), action: left, reward: 1.22732663614
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNlN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 14, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.2273266361419917, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNlN
Agent drove left instead of forward. (rewarded 1.23)
50% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.5
Environment.act() [POST]: location: (5, 5), heading: (0, -1), action: None, reward: 2.04967431389
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 15, &#39;action&#39;: None, &#39;reward&#39;: 2.0496743138883424, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 2.05)
47% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.5
Environment.act() [POST]: location: (5, 5), heading: (0, -1), action: None, reward: 1.2809657379
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 16, &#39;action&#39;: None, &#39;reward&#39;: 1.2809657378983947, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 1.28)
43% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.5
Environment.act() [POST]: location: (5, 4), heading: (0, -1), action: forward, reward: -0.128653541243
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 17, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -0.12865354124338135, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent drove forward instead of right. (rewarded -0.13)
40% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.5
Environment.act() [POST]: location: (5, 3), heading: (0, -1), action: forward, reward: 0.876011898004
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgflN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 18, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.8760118980041722, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgflN
Agent drove forward instead of right. (rewarded 0.88)
37% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.5
Environment.act() [POST]: location: (5, 3), heading: (0, -1), action: forward, reward: -39.0869039881
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNfr&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 19, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.08690398813915, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNfr
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.09)
33% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.5
Environment.act() [POST]: location: (5, 3), heading: (0, -1), action: None, reward: 1.78682429002
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrrNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 20, &#39;action&#39;: None, &#39;reward&#39;: 1.7868242900220694, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrrNN
Agent properly idled at a red light. (rewarded 1.79)
30% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.5
Environment.act() [POST]: location: (4, 3), heading: (-1, 0), action: left, reward: 0.207481192149
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 21, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.20748119214942184, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent drove left instead of right. (rewarded 0.21)
27% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.5
Environment.act() [POST]: location: (4, 2), heading: (0, -1), action: right, reward: 1.2519967818
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 22, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.2519967818047255, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent followed the waypoint right. (rewarded 1.25)
23% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0.5
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: forward, reward: 0.149833882117
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgffN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 23, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.1498338821169779, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgffN
Agent drove forward instead of right. (rewarded 0.15)
20% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0.5
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: None, reward: -4.70746405784
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNl&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 24, &#39;action&#39;: None, &#39;reward&#39;: -4.707464057839905, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNl
Agent idled at a green light with no oncoming traffic. (rewarded -4.71)
17% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Environment.step(): t = 25
0.5
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: forward, reward: -10.7949028108
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNl&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 25, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.79490281079955, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNl
Agent attempted driving forward through a red light. (rewarded -10.79)
13% of time remaining to reach destination.

/-------------------
| Step 26 Results
\-------------------

Environment.step(): t = 26
0.5
Environment.act() [POST]: location: (5, 7), heading: (1, 0), action: right, reward: 1.72724643773
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNf&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 26, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.7272464377306, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNf
Agent followed the waypoint right. (rewarded 1.73)
10% of time remaining to reach destination.

/-------------------
| Step 27 Results
\-------------------

Environment.step(): t = 27
0.5
Environment.act() [POST]: location: (6, 7), heading: (1, 0), action: forward, reward: 1.54780126243
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 27, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.5478012624335316, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 1.55)
7% of time remaining to reach destination.

/-------------------
| Step 28 Results
\-------------------

Environment.step(): t = 28
0.5
Environment.act() [POST]: location: (6, 7), heading: (1, 0), action: left, reward: -9.5337321558
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 28, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -9.533732155796272, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent attempted driving left through a red light. (rewarded -9.53)
3% of time remaining to reach destination.

/-------------------
| Step 29 Results
\-------------------

Environment.step(): t = 29
0.5
Environment.act() [POST]: location: (6, 7), heading: (1, 0), action: forward, reward: -10.0901472112
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 29, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.090147211232289, &#39;waypoint&#39;: &#39;forward&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: frfNN
Agent attempted driving forward through a red light. (rewarded -10.09)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 11
\-------------------------

Environment.reset(): Trial set up with start = (8, 7), destination = (5, 4), deadline = 30
Simulating trial. . . 
epsilon = 0.4500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.45
Environment.act() [POST]: location: (7, 7), heading: (-1, 0), action: right, reward: 2.83174380003
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNf&#39;, &#39;deadline&#39;: 30, &#39;t&#39;: 0, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.831743800030564, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNf
Agent followed the waypoint right. (rewarded 2.83)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.45
Environment.act() [POST]: location: (7, 6), heading: (0, -1), action: right, reward: 0.86161957695
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgllN&#39;, &#39;deadline&#39;: 29, &#39;t&#39;: 1, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.8616195769500815, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgllN
Agent drove right instead of forward. (rewarded 0.86)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.45
Environment.act() [POST]: location: (7, 6), heading: (0, -1), action: forward, reward: -10.5959910656
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrllN&#39;, &#39;deadline&#39;: 28, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.595991065627334, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrllN
Agent attempted driving forward through a red light. (rewarded -10.60)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.45
Environment.act() [POST]: location: (7, 6), heading: (0, -1), action: left, reward: -40.7471942472
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrllf&#39;, &#39;deadline&#39;: 27, &#39;t&#39;: 3, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -40.74719424721354, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrllf
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -40.75)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.45
Environment.act() [POST]: location: (8, 6), heading: (1, 0), action: right, reward: 0.925837728727
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 26, &#39;t&#39;: 4, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.9258377287265046, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent drove right instead of left. (rewarded 0.93)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.45
Environment.act() [POST]: location: (8, 6), heading: (1, 0), action: None, reward: 2.51697760913
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNrl&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: 2.516977609130315, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNrl
Agent properly idled at a red light. (rewarded 2.52)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.45
Environment.act() [POST]: location: (8, 6), heading: (1, 0), action: left, reward: -9.43995167411
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 6, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -9.439951674113386, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent attempted driving left through a red light. (rewarded -9.44)
77% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.45
Environment.act() [POST]: location: (8, 7), heading: (0, 1), action: right, reward: 1.89706250478
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrrNN&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 7, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.8970625047770224, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrrNN
Agent drove right instead of left. (rewarded 1.90)
73% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.45
Environment.act() [POST]: location: (8, 7), heading: (0, 1), action: left, reward: -39.9578744199
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNf&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 8, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -39.95787441994447, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNf
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -39.96)
70% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.45
Environment.act() [POST]: location: (8, 7), heading: (0, 1), action: None, reward: 1.88178746748
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNrN&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 9, &#39;action&#39;: None, &#39;reward&#39;: 1.8817874674842021, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNrN
Agent properly idled at a red light. (rewarded 1.88)
67% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.45
Environment.act() [POST]: location: (1, 7), heading: (1, 0), action: left, reward: 0.492674587284
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNl&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 10, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.49267458728366353, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNl
Agent drove left instead of right. (rewarded 0.49)
63% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.45
Environment.act() [POST]: location: (1, 7), heading: (1, 0), action: left, reward: -40.6827745399
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlfl&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 11, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -40.68277453990764, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlfl
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -40.68)
60% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.45
Environment.act() [POST]: location: (1, 7), heading: (1, 0), action: forward, reward: -40.5104891641
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlfl&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 12, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.51048916410877, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlfl
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.51)
57% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.45
Environment.act() [POST]: location: (1, 7), heading: (1, 0), action: None, reward: 1.6973626904
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 13, &#39;action&#39;: None, &#39;reward&#39;: 1.6973626904016423, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 1.70)
53% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.45
Environment.act() [POST]: location: (1, 7), heading: (1, 0), action: None, reward: 1.83720667605
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 14, &#39;action&#39;: None, &#39;reward&#39;: 1.8372066760480348, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 1.84)
50% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.45
Environment.act() [POST]: location: (1, 7), heading: (1, 0), action: forward, reward: -10.2036730708
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 15, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.203673070783314, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent attempted driving forward through a red light. (rewarded -10.20)
47% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.45
Environment.act() [POST]: location: (1, 6), heading: (0, -1), action: left, reward: 1.55921793423
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 16, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.5592179342342305, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent drove left instead of right. (rewarded 1.56)
43% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.45
Environment.act() [POST]: location: (1, 6), heading: (0, -1), action: None, reward: -4.93161306886
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 17, &#39;action&#39;: None, &#39;reward&#39;: -4.931613068855733, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent idled at a green light with no oncoming traffic. (rewarded -4.93)
40% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.45
Environment.act() [POST]: location: (2, 6), heading: (1, 0), action: right, reward: 1.51623449263
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 18, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.516234492627486, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent drove right instead of left. (rewarded 1.52)
37% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.45
Environment.act() [POST]: location: (2, 7), heading: (0, 1), action: right, reward: 0.757679715023
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 19, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.7576797150229452, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlN
Agent drove right instead of forward. (rewarded 0.76)
33% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.45
Environment.act() [POST]: location: (1, 7), heading: (-1, 0), action: right, reward: 0.144589999415
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNr&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 20, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.14458999941494954, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNr
Agent drove right instead of left. (rewarded 0.14)
30% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.45
Environment.act() [POST]: location: (1, 7), heading: (-1, 0), action: None, reward: 0.685822859952
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNfN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 21, &#39;action&#39;: None, &#39;reward&#39;: 0.6858228599515614, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNfN
Agent properly idled at a red light. (rewarded 0.69)
27% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.45
Environment.act() [POST]: location: (1, 7), heading: (-1, 0), action: None, reward: 2.01383109835
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 22, &#39;action&#39;: None, &#39;reward&#39;: 2.0138310983453955, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.01)
23% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0.45
Environment.act() [POST]: location: (1, 6), heading: (0, -1), action: right, reward: -0.1343412615
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 23, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.13434126150018655, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlN
Agent drove right instead of forward. (rewarded -0.13)
20% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0.45
Environment.act() [POST]: location: (1, 5), heading: (0, -1), action: forward, reward: 0.47799637913
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNff&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 24, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.4779963791302446, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNff
Agent drove forward instead of left. (rewarded 0.48)
17% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Environment.step(): t = 25
0.45
Environment.act() [POST]: location: (2, 5), heading: (1, 0), action: right, reward: 0.605200057589
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNf&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 25, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.605200057588761, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNf
Agent drove right instead of left. (rewarded 0.61)
13% of time remaining to reach destination.

/-------------------
| Step 26 Results
\-------------------

Environment.step(): t = 26
0.45
Environment.act() [POST]: location: (2, 5), heading: (1, 0), action: None, reward: 1.92657370438
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNl&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 26, &#39;action&#39;: None, &#39;reward&#39;: 1.926573704379789, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNl
Agent properly idled at a red light. (rewarded 1.93)
10% of time remaining to reach destination.

/-------------------
| Step 27 Results
\-------------------

Environment.step(): t = 27
0.45
Environment.act() [POST]: location: (2, 5), heading: (1, 0), action: forward, reward: -9.35957240011
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNrl&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 27, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.359572400107536, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNrl
Agent attempted driving forward through a red light. (rewarded -9.36)
7% of time remaining to reach destination.

/-------------------
| Step 28 Results
\-------------------

Environment.step(): t = 28
0.45
Environment.act() [POST]: location: (2, 6), heading: (0, 1), action: right, reward: -0.336156757477
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 28, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.33615675747701224, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlN
Agent drove right instead of forward. (rewarded -0.34)
3% of time remaining to reach destination.

/-------------------
| Step 29 Results
\-------------------

Environment.step(): t = 29
0.45
Environment.act() [POST]: location: (1, 6), heading: (-1, 0), action: right, reward: 0.19590468979
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 29, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.1959046897896246, &#39;waypoint&#39;: &#39;left&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: lrNNN
Agent drove right instead of left. (rewarded 0.20)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 12
\-------------------------

Environment.reset(): Trial set up with start = (8, 6), destination = (2, 4), deadline = 20
Simulating trial. . . 
epsilon = 0.4000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.4
Environment.act() [POST]: location: (8, 6), heading: (1, 0), action: forward, reward: -10.4284177301
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfrr&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.428417730140264, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfrr
Agent attempted driving forward through a red light. (rewarded -10.43)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.4
Environment.act() [POST]: location: (8, 7), heading: (0, 1), action: right, reward: 1.96521627163
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNr&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.9652162716341999, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNr
Agent drove right instead of forward. (rewarded 1.97)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.4
Environment.act() [POST]: location: (8, 2), heading: (0, 1), action: forward, reward: 0.962101326872
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNl&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.9621013268715614, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNl
Agent drove forward instead of left. (rewarded 0.96)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.4
Environment.act() [POST]: location: (7, 2), heading: (-1, 0), action: right, reward: 0.554667775231
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNl&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.5546677752313954, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNl
Agent drove right instead of left. (rewarded 0.55)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.4
Environment.act() [POST]: location: (7, 7), heading: (0, -1), action: right, reward: 1.91404158738
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.9140415873841388, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent drove right instead of left. (rewarded 1.91)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.4
Environment.act() [POST]: location: (7, 7), heading: (0, -1), action: left, reward: -10.6677980595
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.66779805947002, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent attempted driving left through a red light. (rewarded -10.67)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.4
Environment.act() [POST]: location: (8, 7), heading: (1, 0), action: right, reward: 1.33303658686
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.3330365868564866, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent followed the waypoint right. (rewarded 1.33)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.4
Environment.act() [POST]: location: (8, 2), heading: (0, 1), action: right, reward: 0.142816286449
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlf&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.14281628644910893, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlf
Agent drove right instead of forward. (rewarded 0.14)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.4
Environment.act() [POST]: location: (8, 2), heading: (0, 1), action: forward, reward: -39.3097608818
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrffl&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.309760881809666, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrffl
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.31)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.4
Environment.act() [POST]: location: (8, 3), heading: (0, 1), action: forward, reward: 0.785956136334
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgffl&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.7859561363339391, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgffl
Agent drove forward instead of left. (rewarded 0.79)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.4
Environment.act() [POST]: location: (8, 4), heading: (0, 1), action: forward, reward: 0.683169760729
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgllf&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.6831697607290829, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgllf
Agent drove forward instead of left. (rewarded 0.68)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.4
Environment.act() [POST]: location: (8, 4), heading: (0, 1), action: None, reward: -5.04109255155
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNl&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: None, &#39;reward&#39;: -5.041092551549503, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNl
Agent idled at a green light with no oncoming traffic. (rewarded -5.04)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.4
Environment.act() [POST]: location: (8, 5), heading: (0, 1), action: forward, reward: 0.200432724455
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNl&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.2004327244551909, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNl
Agent drove forward instead of left. (rewarded 0.20)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.4
Environment.act() [POST]: location: (7, 5), heading: (-1, 0), action: right, reward: 0.627829354136
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.6278293541360477, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent drove right instead of left. (rewarded 0.63)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.4
Environment.act() [POST]: location: (7, 6), heading: (0, 1), action: left, reward: -0.0694654658285
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNf&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 14, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -0.06946546582851376, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNf
Agent drove left instead of right. (rewarded -0.07)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.4
Environment.act() [POST]: location: (7, 7), heading: (0, 1), action: forward, reward: 0.402858761987
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 15, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.4028587619866477, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.40)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.4
Environment.act() [POST]: location: (7, 7), heading: (0, 1), action: right, reward: -19.5988540587
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 3, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNff&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 16, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -19.598854058681525, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNff
Agent attempted driving right through traffic and cause a minor accident. (rewarded -19.60)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.4
Environment.act() [POST]: location: (7, 7), heading: (0, 1), action: left, reward: -9.85405902818
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 17, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -9.854059028175973, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent attempted driving left through a red light. (rewarded -9.85)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.4
Environment.act() [POST]: location: (6, 7), heading: (-1, 0), action: right, reward: -0.0505036407868
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNlN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 18, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.050503640786758286, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNlN
Agent drove right instead of left. (rewarded -0.05)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.4
Environment.act() [POST]: location: (6, 7), heading: (-1, 0), action: left, reward: -9.62227399405
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 19, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -9.622273994050097, &#39;waypoint&#39;: &#39;left&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: lrNNN
Agent attempted driving left through a red light. (rewarded -9.62)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 13
\-------------------------

Environment.reset(): Trial set up with start = (3, 2), destination = (5, 6), deadline = 20
Simulating trial. . . 
epsilon = 0.3500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.35
Environment.act() [POST]: location: (3, 2), heading: (-1, 0), action: None, reward: 1.74294585539
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNl&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: None, &#39;reward&#39;: 1.7429458553868082, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNl
Agent idled at a green light with oncoming traffic. (rewarded 1.74)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.35
Environment.act() [POST]: location: (3, 2), heading: (-1, 0), action: None, reward: 1.41681051352
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNl&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: None, &#39;reward&#39;: 1.4168105135156948, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNl
Agent idled at a green light with oncoming traffic. (rewarded 1.42)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.35
Environment.act() [POST]: location: (3, 3), heading: (0, 1), action: left, reward: 0.431980034634
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNl&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.43198003463386947, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNl
Agent drove left instead of right. (rewarded 0.43)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.35
Environment.act() [POST]: location: (3, 4), heading: (0, 1), action: forward, reward: -0.00725623348368
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNfl&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -0.007256233483681762, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNfl
Agent drove forward instead of left. (rewarded -0.01)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.35
Environment.act() [POST]: location: (3, 4), heading: (0, 1), action: None, reward: 2.26623499088
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 2.2662349908823067, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.27)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.35
Environment.act() [POST]: location: (3, 5), heading: (0, 1), action: forward, reward: 0.896794855683
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNrN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.8967948556833201, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNrN
Agent drove forward instead of left. (rewarded 0.90)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.35
Environment.act() [POST]: location: (2, 5), heading: (-1, 0), action: right, reward: 1.50333722427
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.5033372242663143, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent drove right instead of left. (rewarded 1.50)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.35
Environment.act() [POST]: location: (2, 4), heading: (0, -1), action: right, reward: 0.75536653937
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.7553665393696851, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent drove right instead of left. (rewarded 0.76)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.35
Environment.act() [POST]: location: (2, 3), heading: (0, -1), action: forward, reward: 1.54591486834
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgfll&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.5459148683371304, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgfll
Agent drove forward instead of right. (rewarded 1.55)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.35
Environment.act() [POST]: location: (2, 3), heading: (0, -1), action: None, reward: 1.81384124812
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: None, &#39;reward&#39;: 1.8138412481234272, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 1.81)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.35
Environment.act() [POST]: location: (1, 3), heading: (-1, 0), action: left, reward: 0.316198721266
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.3161987212661611, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent drove left instead of right. (rewarded 0.32)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.35
Environment.act() [POST]: location: (1, 3), heading: (-1, 0), action: right, reward: -19.0827219934
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 3, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlfN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -19.082721993443826, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlfN
Agent attempted driving right through traffic and cause a minor accident. (rewarded -19.08)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.35
Environment.act() [POST]: location: (1, 2), heading: (0, -1), action: right, reward: 0.8445486774
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.844548677400397, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 0.84)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.35
Environment.act() [POST]: location: (8, 2), heading: (-1, 0), action: left, reward: 0.713019401673
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNl&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.7130194016728735, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNl
Agent followed the waypoint left. (rewarded 0.71)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.35
Environment.act() [POST]: location: (7, 2), heading: (-1, 0), action: forward, reward: 2.34881671566
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglrN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 14, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.3488167156618167, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglrN
Agent followed the waypoint forward. (rewarded 2.35)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.35
Environment.act() [POST]: location: (7, 7), heading: (0, -1), action: right, reward: -0.292972417539
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNl&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 15, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.29297241753858994, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNl
Agent drove right instead of forward. (rewarded -0.29)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.35
Environment.act() [POST]: location: (8, 7), heading: (1, 0), action: right, reward: 0.703616910566
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNlf&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 16, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.7036169105660763, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNlf
Agent drove right instead of left. (rewarded 0.70)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.35
Environment.act() [POST]: location: (1, 7), heading: (1, 0), action: forward, reward: -0.298414163399
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgffN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 17, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -0.2984141633985319, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgffN
Agent drove forward instead of left. (rewarded -0.30)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.35
Environment.act() [POST]: location: (2, 7), heading: (1, 0), action: forward, reward: 1.01132612462
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNll&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 18, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.0113261246248906, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNll
Agent drove forward instead of left. (rewarded 1.01)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.35
Environment.act() [POST]: location: (2, 6), heading: (0, -1), action: left, reward: 0.695897396669
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNlN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 19, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.6958973966689158, &#39;waypoint&#39;: &#39;forward&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: fgNlN
Agent drove left instead of forward. (rewarded 0.70)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 14
\-------------------------

Environment.reset(): Trial set up with start = (1, 3), destination = (3, 6), deadline = 25
Simulating trial. . . 
epsilon = 0.3000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.3
Environment.act() [POST]: location: (2, 3), heading: (1, 0), action: right, reward: 1.9847660867
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglff&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 0, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.9847660867035668, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglff
Agent followed the waypoint right. (rewarded 1.98)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.3
Environment.act() [POST]: location: (3, 3), heading: (1, 0), action: forward, reward: 1.46346271061
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgrlN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.4634627106074864, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgrlN
Agent followed the waypoint forward. (rewarded 1.46)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.3
Environment.act() [POST]: location: (3, 3), heading: (1, 0), action: forward, reward: -9.92032029272
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNr&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.920320292718904, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNr
Agent attempted driving forward through a red light. (rewarded -9.92)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.3
Environment.act() [POST]: location: (3, 3), heading: (1, 0), action: forward, reward: -39.7672102434
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNf&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 3, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.76721024337692, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.77)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.3
Environment.act() [POST]: location: (3, 3), heading: (1, 0), action: forward, reward: -9.94160178334
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 4, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.9416017833437, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent attempted driving forward through a red light. (rewarded -9.94)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.3
Environment.act() [POST]: location: (3, 4), heading: (0, 1), action: right, reward: 1.53198505732
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 5, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.5319850573195528, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent drove right instead of left. (rewarded 1.53)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.3
Environment.act() [POST]: location: (2, 4), heading: (-1, 0), action: right, reward: 0.773896913417
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 6, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.7738969134166352, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 0.77)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.3
Environment.act() [POST]: location: (2, 4), heading: (-1, 0), action: None, reward: -4.00269820016
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 7, &#39;action&#39;: None, &#39;reward&#39;: -4.002698200157303, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent idled at a green light with no oncoming traffic. (rewarded -4.00)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.3
Environment.act() [POST]: location: (2, 5), heading: (0, 1), action: left, reward: 1.23988537907
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 8, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.2398853790687365, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 1.24)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.3
Environment.act() [POST]: location: (1, 5), heading: (-1, 0), action: right, reward: 1.84887939004
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 9, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.8488793900357232, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent drove right instead of left. (rewarded 1.85)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.3
Environment.act() [POST]: location: (8, 5), heading: (-1, 0), action: forward, reward: 0.202413412626
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 10, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.20241341262635382, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.20)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.3
Environment.act() [POST]: location: (8, 4), heading: (0, -1), action: right, reward: 0.510137973198
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrllN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 11, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.5101379731978876, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrllN
Agent drove right instead of left. (rewarded 0.51)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.3
Environment.act() [POST]: location: (8, 3), heading: (0, -1), action: forward, reward: 0.699558153969
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglfN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 12, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.6995581539692437, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglfN
Agent drove forward instead of right. (rewarded 0.70)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.3
Environment.act() [POST]: location: (8, 3), heading: (0, -1), action: forward, reward: -40.1682689704
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNfN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.1682689704496, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNfN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.17)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.3
Environment.act() [POST]: location: (8, 3), heading: (0, -1), action: forward, reward: -40.9454232941
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNf&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 14, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.94542329411269, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.95)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.3
Environment.act() [POST]: location: (8, 3), heading: (0, -1), action: forward, reward: -10.9568046346
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlrN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 15, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.956804634562221, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlrN
Agent attempted driving forward through a red light. (rewarded -10.96)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.3
Environment.act() [POST]: location: (8, 3), heading: (0, -1), action: left, reward: -9.2030356973
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 16, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -9.203035697295011, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent attempted driving left through a red light. (rewarded -9.20)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.3
Environment.act() [POST]: location: (8, 3), heading: (0, -1), action: None, reward: 0.268897238562
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNl&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 17, &#39;action&#39;: None, &#39;reward&#39;: 0.26889723856183356, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNl
Agent idled at a green light with oncoming traffic. (rewarded 0.27)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.3
Environment.act() [POST]: location: (7, 3), heading: (-1, 0), action: left, reward: -0.324747364792
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNl&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 18, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -0.3247473647923853, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNl
Agent drove left instead of right. (rewarded -0.32)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.3
Environment.act() [POST]: location: (6, 3), heading: (-1, 0), action: forward, reward: -0.214190211179
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 19, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -0.2141902111787698, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent drove forward instead of right. (rewarded -0.21)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.3
Environment.act() [POST]: location: (6, 2), heading: (0, -1), action: right, reward: 0.55889867015
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 20, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.5588986701504035, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlN
Agent drove right instead of forward. (rewarded 0.56)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.3
Environment.act() [POST]: location: (7, 2), heading: (1, 0), action: right, reward: 0.560811727057
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 21, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.5608117270571239, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent drove right instead of left. (rewarded 0.56)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.3
Environment.act() [POST]: location: (8, 2), heading: (1, 0), action: forward, reward: 2.16650231856
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 22, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.166502318558699, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfNN
Agent followed the waypoint forward. (rewarded 2.17)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0.3
Environment.act() [POST]: location: (1, 2), heading: (1, 0), action: forward, reward: 1.37976241116
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 23, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.3797624111584725, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 1.38)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0.3
Environment.act() [POST]: location: (1, 7), heading: (0, -1), action: left, reward: -0.677860385801
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNll&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 24, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -0.6778603858008634, &#39;waypoint&#39;: &#39;forward&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: fgNll
Agent drove left instead of forward. (rewarded -0.68)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 15
\-------------------------

Environment.reset(): Trial set up with start = (2, 5), destination = (6, 2), deadline = 35
Simulating trial. . . 
epsilon = 0.2500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.25
Environment.act() [POST]: location: (2, 5), heading: (-1, 0), action: None, reward: 2.44389686088
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 35, &#39;t&#39;: 0, &#39;action&#39;: None, &#39;reward&#39;: 2.443896860882342, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.44)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.25
Environment.act() [POST]: location: (2, 4), heading: (0, -1), action: right, reward: 0.612520693578
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 34, &#39;t&#39;: 1, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.6125206935780996, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 0.61)
94% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.25
Environment.act() [POST]: location: (2, 3), heading: (0, -1), action: forward, reward: 1.23187146127
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNfN&#39;, &#39;deadline&#39;: 33, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.2318714612701775, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNfN
Agent drove forward instead of left. (rewarded 1.23)
91% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.25
Environment.act() [POST]: location: (3, 3), heading: (1, 0), action: right, reward: 0.874442000137
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 32, &#39;t&#39;: 3, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.8744420001365234, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent drove right instead of left. (rewarded 0.87)
89% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.25
Environment.act() [POST]: location: (3, 3), heading: (1, 0), action: None, reward: 1.74712854498
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 31, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 1.7471285449839231, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.75)
86% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.25
Environment.act() [POST]: location: (4, 3), heading: (1, 0), action: forward, reward: 2.09307436407
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 30, &#39;t&#39;: 5, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.0930743640675766, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 2.09)
83% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.25
Environment.act() [POST]: location: (4, 3), heading: (1, 0), action: forward, reward: -40.1462304373
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNfl&#39;, &#39;deadline&#39;: 29, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.146230437296744, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNfl
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.15)
80% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.25
Environment.act() [POST]: location: (4, 3), heading: (1, 0), action: left, reward: -9.19688915356
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 28, &#39;t&#39;: 7, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -9.19688915355879, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent attempted driving left through a red light. (rewarded -9.20)
77% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.25
Environment.act() [POST]: location: (4, 3), heading: (1, 0), action: None, reward: 1.9128256889
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNf&#39;, &#39;deadline&#39;: 27, &#39;t&#39;: 8, &#39;action&#39;: None, &#39;reward&#39;: 1.9128256888958657, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNf
Agent properly idled at a red light. (rewarded 1.91)
74% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.25
Environment.act() [POST]: location: (5, 3), heading: (1, 0), action: forward, reward: 1.10452569919
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNr&#39;, &#39;deadline&#39;: 26, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.104525699189396, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNr
Agent followed the waypoint forward. (rewarded 1.10)
71% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.25
Environment.act() [POST]: location: (5, 3), heading: (1, 0), action: None, reward: 2.26745568731
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 10, &#39;action&#39;: None, &#39;reward&#39;: 2.2674556873132565, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.27)
69% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.25
Environment.act() [POST]: location: (6, 3), heading: (1, 0), action: forward, reward: 2.32264906833
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 11, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.3226490683303744, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 2.32)
66% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.25
Environment.act() [POST]: location: (6, 3), heading: (1, 0), action: None, reward: 1.3575808992
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNrl&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 12, &#39;action&#39;: None, &#39;reward&#39;: 1.3575808992022091, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNrl
Agent properly idled at a red light. (rewarded 1.36)
63% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.25
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: forward, reward: 0.0607560688518
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNl&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.06075606885177487, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNl
Agent drove forward instead of left. (rewarded 0.06)
60% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.25
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: forward, reward: -9.91263916693
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrrNl&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 14, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.912639166931811, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrrNl
Agent attempted driving forward through a red light. (rewarded -9.91)
57% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.25
Environment.act() [POST]: location: (7, 4), heading: (0, 1), action: right, reward: -0.019184053716
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 15, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.019184053715976312, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNN
Agent drove right instead of left. (rewarded -0.02)
54% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.25
Environment.act() [POST]: location: (7, 4), heading: (0, 1), action: left, reward: -10.8666676783
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 16, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.866667678315252, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent attempted driving left through a red light. (rewarded -10.87)
51% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.25
Environment.act() [POST]: location: (6, 4), heading: (-1, 0), action: right, reward: 1.21923530012
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNfN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 17, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.2192353001232774, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNfN
Agent followed the waypoint right. (rewarded 1.22)
49% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.25
Environment.act() [POST]: location: (6, 3), heading: (0, -1), action: right, reward: 1.70461163657
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 18, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.704611636565293, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 1.70)
46% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.25
Environment.act() [POST]: location: (7, 3), heading: (1, 0), action: right, reward: 0.953369741717
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 19, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.9533697417171264, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 0.95)
43% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.25
Environment.act() [POST]: location: (8, 3), heading: (1, 0), action: forward, reward: -0.169251798047
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNlN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 20, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -0.169251798046538, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNlN
Agent drove forward instead of left. (rewarded -0.17)
40% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.25
Environment.act() [POST]: location: (8, 4), heading: (0, 1), action: right, reward: 0.0151580683909
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 21, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.015158068390877188, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNN
Agent drove right instead of left. (rewarded 0.02)
37% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.25
Environment.act() [POST]: location: (7, 4), heading: (-1, 0), action: right, reward: 2.06773581848
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 22, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.0677358184826167, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 2.07)
34% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0.25
Environment.act() [POST]: location: (7, 4), heading: (-1, 0), action: None, reward: -4.49540360398
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 23, &#39;action&#39;: None, &#39;reward&#39;: -4.495403603975617, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent idled at a green light with no oncoming traffic. (rewarded -4.50)
31% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0.25
Environment.act() [POST]: location: (7, 3), heading: (0, -1), action: right, reward: 1.35531627125
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNl&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 24, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.3553162712540654, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNl
Agent drove right instead of forward. (rewarded 1.36)
29% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Environment.step(): t = 25
0.25
Environment.act() [POST]: location: (6, 3), heading: (-1, 0), action: left, reward: 1.05782147451
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 25, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.0578214745066947, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 1.06)
26% of time remaining to reach destination.

/-------------------
| Step 26 Results
\-------------------

Environment.step(): t = 26
0.25
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (6, 2), heading: (0, -1), action: right, reward: 2.12468667031
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 26, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.1246866703120864, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 2.12)
23% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Training trial 16
\-------------------------

Environment.reset(): Trial set up with start = (5, 4), destination = (8, 6), deadline = 25
Simulating trial. . . 
epsilon = 0.2000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.2
Environment.act() [POST]: location: (5, 4), heading: (0, 1), action: forward, reward: -40.31632639
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNrf&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.31632638998276, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNrf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.32)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.2
Environment.act() [POST]: location: (4, 4), heading: (-1, 0), action: right, reward: 1.82319591718
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 1, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.823195917176783, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent drove right instead of left. (rewarded 1.82)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.2
Environment.act() [POST]: location: (4, 3), heading: (0, -1), action: right, reward: 1.65925704102
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 2, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.6592570410243832, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 1.66)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.2
Environment.act() [POST]: location: (4, 3), heading: (0, -1), action: None, reward: 2.92875542115
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfrN&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 2.9287554211519695, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfrN
Agent properly idled at a red light. (rewarded 2.93)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.2
Environment.act() [POST]: location: (4, 3), heading: (0, -1), action: None, reward: 2.10719448022
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNN&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 2.107194480215467, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNN
Agent properly idled at a red light. (rewarded 2.11)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.2
Environment.act() [POST]: location: (4, 2), heading: (0, -1), action: forward, reward: 1.73549420343
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfrl&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 5, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.7354942034274008, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfrl
Agent drove forward instead of left. (rewarded 1.74)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.2
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: forward, reward: 1.59183277933
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNl&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.5918327793332652, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNl
Agent drove forward instead of left. (rewarded 1.59)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.2
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: forward, reward: -39.3919636878
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfff&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 7, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.39196368776183, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfff
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.39)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.2
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: None, reward: 1.43848264837
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNl&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 8, &#39;action&#39;: None, &#39;reward&#39;: 1.4384826483748843, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNl
Agent properly idled at a red light. (rewarded 1.44)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.2
Environment.act() [POST]: location: (5, 7), heading: (1, 0), action: right, reward: 0.240187169396
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrrNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 9, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.24018716939606466, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrrNN
Agent drove right instead of left. (rewarded 0.24)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.2
Environment.act() [POST]: location: (5, 2), heading: (0, 1), action: right, reward: 0.173945701867
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlf&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 10, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.17394570186706237, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlf
Agent drove right instead of forward. (rewarded 0.17)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.2
Environment.act() [POST]: location: (5, 2), heading: (0, 1), action: None, reward: 2.68458268251
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 11, &#39;action&#39;: None, &#39;reward&#39;: 2.6845826825096344, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.68)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.2
Environment.act() [POST]: location: (5, 2), heading: (0, 1), action: left, reward: -10.3749078509
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 12, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -10.37490785088013, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent attempted driving left through a red light. (rewarded -10.37)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.2
Environment.act() [POST]: location: (4, 2), heading: (-1, 0), action: right, reward: 1.5909336026
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNf&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 13, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.590933602603244, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNf
Agent drove right instead of left. (rewarded 1.59)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.2
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: right, reward: 1.56099136394
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNlf&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 14, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.5609913639432054, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNlf
Agent drove right instead of forward. (rewarded 1.56)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.2
Environment.act() [POST]: location: (5, 7), heading: (1, 0), action: right, reward: 0.510709923936
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 15, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.5107099239355812, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent drove right instead of left. (rewarded 0.51)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.2
Environment.act() [POST]: location: (5, 7), heading: (1, 0), action: None, reward: 2.12942565826
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 16, &#39;action&#39;: None, &#39;reward&#39;: 2.1294256582579854, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.13)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.2
Environment.act() [POST]: location: (5, 2), heading: (0, 1), action: right, reward: -0.315440589428
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 17, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.315440589428275, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNN
Agent drove right instead of forward. (rewarded -0.32)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.2
Environment.act() [POST]: location: (5, 2), heading: (0, 1), action: forward, reward: -10.2304475525
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlrN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 18, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.230447552463044, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlrN
Agent attempted driving forward through a red light. (rewarded -10.23)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.2
Environment.act() [POST]: location: (4, 2), heading: (-1, 0), action: right, reward: 0.717006818935
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 19, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.7170068189345117, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent drove right instead of left. (rewarded 0.72)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.2
Environment.act() [POST]: location: (4, 2), heading: (-1, 0), action: forward, reward: -39.5790289099
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frffr&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 20, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.579028909872065, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frffr
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.58)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.2
Environment.act() [POST]: location: (3, 2), heading: (-1, 0), action: forward, reward: 1.44940460663
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 21, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.4494046066292818, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfNN
Agent followed the waypoint forward. (rewarded 1.45)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.2
Environment.act() [POST]: location: (3, 7), heading: (0, -1), action: right, reward: 0.797468073433
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNl&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 22, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.7974680734328776, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNl
Agent drove right instead of forward. (rewarded 0.80)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0.2
Environment.act() [POST]: location: (3, 6), heading: (0, -1), action: forward, reward: 0.518321605529
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNrN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 23, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.51832160552945, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNrN
Agent drove forward instead of left. (rewarded 0.52)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0.2
Environment.act() [POST]: location: (4, 6), heading: (1, 0), action: right, reward: 0.904896703602
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNf&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 24, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.9048967036018285, &#39;waypoint&#39;: &#39;left&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: lgNNf
Agent drove right instead of left. (rewarded 0.90)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 17
\-------------------------

Environment.reset(): Trial set up with start = (6, 2), destination = (5, 5), deadline = 20
Simulating trial. . . 
epsilon = 0.1500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.15
Environment.act() [POST]: location: (6, 7), heading: (0, -1), action: left, reward: 1.32801805564
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.3280180556432455, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 1.33)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.15
Environment.act() [POST]: location: (7, 7), heading: (1, 0), action: right, reward: 1.33903571989
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNfN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.3390357198923617, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNfN
Agent drove right instead of left. (rewarded 1.34)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.15
Environment.act() [POST]: location: (7, 7), heading: (1, 0), action: forward, reward: -10.1014352784
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNlr&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.101435278392948, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNlr
Agent attempted driving forward through a red light. (rewarded -10.10)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.15
Environment.act() [POST]: location: (7, 2), heading: (0, 1), action: right, reward: 1.46312531336
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNl&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.4631253133633315, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNl
Agent drove right instead of left. (rewarded 1.46)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.15
Environment.act() [POST]: location: (7, 2), heading: (0, 1), action: None, reward: 2.499581439
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 2.499581438998968, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 2.50)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.15
Environment.act() [POST]: location: (8, 2), heading: (1, 0), action: left, reward: 0.982924203781
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.9829242037806554, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent drove left instead of right. (rewarded 0.98)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.15
Environment.act() [POST]: location: (8, 3), heading: (0, 1), action: right, reward: 0.88281326351
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNf&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.882813263510182, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNf
Agent drove right instead of left. (rewarded 0.88)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.15
Environment.act() [POST]: location: (8, 3), heading: (0, 1), action: left, reward: -39.2117654331
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrrNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -39.21176543310288, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrrNN
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -39.21)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.15
Environment.act() [POST]: location: (7, 3), heading: (-1, 0), action: right, reward: 2.21057797338
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNl&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.210577973375691, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNl
Agent followed the waypoint right. (rewarded 2.21)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.15
Environment.act() [POST]: location: (6, 3), heading: (-1, 0), action: forward, reward: 1.11817645649
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.1181764564886947, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfNN
Agent followed the waypoint forward. (rewarded 1.12)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.15
Environment.act() [POST]: location: (6, 2), heading: (0, -1), action: right, reward: 1.13575949998
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frrNr&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.1357594999760288, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frrNr
Agent drove right instead of forward. (rewarded 1.14)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.15
Environment.act() [POST]: location: (6, 2), heading: (0, -1), action: None, reward: 1.72843850254
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: None, &#39;reward&#39;: 1.7284385025435292, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.73)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.15
Environment.act() [POST]: location: (7, 2), heading: (1, 0), action: right, reward: 0.561179936292
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNf&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.5611799362924879, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNf
Agent drove right instead of left. (rewarded 0.56)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.15
Environment.act() [POST]: location: (7, 2), heading: (1, 0), action: forward, reward: -10.3270790979
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.327079097928978, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent attempted driving forward through a red light. (rewarded -10.33)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.15
Environment.act() [POST]: location: (7, 2), heading: (1, 0), action: left, reward: -40.1840877365
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNrf&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 14, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -40.184087736475085, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNrf
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -40.18)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.15
Environment.act() [POST]: location: (7, 7), heading: (0, -1), action: left, reward: 1.09207885541
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 15, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.0920788554094787, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 1.09)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.15
Environment.act() [POST]: location: (8, 7), heading: (1, 0), action: right, reward: -0.0381635227219
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNll&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 16, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.038163522721928134, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNll
Agent drove right instead of left. (rewarded -0.04)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.15
Environment.act() [POST]: location: (8, 6), heading: (0, -1), action: left, reward: 1.43970770234
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 17, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.4397077023381246, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 1.44)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.15
Environment.act() [POST]: location: (1, 6), heading: (1, 0), action: right, reward: -0.0132269520488
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNfl&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 18, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.013226952048762675, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNfl
Agent drove right instead of left. (rewarded -0.01)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.15
Environment.act() [POST]: location: (1, 7), heading: (0, 1), action: right, reward: -0.580645015491
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNlf&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 19, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.5806450154910586, &#39;waypoint&#39;: &#39;left&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: lrNlf
Agent drove right instead of left. (rewarded -0.58)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 18
\-------------------------

Environment.reset(): Trial set up with start = (8, 7), destination = (3, 2), deadline = 20
Simulating trial. . . 
epsilon = 0.1000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.1
Environment.act() [POST]: location: (8, 2), heading: (0, 1), action: forward, reward: 1.15830635968
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNr&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.158306359676108, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNr
Agent drove forward instead of left. (rewarded 1.16)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.1
Environment.act() [POST]: location: (8, 3), heading: (0, 1), action: forward, reward: 1.45199233356
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNll&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.4519923335554297, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNll
Agent drove forward instead of left. (rewarded 1.45)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.1
Environment.act() [POST]: location: (8, 4), heading: (0, 1), action: forward, reward: 1.60654744474
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNlf&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.6065474447372958, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNlf
Agent drove forward instead of left. (rewarded 1.61)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.1
Environment.act() [POST]: location: (1, 4), heading: (1, 0), action: left, reward: 1.4638205891
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNlN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.463820589101543, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNlN
Agent followed the waypoint left. (rewarded 1.46)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.1
Environment.act() [POST]: location: (1, 5), heading: (0, 1), action: right, reward: 0.0752989931032
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.07529899310316945, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 0.08)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.1
Environment.act() [POST]: location: (1, 5), heading: (0, 1), action: None, reward: 2.06592114598
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNl&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: 2.0659211459838467, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNl
Agent properly idled at a red light. (rewarded 2.07)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.1
Environment.act() [POST]: location: (1, 5), heading: (0, 1), action: None, reward: 2.03499246151
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: None, &#39;reward&#39;: 2.0349924615128048, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNN
Agent properly idled at a red light. (rewarded 2.03)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.1
Environment.act() [POST]: location: (8, 5), heading: (-1, 0), action: right, reward: 1.46409376614
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.464093766141402, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNN
Agent drove right instead of left. (rewarded 1.46)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.1
Environment.act() [POST]: location: (8, 4), heading: (0, -1), action: right, reward: -0.11184988693
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNf&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.11184988693001274, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNf
Agent drove right instead of left. (rewarded -0.11)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.1
Environment.act() [POST]: location: (8, 4), heading: (0, -1), action: None, reward: 2.25952534519
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: None, &#39;reward&#39;: 2.259525345193389, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 2.26)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.1
Environment.act() [POST]: location: (8, 4), heading: (0, -1), action: None, reward: 1.7214153132
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: None, &#39;reward&#39;: 1.7214153132016763, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 1.72)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.1
Environment.act() [POST]: location: (7, 4), heading: (-1, 0), action: left, reward: 0.139889659773
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.13988965977296086, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent drove left instead of right. (rewarded 0.14)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.1
Environment.act() [POST]: location: (7, 4), heading: (-1, 0), action: None, reward: -5.62415561336
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 1, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgfrN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: None, &#39;reward&#39;: -5.624155613361377, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgfrN
Agent idled at a green light with no oncoming traffic. (rewarded -5.62)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.1
Environment.act() [POST]: location: (7, 4), heading: (-1, 0), action: forward, reward: -10.5614302182
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfrN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.561430218169198, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfrN
Agent attempted driving forward through a red light. (rewarded -10.56)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.1
Environment.act() [POST]: location: (7, 4), heading: (-1, 0), action: forward, reward: -9.76705739267
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrrNr&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 14, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.767057392674946, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrrNr
Agent attempted driving forward through a red light. (rewarded -9.77)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.1
Environment.act() [POST]: location: (6, 4), heading: (-1, 0), action: forward, reward: 1.0424719561
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgfrl&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 15, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.0424719561040545, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgfrl
Agent drove forward instead of right. (rewarded 1.04)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.1
Environment.act() [POST]: location: (5, 4), heading: (-1, 0), action: forward, reward: 1.28345769545
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 16, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.2834576954454555, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 1.28)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.1
Environment.act() [POST]: location: (5, 4), heading: (-1, 0), action: None, reward: 0.924417100268
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNf&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 17, &#39;action&#39;: None, &#39;reward&#39;: 0.9244171002675663, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNf
Agent properly idled at a red light. (rewarded 0.92)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.1
Environment.act() [POST]: location: (5, 3), heading: (0, -1), action: right, reward: -0.73567192098
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNl&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 18, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.7356719209803129, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNl
Agent drove right instead of forward. (rewarded -0.74)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.1
Environment.act() [POST]: location: (5, 3), heading: (0, -1), action: right, reward: -19.0910791544
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 3, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrffl&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 19, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -19.09107915438393, &#39;waypoint&#39;: &#39;left&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: lrffl
Agent attempted driving right through traffic and cause a minor accident. (rewarded -19.09)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 19
\-------------------------

Environment.reset(): Trial set up with start = (8, 2), destination = (6, 5), deadline = 25
Simulating trial. . . 
epsilon = 0.0500; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0.05
Environment.act() [POST]: location: (8, 2), heading: (1, 0), action: forward, reward: -40.0008346733
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrflf&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.00083467325564, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrflf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.00)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0.05
Environment.act() [POST]: location: (8, 3), heading: (0, 1), action: right, reward: 1.47221205073
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrllN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 1, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.472212050727753, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrllN
Agent drove right instead of left. (rewarded 1.47)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0.05
Environment.act() [POST]: location: (7, 3), heading: (-1, 0), action: right, reward: 2.68541641295
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNfN&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 2, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.685416412950671, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNfN
Agent followed the waypoint right. (rewarded 2.69)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0.05
Environment.act() [POST]: location: (7, 3), heading: (-1, 0), action: None, reward: 1.95974751533
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 1.9597475153310635, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.96)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0.05
Environment.act() [POST]: location: (7, 3), heading: (-1, 0), action: None, reward: 1.17552534886
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNf&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 1.1755253488563513, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNf
Agent properly idled at a red light. (rewarded 1.18)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0.05
Environment.act() [POST]: location: (6, 3), heading: (-1, 0), action: forward, reward: 2.25531613015
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 5, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.255316130151777, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 2.26)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0.05
Environment.act() [POST]: location: (6, 3), heading: (-1, 0), action: forward, reward: -10.2206895352
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNrN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.220689535198032, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNrN
Agent attempted driving forward through a red light. (rewarded -10.22)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0.05
Environment.act() [POST]: location: (6, 4), heading: (0, 1), action: left, reward: 1.81798582703
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 7, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.8179858270295401, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 1.82)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0.05
Environment.act() [POST]: location: (5, 4), heading: (-1, 0), action: right, reward: 1.3901899248
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNl&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.3901899247981664, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNl
Agent drove right instead of forward. (rewarded 1.39)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0.05
Environment.act() [POST]: location: (5, 3), heading: (0, -1), action: right, reward: 1.65755709834
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 9, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.657557098337698, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent drove right instead of left. (rewarded 1.66)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0.05
Environment.act() [POST]: location: (5, 3), heading: (0, -1), action: forward, reward: -40.5267180671
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNlf&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 10, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.52671806713819, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNlf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.53)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0.05
Environment.act() [POST]: location: (6, 3), heading: (1, 0), action: right, reward: 1.36533784007
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 11, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.3653378400699172, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 1.37)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0.05
Environment.act() [POST]: location: (6, 2), heading: (0, -1), action: left, reward: 1.6612355699
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNl&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 12, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.661235569900991, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNl
Agent drove left instead of right. (rewarded 1.66)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0.05
Environment.act() [POST]: location: (7, 2), heading: (1, 0), action: right, reward: 0.44387813578
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 13, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.4438781357801893, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 0.44)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0.05
Environment.act() [POST]: location: (7, 3), heading: (0, 1), action: right, reward: 0.556235188359
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlrN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 14, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.5562351883594453, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlrN
Agent drove right instead of left. (rewarded 0.56)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0.05
Environment.act() [POST]: location: (8, 3), heading: (1, 0), action: left, reward: 0.475047203549
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNfl&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 15, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.4750472035487747, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNfl
Agent drove left instead of right. (rewarded 0.48)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0.05
Environment.act() [POST]: location: (1, 3), heading: (1, 0), action: forward, reward: -0.33410061387
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNff&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 16, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -0.3341006138698964, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNff
Agent drove forward instead of right. (rewarded -0.33)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0.05
Environment.act() [POST]: location: (1, 3), heading: (1, 0), action: forward, reward: -39.83520054
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNff&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 17, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.83520053999545, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNff
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.84)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0.05
Environment.act() [POST]: location: (1, 4), heading: (0, 1), action: right, reward: 1.31388700341
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 18, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.313887003406468, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent followed the waypoint right. (rewarded 1.31)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0.05
Environment.act() [POST]: location: (8, 4), heading: (-1, 0), action: right, reward: 2.27285115012
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 19, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.272851150123083, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 2.27)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0.05
Environment.act() [POST]: location: (8, 4), heading: (-1, 0), action: forward, reward: -10.8578935139
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frrNl&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 20, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.857893513885555, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frrNl
Agent attempted driving forward through a red light. (rewarded -10.86)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0.05
Environment.act() [POST]: location: (7, 4), heading: (-1, 0), action: forward, reward: 0.625025458881
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 21, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.6250254588809201, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfNN
Agent followed the waypoint forward. (rewarded 0.63)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0.05
Environment.act() [POST]: location: (7, 3), heading: (0, -1), action: right, reward: 1.21527535141
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNf&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 22, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.2152753514132972, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNf
Agent drove right instead of forward. (rewarded 1.22)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0.05
Environment.act() [POST]: location: (6, 3), heading: (-1, 0), action: left, reward: 0.347841723082
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNlN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 23, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.34784172308234806, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNlN
Agent followed the waypoint left. (rewarded 0.35)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0.05
Environment.act() [POST]: location: (6, 4), heading: (0, 1), action: left, reward: 1.51664423612
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNlN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 24, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.5166442361233887, &#39;waypoint&#39;: &#39;left&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: lgNlN
Agent followed the waypoint left. (rewarded 1.52)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 20
\-------------------------

Environment.reset(): Trial set up with start = (7, 6), destination = (4, 2), deadline = 25
Simulating trial. . . 
epsilon = -0.0000; alpha = 0.5000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
-3.1918911958e-16
Environment.act() [POST]: location: (7, 7), heading: (0, 1), action: forward, reward: 1.51940000783
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgfNl&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.5194000078323742, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgfNl
Agent drove forward instead of right. (rewarded 1.52)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
-3.1918911958e-16
Environment.act() [POST]: location: (7, 2), heading: (0, 1), action: forward, reward: 1.20848032372
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNrN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.208480323717528, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNrN
Agent drove forward instead of right. (rewarded 1.21)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
-3.1918911958e-16
Environment.act() [POST]: location: (7, 3), heading: (0, 1), action: forward, reward: 0.129122542331
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNf&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.12912254233124765, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNf
Agent drove forward instead of right. (rewarded 0.13)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
-3.1918911958e-16
Environment.act() [POST]: location: (8, 3), heading: (1, 0), action: left, reward: 1.79192138634
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 3, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.7919213863423553, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent drove left instead of right. (rewarded 1.79)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
-3.1918911958e-16
Environment.act() [POST]: location: (8, 4), heading: (0, 1), action: right, reward: 0.240073996312
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 4, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.2400739963120443, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 0.24)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
-3.1918911958e-16
Environment.act() [POST]: location: (7, 4), heading: (-1, 0), action: right, reward: 0.983873162948
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrrNN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 5, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.9838731629477558, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrrNN
Agent drove right instead of left. (rewarded 0.98)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
-3.1918911958e-16
Environment.act() [POST]: location: (6, 4), heading: (-1, 0), action: forward, reward: 1.83449222597
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNfN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.8344922259716252, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNfN
Agent followed the waypoint forward. (rewarded 1.83)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
-3.1918911958e-16
Environment.act() [POST]: location: (6, 3), heading: (0, -1), action: right, reward: 0.444216116612
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNl&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 7, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.44421611661186056, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNl
Agent drove right instead of forward. (rewarded 0.44)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
-3.1918911958e-16
Environment.act() [POST]: location: (6, 3), heading: (0, -1), action: None, reward: 1.28116983807
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNlN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 8, &#39;action&#39;: None, &#39;reward&#39;: 1.2811698380745875, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNlN
Agent properly idled at a red light. (rewarded 1.28)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
-3.1918911958e-16
Environment.act() [POST]: location: (5, 3), heading: (-1, 0), action: left, reward: 2.74838451766
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 9, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.748384517655343, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 2.75)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
-3.1918911958e-16
Environment.act() [POST]: location: (5, 2), heading: (0, -1), action: right, reward: 1.23594746689
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNf&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 10, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.2359474668925383, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNf
Agent drove right instead of forward. (rewarded 1.24)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
-3.1918911958e-16
Environment.act() [POST]: location: (5, 2), heading: (0, -1), action: None, reward: 1.46168442778
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 11, &#39;action&#39;: None, &#39;reward&#39;: 1.4616844277773247, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.46)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
-3.1918911958e-16
Environment.act() [POST]: location: (6, 2), heading: (1, 0), action: right, reward: 1.54644774482
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 12, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.5464477448153586, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent drove right instead of left. (rewarded 1.55)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
-3.1918911958e-16
Environment.act() [POST]: location: (6, 2), heading: (1, 0), action: forward, reward: -39.213494894
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNfl&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.213494894035875, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNfl
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.21)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
-3.1918911958e-16
Environment.act() [POST]: location: (6, 2), heading: (1, 0), action: None, reward: 1.19151260457
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNrN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 14, &#39;action&#39;: None, &#39;reward&#39;: 1.1915126045708744, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNrN
Agent properly idled at a red light. (rewarded 1.19)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
-3.1918911958e-16
Environment.act() [POST]: location: (6, 3), heading: (0, 1), action: right, reward: 2.46222298503
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 15, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.4622229850330397, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent followed the waypoint right. (rewarded 2.46)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
-3.1918911958e-16
Environment.act() [POST]: location: (5, 3), heading: (-1, 0), action: right, reward: 1.45004025826
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNlf&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 16, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.4500402582622307, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNlf
Agent followed the waypoint right. (rewarded 1.45)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
-3.1918911958e-16
Environment.act() [POST]: location: (4, 3), heading: (-1, 0), action: forward, reward: 1.45703348446
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 17, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.4570334844556736, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 1.46)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
-3.1918911958e-16
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (4, 2), heading: (0, -1), action: right, reward: 1.78399374645
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNff&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 18, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.7839937464505022, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNff
Agent followed the waypoint right. (rewarded 1.78)
24% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Testing trial 1
\-------------------------

Environment.reset(): Trial set up with start = (7, 5), destination = (4, 4), deadline = 20
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (6, 5), heading: (-1, 0), action: right, reward: 2.14156421762
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNf&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.1415642176160716, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNf
Agent followed the waypoint right. (rewarded 2.14)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (6, 5), heading: (-1, 0), action: None, reward: 2.79174736961
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlfN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: None, &#39;reward&#39;: 2.7917473696063526, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlfN
Agent properly idled at a red light. (rewarded 2.79)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (6, 4), heading: (0, -1), action: right, reward: 1.77843275931
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.7784327593104972, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 1.78)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (5, 4), heading: (-1, 0), action: left, reward: 1.6365648429
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.6365648429024748, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 1.64)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (4, 4), heading: (-1, 0), action: forward, reward: 1.93077332969
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.9307733296850254, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 1.93)
75% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Testing trial 2
\-------------------------

Environment.reset(): Trial set up with start = (3, 7), destination = (6, 5), deadline = 25
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (3, 2), heading: (0, 1), action: right, reward: 1.41120419469
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfrN&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 0, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.4112041946937366, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfrN
Agent drove right instead of forward. (rewarded 1.41)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (4, 2), heading: (1, 0), action: left, reward: 2.30890206559
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNlN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 1, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.308902065591852, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNlN
Agent followed the waypoint left. (rewarded 2.31)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (4, 2), heading: (1, 0), action: forward, reward: -39.5100823109
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNf&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.51008231089273, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.51)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (4, 3), heading: (0, 1), action: right, reward: 1.37192618402
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 3, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.3719261840176118, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 1.37)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act() [POST]: location: (4, 4), heading: (0, 1), action: forward, reward: 1.35429623307
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNl&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 4, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.3542962330688404, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNl
Agent drove forward instead of left. (rewarded 1.35)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0
Environment.act() [POST]: location: (3, 4), heading: (-1, 0), action: right, reward: 0.920525295136
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNf&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 5, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.920525295135998, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNf
Agent drove right instead of left. (rewarded 0.92)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0
Environment.act() [POST]: location: (2, 4), heading: (-1, 0), action: forward, reward: 1.31538625061
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNrf&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.3153862506136442, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNrf
Agent drove forward instead of left. (rewarded 1.32)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0
Environment.act() [POST]: location: (1, 4), heading: (-1, 0), action: forward, reward: 2.85029367639
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 7, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.850293676385785, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 2.85)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0
Environment.act() [POST]: location: (1, 3), heading: (0, -1), action: right, reward: 1.66424421674
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.6642442167390965, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 1.66)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0
Environment.act() [POST]: location: (2, 3), heading: (1, 0), action: right, reward: 0.615926463653
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNf&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 9, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.615926463653234, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNf
Agent drove right instead of left. (rewarded 0.62)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0
Environment.act() [POST]: location: (2, 2), heading: (0, -1), action: left, reward: 1.72146659404
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 10, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.721466594038143, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent drove left instead of right. (rewarded 1.72)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0
Environment.act() [POST]: location: (2, 7), heading: (0, -1), action: forward, reward: 1.64987303069
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgrlf&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 11, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.6498730306944789, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgrlf
Agent drove forward instead of left. (rewarded 1.65)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0
Environment.act() [POST]: location: (3, 7), heading: (1, 0), action: right, reward: 1.3917992808
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 12, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.3917992808049091, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent drove right instead of left. (rewarded 1.39)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0
Environment.act() [POST]: location: (4, 7), heading: (1, 0), action: forward, reward: 2.40869633396
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNl&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.408696333958259, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNl
Agent followed the waypoint forward. (rewarded 2.41)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0
Environment.act() [POST]: location: (4, 2), heading: (0, 1), action: right, reward: 0.819722509981
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 14, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.8197225099811837, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNN
Agent drove right instead of forward. (rewarded 0.82)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0
Environment.act() [POST]: location: (5, 2), heading: (1, 0), action: left, reward: 2.01194757709
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNlN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 15, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.01194757709262, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNlN
Agent followed the waypoint left. (rewarded 2.01)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0
Environment.act() [POST]: location: (5, 3), heading: (0, 1), action: right, reward: -0.0952885135454
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNl&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 16, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.09528851354535994, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNl
Agent drove right instead of forward. (rewarded -0.10)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0
Environment.act() [POST]: location: (6, 3), heading: (1, 0), action: left, reward: 0.75038269247
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 17, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.7503826924698156, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 0.75)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0
Environment.act() [POST]: location: (6, 4), heading: (0, 1), action: right, reward: 1.0909311312
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNff&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 18, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.090931131203373, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNff
Agent followed the waypoint right. (rewarded 1.09)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0
Environment.act() [POST]: location: (6, 4), heading: (0, 1), action: forward, reward: -10.3379020956
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frrlN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 19, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.337902095594137, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frrlN
Agent attempted driving forward through a red light. (rewarded -10.34)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0
Environment.act() [POST]: location: (6, 4), heading: (0, 1), action: forward, reward: -40.454316462
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frrfN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 20, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.454316461962705, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frrfN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.45)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0
Environment.act() [POST]: location: (6, 4), heading: (0, 1), action: forward, reward: -39.3029866921
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frrNf&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 21, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.302986692055796, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frrNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.30)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (6, 5), heading: (0, 1), action: forward, reward: 1.44406392489
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgrNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 22, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.4440639248916858, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgrNN
Agent followed the waypoint forward. (rewarded 1.44)
8% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Testing trial 3
\-------------------------

Environment.reset(): Trial set up with start = (8, 4), destination = (6, 2), deadline = 20
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (8, 5), heading: (0, 1), action: right, reward: 0.921491137929
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNl&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.9214911379285806, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNl
Agent drove right instead of left. (rewarded 0.92)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (8, 5), heading: (0, 1), action: forward, reward: -40.072134926
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrllf&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.07213492599404, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrllf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.07)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (8, 5), heading: (0, 1), action: None, reward: 1.98500975427
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrllN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: None, &#39;reward&#39;: 1.9850097542735345, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrllN
Agent properly idled at a red light. (rewarded 1.99)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (8, 5), heading: (0, 1), action: None, reward: 1.66547730432
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 1.6654773043165456, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 1.67)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act() [POST]: location: (8, 5), heading: (0, 1), action: None, reward: 0.114576416237
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNl&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 0.1145764162369608, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNl
Agent idled at a green light with oncoming traffic. (rewarded 0.11)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0
Environment.act() [POST]: location: (8, 5), heading: (0, 1), action: None, reward: 1.865821062
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNl&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: 1.8658210619957274, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNl
Agent idled at a green light with oncoming traffic. (rewarded 1.87)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0
Environment.act() [POST]: location: (8, 5), heading: (0, 1), action: None, reward: 0.296056851203
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNl&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: None, &#39;reward&#39;: 0.2960568512025543, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNl
Agent idled at a green light with oncoming traffic. (rewarded 0.30)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0
Environment.act() [POST]: location: (7, 5), heading: (-1, 0), action: right, reward: 2.85316046261
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNl&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.853160462605598, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNl
Agent followed the waypoint right. (rewarded 2.85)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0
Environment.act() [POST]: location: (6, 5), heading: (-1, 0), action: forward, reward: 1.70732846741
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.7073284674100335, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 1.71)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0
Environment.act() [POST]: location: (6, 5), heading: (-1, 0), action: None, reward: 2.17647983813
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: None, &#39;reward&#39;: 2.176479838133968, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.18)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0
Environment.act() [POST]: location: (6, 5), heading: (-1, 0), action: forward, reward: -40.2605407829
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrrfN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.26054078286745, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrrfN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.26)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0
Environment.act() [POST]: location: (6, 4), heading: (0, -1), action: right, reward: -0.277757726972
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNl&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.27775772697197, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNl
Agent drove right instead of left. (rewarded -0.28)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0
Environment.act() [POST]: location: (7, 4), heading: (1, 0), action: right, reward: 0.146933192648
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.14693319264778038, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNN
Agent drove right instead of forward. (rewarded 0.15)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0
Environment.act() [POST]: location: (8, 4), heading: (1, 0), action: forward, reward: 0.0119361224624
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNr&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.01193612246236564, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNr
Agent drove forward instead of left. (rewarded 0.01)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0
Environment.act() [POST]: location: (8, 4), heading: (1, 0), action: None, reward: 0.83363803219
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 14, &#39;action&#39;: None, &#39;reward&#39;: 0.8336380321895769, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNN
Agent properly idled at a red light. (rewarded 0.83)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0
Environment.act() [POST]: location: (8, 4), heading: (1, 0), action: None, reward: 1.78241361766
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNf&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 15, &#39;action&#39;: None, &#39;reward&#39;: 1.7824136176637664, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNf
Agent properly idled at a red light. (rewarded 1.78)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0
Environment.act() [POST]: location: (8, 5), heading: (0, 1), action: right, reward: 0.0157969546492
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 16, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.01579695464919073, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNN
Agent drove right instead of left. (rewarded 0.02)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0
Environment.act() [POST]: location: (1, 5), heading: (1, 0), action: left, reward: -0.468194034655
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 17, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -0.4681940346553567, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent drove left instead of right. (rewarded -0.47)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0
Environment.act() [POST]: location: (1, 5), heading: (1, 0), action: forward, reward: -10.2581624962
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfrl&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 18, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.25816249617346, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfrl
Agent attempted driving forward through a red light. (rewarded -10.26)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0
Environment.act() [POST]: location: (1, 4), heading: (0, -1), action: left, reward: -0.826948880478
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 19, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -0.8269488804781778, &#39;waypoint&#39;: &#39;right&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: rglNN
Agent drove left instead of right. (rewarded -0.83)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Testing trial 4
\-------------------------

Environment.reset(): Trial set up with start = (6, 6), destination = (3, 3), deadline = 30
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (6, 6), heading: (1, 0), action: forward, reward: -9.55575931709
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrflN&#39;, &#39;deadline&#39;: 30, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.555759317094864, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrflN
Agent attempted driving forward through a red light. (rewarded -9.56)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (6, 7), heading: (0, 1), action: right, reward: 2.97393922872
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfNN&#39;, &#39;deadline&#39;: 29, &#39;t&#39;: 1, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.9739392287217474, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfNN
Agent followed the waypoint right. (rewarded 2.97)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (6, 2), heading: (0, 1), action: forward, reward: 0.767938280395
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNrN&#39;, &#39;deadline&#39;: 28, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.7679382803952498, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNrN
Agent drove forward instead of right. (rewarded 0.77)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (5, 2), heading: (-1, 0), action: right, reward: 1.0946966346
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfNN&#39;, &#39;deadline&#39;: 27, &#39;t&#39;: 3, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.0946966346029832, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfNN
Agent followed the waypoint right. (rewarded 1.09)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act() [POST]: location: (4, 2), heading: (-1, 0), action: forward, reward: 1.13640564421
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNfl&#39;, &#39;deadline&#39;: 26, &#39;t&#39;: 4, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.1364056442111115, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNfl
Agent followed the waypoint forward. (rewarded 1.14)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: right, reward: 1.32310857845
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNf&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 5, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.3231085784472199, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNf
Agent drove right instead of forward. (rewarded 1.32)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0
Environment.act() [POST]: location: (4, 6), heading: (0, -1), action: forward, reward: 1.56639518148
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgrNN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.5663951814808383, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgrNN
Agent drove forward instead of left. (rewarded 1.57)
77% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0
Environment.act() [POST]: location: (5, 6), heading: (1, 0), action: right, reward: 0.766905062011
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlrl&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 7, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.7669050620107146, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlrl
Agent drove right instead of left. (rewarded 0.77)
73% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0
Environment.act() [POST]: location: (6, 6), heading: (1, 0), action: forward, reward: 0.780385929662
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgrNl&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 8, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.7803859296622838, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgrNl
Agent drove forward instead of right. (rewarded 0.78)
70% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0
Environment.act() [POST]: location: (6, 7), heading: (0, 1), action: right, reward: 2.66606749978
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 9, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.6660674997849076, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 2.67)
67% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0
Environment.act() [POST]: location: (5, 7), heading: (-1, 0), action: right, reward: 2.02668867898
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfrN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 10, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.0266886789793013, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfrN
Agent followed the waypoint right. (rewarded 2.03)
63% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0
Environment.act() [POST]: location: (5, 7), heading: (-1, 0), action: forward, reward: -40.9179940386
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlfr&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 11, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.91799403857483, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlfr
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.92)
60% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0
Environment.act() [POST]: location: (5, 6), heading: (0, -1), action: right, reward: 0.0509246583074
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 12, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.05092465830735915, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 0.05)
57% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0
Environment.act() [POST]: location: (5, 5), heading: (0, -1), action: forward, reward: 1.49104063638
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNfr&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.4910406363798656, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNfr
Agent drove forward instead of left. (rewarded 1.49)
53% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0
Environment.act() [POST]: location: (5, 5), heading: (0, -1), action: forward, reward: -40.8058493286
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrrfN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 14, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.80584932864818, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrrfN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.81)
50% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0
Environment.act() [POST]: location: (5, 5), heading: (0, -1), action: None, reward: 1.7714901726
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 15, &#39;action&#39;: None, &#39;reward&#39;: 1.7714901725979344, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.77)
47% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0
Environment.act() [POST]: location: (6, 5), heading: (1, 0), action: right, reward: 1.01109937051
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 16, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.0110993705054983, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent drove right instead of left. (rewarded 1.01)
43% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0
Environment.act() [POST]: location: (6, 5), heading: (1, 0), action: None, reward: 0.754648252841
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNrN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 17, &#39;action&#39;: None, &#39;reward&#39;: 0.7546482528407354, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNrN
Agent properly idled at a red light. (rewarded 0.75)
40% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0
Environment.act() [POST]: location: (6, 6), heading: (0, 1), action: right, reward: 1.47632715795
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrrNl&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 18, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.476327157947542, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrrNl
Agent drove right instead of left. (rewarded 1.48)
37% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0
Environment.act() [POST]: location: (6, 6), heading: (0, 1), action: forward, reward: -39.9562147599
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrffN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 19, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.95621475990958, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrffN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.96)
33% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0
Environment.act() [POST]: location: (5, 6), heading: (-1, 0), action: right, reward: 1.73464515287
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 20, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.7346451528747289, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfNN
Agent followed the waypoint right. (rewarded 1.73)
30% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0
Environment.act() [POST]: location: (5, 6), heading: (-1, 0), action: None, reward: 1.96925979809
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 21, &#39;action&#39;: None, &#39;reward&#39;: 1.969259798089769, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.97)
27% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0
Environment.act() [POST]: location: (5, 5), heading: (0, -1), action: right, reward: -0.433414126179
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frfNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 22, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.43341412617921304, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frfNN
Agent drove right instead of forward. (rewarded -0.43)
23% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0
Environment.act() [POST]: location: (5, 5), heading: (0, -1), action: None, reward: 0.85517858328
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 23, &#39;action&#39;: None, &#39;reward&#39;: 0.8551785832797241, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 0.86)
20% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0
Environment.act() [POST]: location: (5, 5), heading: (0, -1), action: None, reward: 1.90096045442
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 24, &#39;action&#39;: None, &#39;reward&#39;: 1.900960454416028, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.90)
17% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Environment.step(): t = 25
0
Environment.act() [POST]: location: (5, 4), heading: (0, -1), action: forward, reward: 1.35080689797
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgllN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 25, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.350806897972236, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgllN
Agent drove forward instead of left. (rewarded 1.35)
13% of time remaining to reach destination.

/-------------------
| Step 26 Results
\-------------------

Environment.step(): t = 26
0
Environment.act() [POST]: location: (5, 3), heading: (0, -1), action: forward, reward: 0.740493007123
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNr&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 26, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.7404930071232216, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNr
Agent drove forward instead of left. (rewarded 0.74)
10% of time remaining to reach destination.

/-------------------
| Step 27 Results
\-------------------

Environment.step(): t = 27
0
Environment.act() [POST]: location: (5, 3), heading: (0, -1), action: None, reward: 1.96839841042
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNlN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 27, &#39;action&#39;: None, &#39;reward&#39;: 1.9683984104208994, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNlN
Agent properly idled at a red light. (rewarded 1.97)
7% of time remaining to reach destination.

/-------------------
| Step 28 Results
\-------------------

Environment.step(): t = 28
0
Environment.act() [POST]: location: (5, 3), heading: (0, -1), action: None, reward: 1.82680084554
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 28, &#39;action&#39;: None, &#39;reward&#39;: 1.826800845540806, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNN
Agent properly idled at a red light. (rewarded 1.83)
3% of time remaining to reach destination.

/-------------------
| Step 29 Results
\-------------------

Environment.step(): t = 29
0
Environment.act() [POST]: location: (6, 3), heading: (1, 0), action: right, reward: -0.264089774664
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 29, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.2640897746643971, &#39;waypoint&#39;: &#39;left&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: lgfNN
Agent drove right instead of left. (rewarded -0.26)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Testing trial 5
\-------------------------

Environment.reset(): Trial set up with start = (2, 7), destination = (1, 4), deadline = 20
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (1, 7), heading: (-1, 0), action: right, reward: 1.48435511044
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNfN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.4843551104412294, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNfN
Agent followed the waypoint right. (rewarded 1.48)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (8, 7), heading: (-1, 0), action: forward, reward: 1.45543080598
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNrN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.4554308059766172, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNrN
Agent drove forward instead of left. (rewarded 1.46)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (8, 6), heading: (0, -1), action: right, reward: 1.77549203434
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNf&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.7754920343407004, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNf
Agent drove right instead of left. (rewarded 1.78)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (1, 6), heading: (1, 0), action: right, reward: 2.87123278789
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.871232787888132, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent followed the waypoint right. (rewarded 2.87)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act() [POST]: location: (1, 6), heading: (1, 0), action: right, reward: -19.6287606849
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 3, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNfN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -19.628760684889144, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNfN
Agent attempted driving right through traffic and cause a minor accident. (rewarded -19.63)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0
Environment.act() [POST]: location: (1, 7), heading: (0, 1), action: right, reward: 0.0638290285339
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.06382902853393291, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent drove right instead of left. (rewarded 0.06)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0
Environment.act() [POST]: location: (1, 2), heading: (0, 1), action: forward, reward: 1.60340408089
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.6034040808928594, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 1.60)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0
Environment.act() [POST]: location: (1, 2), heading: (0, 1), action: forward, reward: -10.7484514044
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNr&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.748451404401228, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNr
Agent attempted driving forward through a red light. (rewarded -10.75)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0
Environment.act() [POST]: location: (1, 2), heading: (0, 1), action: None, reward: 1.04839623934
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frllN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: None, &#39;reward&#39;: 1.0483962393411212, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frllN
Agent properly idled at a red light. (rewarded 1.05)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0
Environment.act() [POST]: location: (1, 2), heading: (0, 1), action: forward, reward: -9.05673863748
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlll&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.056738637476906, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlll
Agent attempted driving forward through a red light. (rewarded -9.06)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0
Environment.act() [POST]: location: (1, 3), heading: (0, 1), action: forward, reward: 1.77960647589
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.7796064758908878, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 1.78)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0
Environment.act() [POST]: location: (1, 3), heading: (0, 1), action: None, reward: 1.20708788152
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: None, &#39;reward&#39;: 1.2070878815227992, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.21)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0
Environment.act() [POST]: location: (1, 3), heading: (0, 1), action: None, reward: 1.27736203358
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: None, &#39;reward&#39;: 1.2773620335808586, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.28)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (1, 4), heading: (0, 1), action: forward, reward: 1.91656091424
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.9165609142401658, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 1.92)
30% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Testing trial 6
\-------------------------

Environment.reset(): Trial set up with start = (6, 5), destination = (4, 7), deadline = 20
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (6, 5), heading: (1, 0), action: forward, reward: -40.5604227542
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrrNf&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.56042275424141, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrrNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.56)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (6, 5), heading: (1, 0), action: forward, reward: -9.73749944303
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrrrl&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.737499443031675, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrrrl
Agent attempted driving forward through a red light. (rewarded -9.74)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (6, 5), heading: (1, 0), action: forward, reward: -10.8612645483
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNrl&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.861264548257854, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNrl
Agent attempted driving forward through a red light. (rewarded -10.86)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (6, 6), heading: (0, 1), action: right, reward: 1.53559772042
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNl&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.5355977204223246, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNl
Agent followed the waypoint right. (rewarded 1.54)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act() [POST]: location: (6, 6), heading: (0, 1), action: None, reward: 2.1222928343
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 2.122292834295136, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 2.12)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0
Environment.act() [POST]: location: (6, 6), heading: (0, 1), action: forward, reward: -40.4281750646
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlfN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -40.428175064603735, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlfN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.43)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0
Environment.act() [POST]: location: (6, 6), heading: (0, 1), action: None, reward: 0.537870306713
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNl&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: None, &#39;reward&#39;: 0.5378703067133541, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNl
Agent idled at a green light with oncoming traffic. (rewarded 0.54)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0
Environment.act() [POST]: location: (6, 6), heading: (0, 1), action: None, reward: 0.655947987053
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNl&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: None, &#39;reward&#39;: 0.6559479870531186, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNl
Agent idled at a green light with oncoming traffic. (rewarded 0.66)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0
Environment.act() [POST]: location: (6, 7), heading: (0, 1), action: forward, reward: 0.411498096545
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNrl&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.4114980965453118, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNrl
Agent drove forward instead of right. (rewarded 0.41)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0
Environment.act() [POST]: location: (5, 7), heading: (-1, 0), action: right, reward: 1.01450058389
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNfN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.014500583886787, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNfN
Agent followed the waypoint right. (rewarded 1.01)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (4, 7), heading: (-1, 0), action: forward, reward: 1.53028306486
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNl&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.5302830648643984, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNl
Agent followed the waypoint forward. (rewarded 1.53)
45% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Testing trial 7
\-------------------------

Environment.reset(): Trial set up with start = (3, 6), destination = (4, 3), deadline = 20
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (3, 6), heading: (0, 1), action: forward, reward: -39.2012651254
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrrlf&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.20126512539763, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrrlf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.20)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (3, 6), heading: (0, 1), action: None, reward: 2.41176107631
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: None, &#39;reward&#39;: 2.41176107631051, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNN
Agent properly idled at a red light. (rewarded 2.41)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (3, 6), heading: (0, 1), action: forward, reward: -10.8022029571
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrflN&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.802202957137409, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrflN
Agent attempted driving forward through a red light. (rewarded -10.80)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (3, 6), heading: (0, 1), action: None, reward: 2.64465110358
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrfNN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: None, &#39;reward&#39;: 2.6446511035810816, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrfNN
Agent properly idled at a red light. (rewarded 2.64)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act() [POST]: location: (2, 6), heading: (-1, 0), action: right, reward: 0.58598738153
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.5859873815298499, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent drove right instead of left. (rewarded 0.59)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0
Environment.act() [POST]: location: (2, 6), heading: (-1, 0), action: None, reward: 1.61093175837
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 5, &#39;action&#39;: None, &#39;reward&#39;: 1.6109317583650329, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.61)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0
Environment.act() [POST]: location: (2, 6), heading: (-1, 0), action: None, reward: 2.79838463356
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 6, &#39;action&#39;: None, &#39;reward&#39;: 2.7983846335618816, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.80)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0
Environment.act() [POST]: location: (2, 5), heading: (0, -1), action: right, reward: 1.21018082422
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 7, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.2101808242249936, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent drove right instead of left. (rewarded 1.21)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0
Environment.act() [POST]: location: (2, 5), heading: (0, -1), action: None, reward: 2.01923850743
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrllN&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 8, &#39;action&#39;: None, &#39;reward&#39;: 2.0192385074272146, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrllN
Agent properly idled at a red light. (rewarded 2.02)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0
Environment.act() [POST]: location: (2, 5), heading: (0, -1), action: None, reward: 1.14687413357
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 9, &#39;action&#39;: None, &#39;reward&#39;: 1.1468741335691623, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 1.15)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0
Environment.act() [POST]: location: (3, 5), heading: (1, 0), action: right, reward: 1.83881174264
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNf&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 10, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.8388117426360504, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNf
Agent followed the waypoint right. (rewarded 1.84)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0
Environment.act() [POST]: location: (4, 5), heading: (1, 0), action: forward, reward: 1.73780225369
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 11, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.737802253694383, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 1.74)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0
Environment.act() [POST]: location: (4, 6), heading: (0, 1), action: right, reward: 0.522451356222
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNr&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 12, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.5224513562215913, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNr
Agent drove right instead of left. (rewarded 0.52)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0
Environment.act() [POST]: location: (4, 6), heading: (0, 1), action: None, reward: 2.26644923987
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 13, &#39;action&#39;: None, &#39;reward&#39;: 2.266449239868209, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.27)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0
Environment.act() [POST]: location: (4, 6), heading: (0, 1), action: None, reward: 0.960861121836
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 14, &#39;action&#39;: None, &#39;reward&#39;: 0.9608611218356298, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 0.96)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0
Environment.act() [POST]: location: (4, 6), heading: (0, 1), action: None, reward: 0.671049156678
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNf&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 15, &#39;action&#39;: None, &#39;reward&#39;: 0.6710491566783208, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNf
Agent properly idled at a red light. (rewarded 0.67)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0
Environment.act() [POST]: location: (4, 7), heading: (0, 1), action: forward, reward: 1.14053844927
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 16, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.1405384492741037, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 1.14)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0
Environment.act() [POST]: location: (4, 2), heading: (0, 1), action: forward, reward: 0.689466100158
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 17, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.689466100158157, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 0.69)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0
Environment.act() [POST]: location: (4, 2), heading: (0, 1), action: None, reward: 0.716152362946
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 18, &#39;action&#39;: None, &#39;reward&#39;: 0.7161523629457343, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 0.72)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0
Environment.act() [POST]: location: (4, 2), heading: (0, 1), action: None, reward: 0.879886506244
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNf&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 19, &#39;action&#39;: None, &#39;reward&#39;: 0.879886506243809, &#39;waypoint&#39;: &#39;forward&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: frNNf
Agent properly idled at a red light. (rewarded 0.88)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Testing trial 8
\-------------------------

Environment.reset(): Trial set up with start = (3, 3), destination = (7, 6), deadline = 35
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (3, 4), heading: (0, 1), action: forward, reward: 1.62465367841
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgrlN&#39;, &#39;deadline&#39;: 35, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.624653678410621, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgrlN
Agent drove forward instead of right. (rewarded 1.62)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (3, 4), heading: (0, 1), action: forward, reward: -39.8157632334
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 4, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfNf&#39;, &#39;deadline&#39;: 34, &#39;t&#39;: 1, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -39.815763233367164, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.82)
94% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (2, 4), heading: (-1, 0), action: right, reward: 1.53855584642
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfNN&#39;, &#39;deadline&#39;: 33, &#39;t&#39;: 2, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.538555846422672, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfNN
Agent followed the waypoint right. (rewarded 1.54)
91% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (1, 4), heading: (-1, 0), action: forward, reward: 1.96979762553
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfNN&#39;, &#39;deadline&#39;: 32, &#39;t&#39;: 3, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.969797625533653, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfNN
Agent followed the waypoint forward. (rewarded 1.97)
89% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act() [POST]: location: (1, 4), heading: (-1, 0), action: None, reward: 2.43093009852
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frllN&#39;, &#39;deadline&#39;: 31, &#39;t&#39;: 4, &#39;action&#39;: None, &#39;reward&#39;: 2.4309300985164777, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frllN
Agent properly idled at a red light. (rewarded 2.43)
86% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0
Environment.act() [POST]: location: (8, 4), heading: (-1, 0), action: forward, reward: 2.51847544062
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fglNN&#39;, &#39;deadline&#39;: 30, &#39;t&#39;: 5, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.5184754406191825, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fglNN
Agent followed the waypoint forward. (rewarded 2.52)
83% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0
Environment.act() [POST]: location: (8, 4), heading: (-1, 0), action: forward, reward: -9.8075289837
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNll&#39;, &#39;deadline&#39;: 29, &#39;t&#39;: 6, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -9.807528983695386, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNll
Agent attempted driving forward through a red light. (rewarded -9.81)
80% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0
Environment.act() [POST]: location: (8, 4), heading: (-1, 0), action: None, reward: 2.8759979853
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNNN&#39;, &#39;deadline&#39;: 28, &#39;t&#39;: 7, &#39;action&#39;: None, &#39;reward&#39;: 2.8759979852983815, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.88)
77% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0
Environment.act() [POST]: location: (8, 3), heading: (0, -1), action: right, reward: 1.16141298794
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;right&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frrNN&#39;, &#39;deadline&#39;: 27, &#39;t&#39;: 8, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.1614129879381796, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frrNN
Agent drove right instead of forward. (rewarded 1.16)
74% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0
Environment.act() [POST]: location: (8, 2), heading: (0, -1), action: forward, reward: 1.58234612786
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgfNf&#39;, &#39;deadline&#39;: 26, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.5823461278573268, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgfNf
Agent drove forward instead of left. (rewarded 1.58)
71% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0
Environment.act() [POST]: location: (7, 2), heading: (-1, 0), action: left, reward: 2.79370068922
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 10, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.7937006892230363, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 2.79)
69% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0
Environment.act() [POST]: location: (7, 7), heading: (0, -1), action: right, reward: 1.59126935314
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNl&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 11, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.5912693531372792, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNl
Agent followed the waypoint right. (rewarded 1.59)
66% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0
Environment.act() [POST]: location: (7, 7), heading: (0, -1), action: forward, reward: -10.6363318203
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNrN&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 12, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.63633182026604, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNrN
Agent attempted driving forward through a red light. (rewarded -10.64)
63% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (7, 6), heading: (0, -1), action: forward, reward: 1.48024237656
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNN&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 13, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.48024237655878, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 1.48)
60% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Testing trial 9
\-------------------------

Environment.reset(): Trial set up with start = (6, 6), destination = (2, 3), deadline = 35
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (6, 6), heading: (0, -1), action: None, reward: 0.750454089775
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNl&#39;, &#39;deadline&#39;: 35, &#39;t&#39;: 0, &#39;action&#39;: None, &#39;reward&#39;: 0.7504540897750247, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNl
Agent idled at a green light with oncoming traffic. (rewarded 0.75)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (5, 6), heading: (-1, 0), action: left, reward: 0.895885258532
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNl&#39;, &#39;deadline&#39;: 34, &#39;t&#39;: 1, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.8958852585322645, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNl
Agent drove left instead of right. (rewarded 0.90)
94% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (5, 5), heading: (0, -1), action: right, reward: 1.38346498672
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 33, &#39;t&#39;: 2, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.3834649867236537, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 1.38)
91% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (6, 5), heading: (1, 0), action: right, reward: 1.34574338259
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrlNN&#39;, &#39;deadline&#39;: 32, &#39;t&#39;: 3, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.3457433825899074, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrlNN
Agent drove right instead of left. (rewarded 1.35)
89% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act() [POST]: location: (6, 4), heading: (0, -1), action: left, reward: 1.62524770965
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNlN&#39;, &#39;deadline&#39;: 31, &#39;t&#39;: 4, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.6252477096485722, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNlN
Agent drove left instead of forward. (rewarded 1.63)
86% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Environment.step(): t = 5
0
Environment.act() [POST]: location: (7, 4), heading: (1, 0), action: right, reward: 2.82398126868
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 30, &#39;t&#39;: 5, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.823981268680545, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent followed the waypoint right. (rewarded 2.82)
83% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Environment.step(): t = 6
0
Environment.act() [POST]: location: (7, 5), heading: (0, 1), action: right, reward: 1.46216944981
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frNlN&#39;, &#39;deadline&#39;: 29, &#39;t&#39;: 6, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.4621694498050248, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frNlN
Agent drove right instead of forward. (rewarded 1.46)
80% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Environment.step(): t = 7
0
Environment.act() [POST]: location: (7, 6), heading: (0, 1), action: forward, reward: 1.64322071484
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNf&#39;, &#39;deadline&#39;: 28, &#39;t&#39;: 7, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.643220714840357, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNf
Agent drove forward instead of left. (rewarded 1.64)
77% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Environment.step(): t = 8
0
Environment.act() [POST]: location: (7, 7), heading: (0, 1), action: forward, reward: 1.71198303438
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNfN&#39;, &#39;deadline&#39;: 27, &#39;t&#39;: 8, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.711983034375626, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNfN
Agent drove forward instead of left. (rewarded 1.71)
74% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Environment.step(): t = 9
0
Environment.act() [POST]: location: (7, 2), heading: (0, 1), action: forward, reward: 0.554152979878
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNff&#39;, &#39;deadline&#39;: 26, &#39;t&#39;: 9, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.5541529798778189, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNff
Agent drove forward instead of left. (rewarded 0.55)
71% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Environment.step(): t = 10
0
Environment.act() [POST]: location: (7, 2), heading: (0, 1), action: None, reward: 2.42741441875
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNN&#39;, &#39;deadline&#39;: 25, &#39;t&#39;: 10, &#39;action&#39;: None, &#39;reward&#39;: 2.4274144187458466, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.43)
69% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Environment.step(): t = 11
0
Environment.act() [POST]: location: (8, 2), heading: (1, 0), action: left, reward: 2.25515983613
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 24, &#39;t&#39;: 11, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 2.2551598361258236, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 2.26)
66% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Environment.step(): t = 12
0
Environment.act() [POST]: location: (8, 3), heading: (0, 1), action: right, reward: 0.910511195483
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNf&#39;, &#39;deadline&#39;: 23, &#39;t&#39;: 12, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.9105111954825286, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNf
Agent drove right instead of forward. (rewarded 0.91)
63% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Environment.step(): t = 13
0
Environment.act() [POST]: location: (7, 3), heading: (-1, 0), action: right, reward: 1.57774265801
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lglNN&#39;, &#39;deadline&#39;: 22, &#39;t&#39;: 13, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.5777426580147873, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lglNN
Agent drove right instead of left. (rewarded 1.58)
60% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Environment.step(): t = 14
0
Environment.act() [POST]: location: (7, 2), heading: (0, -1), action: right, reward: 2.6809740369
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNN&#39;, &#39;deadline&#39;: 21, &#39;t&#39;: 14, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.68097403690441, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNN
Agent followed the waypoint right. (rewarded 2.68)
57% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Environment.step(): t = 15
0
Environment.act() [POST]: location: (7, 7), heading: (0, -1), action: forward, reward: 0.60816978137
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgfNl&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 15, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.6081697813702313, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgfNl
Agent drove forward instead of right. (rewarded 0.61)
54% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Environment.step(): t = 16
0
Environment.act() [POST]: location: (7, 7), heading: (0, -1), action: right, reward: -20.2686806284
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 3, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNfl&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 16, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -20.26868062841257, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNfl
Agent attempted driving right through traffic and cause a minor accident. (rewarded -20.27)
51% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Environment.step(): t = 17
0
Environment.act() [POST]: location: (8, 7), heading: (1, 0), action: right, reward: 1.04198447673
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNl&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 17, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.0419844767315674, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNl
Agent followed the waypoint right. (rewarded 1.04)
49% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Environment.step(): t = 18
0
Environment.act() [POST]: location: (8, 2), heading: (0, 1), action: right, reward: -0.130966718616
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNNl&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 18, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -0.1309667186157022, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNNl
Agent drove right instead of forward. (rewarded -0.13)
46% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Environment.step(): t = 19
0
Environment.act() [POST]: location: (7, 2), heading: (-1, 0), action: right, reward: 0.544176243896
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNr&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 19, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.5441762438958196, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNr
Agent drove right instead of left. (rewarded 0.54)
43% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Environment.step(): t = 20
0
Environment.act() [POST]: location: (7, 7), heading: (0, -1), action: right, reward: 1.52406970529
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNl&#39;, &#39;deadline&#39;: 15, &#39;t&#39;: 20, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.524069705293263, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNl
Agent drove right instead of left. (rewarded 1.52)
40% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Environment.step(): t = 21
0
Environment.act() [POST]: location: (7, 6), heading: (0, -1), action: forward, reward: 1.44192066354
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgllf&#39;, &#39;deadline&#39;: 14, &#39;t&#39;: 21, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.4419206635381012, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgllf
Agent drove forward instead of right. (rewarded 1.44)
37% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Environment.step(): t = 22
0
Environment.act() [POST]: location: (7, 6), heading: (0, -1), action: right, reward: -20.2496176709
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;right&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 3, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNfr&#39;, &#39;deadline&#39;: 13, &#39;t&#39;: 22, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: -20.24961767085678, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNfr
Agent attempted driving right through traffic and cause a minor accident. (rewarded -20.25)
34% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Environment.step(): t = 23
0
Environment.act() [POST]: location: (8, 6), heading: (1, 0), action: right, reward: 2.59645802458
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrNNl&#39;, &#39;deadline&#39;: 12, &#39;t&#39;: 23, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 2.5964580245819833, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrNNl
Agent followed the waypoint right. (rewarded 2.60)
31% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Environment.step(): t = 24
0
Environment.act() [POST]: location: (8, 7), heading: (0, 1), action: right, reward: 1.31465643575
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;frlNN&#39;, &#39;deadline&#39;: 11, &#39;t&#39;: 24, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.3146564357498831, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 1.31)
29% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Environment.step(): t = 25
0
Environment.act() [POST]: location: (1, 7), heading: (1, 0), action: left, reward: 0.545727795634
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 10, &#39;t&#39;: 25, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.5457277956343811, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 0.55)
26% of time remaining to reach destination.

/-------------------
| Step 26 Results
\-------------------

Environment.step(): t = 26
0
Environment.act() [POST]: location: (2, 7), heading: (1, 0), action: forward, reward: 1.80094135343
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNfN&#39;, &#39;deadline&#39;: 9, &#39;t&#39;: 26, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 1.8009413534267698, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNfN
Agent followed the waypoint forward. (rewarded 1.80)
23% of time remaining to reach destination.

/-------------------
| Step 27 Results
\-------------------

Environment.step(): t = 27
0
Environment.act() [POST]: location: (3, 7), heading: (1, 0), action: forward, reward: 0.828761780605
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglfN&#39;, &#39;deadline&#39;: 8, &#39;t&#39;: 27, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 0.8287617806046447, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglfN
Agent drove forward instead of right. (rewarded 0.83)
20% of time remaining to reach destination.

/-------------------
| Step 28 Results
\-------------------

Environment.step(): t = 28
0
Environment.act() [POST]: location: (3, 2), heading: (0, 1), action: right, reward: 1.86556651097
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNN&#39;, &#39;deadline&#39;: 7, &#39;t&#39;: 28, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.8655665109683386, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNN
Agent followed the waypoint right. (rewarded 1.87)
17% of time remaining to reach destination.

/-------------------
| Step 29 Results
\-------------------

Environment.step(): t = 29
0
Environment.act() [POST]: location: (4, 2), heading: (1, 0), action: left, reward: 1.3606721537
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;left&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rgNNl&#39;, &#39;deadline&#39;: 6, &#39;t&#39;: 29, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.3606721536982698, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rgNNl
Agent drove left instead of right. (rewarded 1.36)
14% of time remaining to reach destination.

/-------------------
| Step 30 Results
\-------------------

Environment.step(): t = 30
0
Environment.act() [POST]: location: (4, 2), heading: (1, 0), action: None, reward: 2.10371261856
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrlNN&#39;, &#39;deadline&#39;: 5, &#39;t&#39;: 30, &#39;action&#39;: None, &#39;reward&#39;: 2.1037126185645914, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrlNN
Agent properly idled at a red light. (rewarded 2.10)
11% of time remaining to reach destination.

/-------------------
| Step 31 Results
\-------------------

Environment.step(): t = 31
0
Environment.act() [POST]: location: (4, 7), heading: (0, -1), action: left, reward: -0.16644340318
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 4, &#39;t&#39;: 31, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: -0.1664434031804366, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent drove left instead of right. (rewarded -0.17)
9% of time remaining to reach destination.

/-------------------
| Step 32 Results
\-------------------

Environment.step(): t = 32
0
Environment.act() [POST]: location: (5, 7), heading: (1, 0), action: right, reward: 0.711644318092
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;lrNNf&#39;, &#39;deadline&#39;: 3, &#39;t&#39;: 32, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 0.7116443180924024, &#39;waypoint&#39;: &#39;left&#39;}
Agent previous state: lrNNf
Agent drove right instead of left. (rewarded 0.71)
6% of time remaining to reach destination.

/-------------------
| Step 33 Results
\-------------------

Environment.step(): t = 33
0
Environment.act() [POST]: location: (5, 6), heading: (0, -1), action: left, reward: 0.737058265265
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;left&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;rglNN&#39;, &#39;deadline&#39;: 2, &#39;t&#39;: 33, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 0.7370582652651767, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rglNN
Agent drove left instead of right. (rewarded 0.74)
3% of time remaining to reach destination.

/-------------------
| Step 34 Results
\-------------------

Environment.step(): t = 34
0
Environment.act() [POST]: location: (4, 6), heading: (-1, 0), action: left, reward: 1.55526927346
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;lgNNN&#39;, &#39;deadline&#39;: 1, &#39;t&#39;: 34, &#39;action&#39;: &#39;left&#39;, &#39;reward&#39;: 1.555269273462769, &#39;waypoint&#39;: &#39;left&#39;}
Environment.step(): Primary agent ran out of time! Trial aborted.
Agent previous state: lgNNN
Agent followed the waypoint left. (rewarded 1.56)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Testing trial 10
\-------------------------

Environment.reset(): Trial set up with start = (7, 7), destination = (1, 3), deadline = 20
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Environment.step(): t = 0
0
Environment.act() [POST]: location: (7, 7), heading: (0, -1), action: forward, reward: -10.1183138831
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;left&#39;}, &#39;violation&#39;: 2, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrflN&#39;, &#39;deadline&#39;: 20, &#39;t&#39;: 0, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: -10.118313883078466, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrflN
Agent attempted driving forward through a red light. (rewarded -10.12)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Environment.step(): t = 1
0
Environment.act() [POST]: location: (8, 7), heading: (1, 0), action: right, reward: 1.77178853007
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfNN&#39;, &#39;deadline&#39;: 19, &#39;t&#39;: 1, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.771788530070334, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfNN
Agent followed the waypoint right. (rewarded 1.77)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Environment.step(): t = 2
0
Environment.act() [POST]: location: (1, 7), heading: (1, 0), action: forward, reward: 2.93165893504
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: None, &#39;right&#39;: &#39;forward&#39;, &#39;left&#39;: &#39;forward&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgNff&#39;, &#39;deadline&#39;: 18, &#39;t&#39;: 2, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.9316589350429343, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgNff
Agent followed the waypoint forward. (rewarded 2.93)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Environment.step(): t = 3
0
Environment.act() [POST]: location: (1, 2), heading: (0, 1), action: right, reward: 1.79666486674
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;red&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: &#39;right&#39;}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;red&#39;, &#39;state&#39;: &#39;rrfrN&#39;, &#39;deadline&#39;: 17, &#39;t&#39;: 3, &#39;action&#39;: &#39;right&#39;, &#39;reward&#39;: 1.7966648667353378, &#39;waypoint&#39;: &#39;right&#39;}
Agent previous state: rrfrN
Agent followed the waypoint right. (rewarded 1.80)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Environment.step(): t = 4
0
Environment.act(): Primary agent has reached destination!
Environment.act() [POST]: location: (1, 3), heading: (0, 1), action: forward, reward: 2.53406843635
Environment.act(): Step data: {&#39;inputs&#39;: {&#39;light&#39;: &#39;green&#39;, &#39;oncoming&#39;: &#39;forward&#39;, &#39;right&#39;: None, &#39;left&#39;: None}, &#39;violation&#39;: 0, &#39;light&#39;: &#39;green&#39;, &#39;state&#39;: &#39;fgfNN&#39;, &#39;deadline&#39;: 16, &#39;t&#39;: 4, &#39;action&#39;: &#39;forward&#39;, &#39;reward&#39;: 2.534068436351859, &#39;waypoint&#39;: &#39;forward&#39;}
Agent previous state: fgfNN
Agent followed the waypoint forward. (rewarded 2.53)
75% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

Simulation ended. . . 
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[35]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Load the &#39;sim_default-learning&#39; file from the default Q-Learning simulation</span>
<span class="n">vs</span><span class="o">.</span><span class="n">plot_trials</span><span class="p">(</span><span class="s1">&#39;sim_default-learning.csv&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA1gAAAI4CAYAAAB3HEhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Question-6">Question 6<a class="anchor-link" href="#Question-6">&#182;</a></h3><p>Using the visualization above that was produced from your default Q-Learning simulation, provide an analysis and make observations about the driving agent like in <strong>Question 3</strong>. Note that the simulation should have also produced the Q-table in a text file which can help you make observations about the agent's learning. Some additional things you could consider:</p>
<ul>
<li><em>Are there any observations that are similar between the basic driving agent and the default Q-Learning agent?</em></li>
<li><em>Approximately how many training trials did the driving agent require before testing? Does that number make sense given the epsilon-tolerance?</em></li>
<li><em>Is the decaying function you implemented for $\epsilon$ (the exploration factor) accurately represented in the parameters panel?</em></li>
<li><em>As the number of training trials increased, did the number of bad actions decrease? Did the average reward increase?</em></li>
<li><em>How does the safety and reliability rating compare to the initial driving agent?</em></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Answer:</strong></p>
<ul>
<li>Firstly, we still have the same number of Accident like the "major Accident" is stay in same amount between 0.04 and 0.1.</li>
<li>The number of traning the agent is 20 time. Comper that to the epsilon value wich started at 1 and end at -3.1918911958e-16 which is very close to the Zero.</li>
<li>Yes, the decaying function work and the exploration factor </li>
<li>Of course by the time of training the bad actions decrease the frequency of them from to 0.438 to 0.2, and the avarge of the reward incresed from about -5.5 to about -2.</li>
<li>The Safty rating is F and Reliability rating D.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Improve-the-Q-Learning-Driving-Agent">Improve the Q-Learning Driving Agent<a class="anchor-link" href="#Improve-the-Q-Learning-Driving-Agent">&#182;</a></h2><p>The third step to creating an optimized Q-Learning agent is to perform the optimization! Now that the Q-Learning algorithm is implemented and the driving agent is successfully learning, it's necessary to tune settings and adjust learning paramaters so the driving agent learns both <strong>safety</strong> and <strong>efficiency</strong>. Typically this step will require a lot of trial and error, as some settings will invariably make the learning worse. One thing to keep in mind is the act of learning itself and the time that this takes: In theory, we could allow the agent to learn for an incredibly long amount of time; however, another goal of Q-Learning is to <em>transition from experimenting with unlearned behavior to acting on learned behavior</em>. For example, always allowing the agent to perform a random action during training (if $\epsilon = 1$ and never decays) will certainly make it <em>learn</em>, but never let it <em>act</em>. When improving on your Q-Learning implementation, consider the impliciations it creates and whether it is logistically sensible to make a particular adjustment.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Improved-Q-Learning-Simulation-Results">Improved Q-Learning Simulation Results<a class="anchor-link" href="#Improved-Q-Learning-Simulation-Results">&#182;</a></h3><p>To obtain results from the initial Q-Learning implementation, you will need to adjust the following flags and setup:</p>
<ul>
<li><code>'enforce_deadline'</code> - Set this to <code>True</code> to force the driving agent to capture whether it reaches the destination in time.</li>
<li><code>'update_delay'</code> - Set this to a small value (such as <code>0.01</code>) to reduce the time between steps in each trial.</li>
<li><code>'log_metrics'</code> - Set this to <code>True</code> to log the simluation results as a <code>.csv</code> file and the Q-table as a <code>.txt</code> file in <code>/logs/</code>.</li>
<li><code>'learning'</code> - Set this to <code>'True'</code> to tell the driving agent to use your Q-Learning implementation.</li>
<li><code>'optimized'</code> - Set this to <code>'True'</code> to tell the driving agent you are performing an optimized version of the Q-Learning implementation.</li>
</ul>
<p>Additional flags that can be adjusted as part of optimizing the Q-Learning agent:</p>
<ul>
<li><code>'n_test'</code> - Set this to some positive number (previously 10) to perform that many testing trials.</li>
<li><code>'alpha'</code> - Set this to a real number between 0 - 1 to adjust the learning rate of the Q-Learning algorithm.</li>
<li><code>'epsilon'</code> - Set this to a real number between 0 - 1 to adjust the starting exploration factor of the Q-Learning algorithm.</li>
<li><code>'tolerance'</code> - set this to some small value larger than 0 (default was 0.05) to set the epsilon threshold for testing.</li>
</ul>
<p>Furthermore, use a decaying function of your choice for $\epsilon$ (the exploration factor). Note that whichever function you use, it <strong>must decay to </strong><code>'tolerance'</code><strong> at a reasonable rate</strong>. The Q-Learning agent will not begin testing until this occurs. Some example decaying functions (for $t$, the number of trials):</p>
$$ \epsilon = a^t, \textrm{for } 0 < a < 1 \hspace{50px}\epsilon = \frac{1}{t^2}\hspace{50px}\epsilon = e^{-at}, \textrm{for } 0 < a < 1 \hspace{50px} \epsilon = \cos(at), \textrm{for } 0 < a < 1$$<p>You may also use a decaying function for $\alpha$ (the learning rate) if you so choose, however this is typically less common. If you do so, be sure that it adheres to the inequality $0 \leq \alpha \leq 1$.</p>
<p>If you have difficulty getting your implementation to work, try setting the <code>'verbose'</code> flag to <code>True</code> to help debug. Flags that have been set here should be returned to their default setting when debugging. It is important that you understand what each flag does and how it affects the simulation!</p>
<p>Once you have successfully completed the improved Q-Learning simulation, run the code cell below to visualize the results. Note that log files are overwritten when identical simulations are run, so be careful with what log file is being loaded!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[67]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="o">%</span><span class="k">run</span>  smartcab/agent.py
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>
/-------------------------
| Training trial 1
\-------------------------

test Epsilon0.5
Simulating trial. . . 
epsilon = 1.0000; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: fglrf
Agent drove right instead of forward. (rewarded 0.08)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: lgNff
Agent drove forward instead of left. (rewarded 0.77)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: lgNlN
Agent drove right instead of left. (rewarded 0.97)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: frNNN
Agent drove right instead of forward. (rewarded 0.87)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: lrNff
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -39.58)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: lrNlN
Agent attempted driving left through a red light. (rewarded -10.28)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: lrfrl
Agent drove right instead of left. (rewarded 1.02)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: fgrNN
Agent idled at a green light with no oncoming traffic. (rewarded -5.06)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: fgNNf
Agent followed the waypoint forward. (rewarded 1.69)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: fgNfN
Agent drove right instead of forward. (rewarded 1.40)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: lrNNN
Agent drove right instead of left. (rewarded 0.75)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: rgNNN
Agent drove left instead of right. (rewarded 0.47)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: lrflN
Agent attempted driving left through a red light. (rewarded -10.86)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: lgfNN
Agent drove right instead of left. (rewarded 1.70)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: frNNN
Agent attempted driving forward through a red light. (rewarded -9.67)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: frNNN
Agent attempted driving forward through a red light. (rewarded -9.85)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 1.85)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: frNlN
Agent attempted driving left through a red light. (rewarded -10.38)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: frrff
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.70)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: frrNN
Agent properly idled at a red light. (rewarded 2.36)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.19)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: fgNll
Agent idled at a green light with no oncoming traffic. (rewarded -5.22)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: fgrll
Agent followed the waypoint forward. (rewarded 0.67)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: fgrNf
Agent attempted driving left through traffic and cause a minor accident. (rewarded -20.38)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: fgfNf
Agent followed the waypoint forward. (rewarded 0.96)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 2
\-------------------------

test Epsilon1.0
Simulating trial. . . 
epsilon = 0.6550; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: lglNl
Agent drove forward instead of left. (rewarded 1.28)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: lgNlN
Agent drove right instead of left. (rewarded 0.75)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: rrlNr
Agent attempted driving forward through a red light. (rewarded -10.60)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: rglNr
Agent drove forward instead of right. (rewarded 1.31)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: rgfNN
Agent idled at a green light with no oncoming traffic. (rewarded -4.43)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: rgNNN
Agent drove left instead of right. (rewarded 0.60)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: fglNN
Agent drove right instead of forward. (rewarded 1.57)
77% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: lgNNN
Agent idled at a green light with no oncoming traffic. (rewarded -5.30)
73% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.55)
70% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: lrNNl
Agent attempted driving forward through a red light. (rewarded -10.19)
67% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.42)
63% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: lglNN
Agent drove right instead of left. (rewarded 0.94)
60% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: fgfNf
Agent drove right instead of forward. (rewarded 0.81)
57% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: lglNN
Agent drove right instead of left. (rewarded 1.33)
53% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: fgNfr
Agent drove left instead of forward. (rewarded 0.65)
50% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: rgNrf
Agent followed the waypoint right. (rewarded 1.70)
47% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 0.18)
43% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: lgrNl
Agent idled at a green light with no oncoming traffic. (rewarded -4.93)
40% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: lgNll
Agent drove forward instead of left. (rewarded 0.34)
37% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: lgrNl
Agent drove forward instead of left. (rewarded 1.60)
33% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: lrNNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.25)
30% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.83)
27% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: lglNl
Agent drove right instead of left. (rewarded 0.81)
23% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 0.81)
20% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: rrNlN
Agent attempted driving forward through a red light. (rewarded -10.92)
17% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Agent previous state: rgNNN
Agent drove left instead of right. (rewarded 1.34)
13% of time remaining to reach destination.

/-------------------
| Step 26 Results
\-------------------

Agent previous state: lgNNr
Agent followed the waypoint left. (rewarded 2.08)
10% of time remaining to reach destination.

/-------------------
| Step 27 Results
\-------------------

Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 1.54)
7% of time remaining to reach destination.

/-------------------
| Step 28 Results
\-------------------

Agent previous state: fgNNf
Agent followed the waypoint forward. (rewarded 1.75)
3% of time remaining to reach destination.

/-------------------
| Step 29 Results
\-------------------

Agent previous state: rgllN
Agent drove forward instead of right. (rewarded 0.84)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 3
\-------------------------

test Epsilon0.655
Simulating trial. . . 
epsilon = 0.4290; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: lgNNl
Agent drove forward instead of left. (rewarded 0.10)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: lgfll
Agent drove forward instead of left. (rewarded 0.47)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: lrllN
Agent attempted driving left through a red light. (rewarded -9.91)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: lrlNN
Agent attempted driving forward through a red light. (rewarded -9.73)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: lglNN
Agent idled at a green light with oncoming traffic. (rewarded 0.49)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: lglNN
Agent drove right instead of left. (rewarded 1.90)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: frNff
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.60)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.35)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: frNNr
Agent attempted driving forward through a red light. (rewarded -9.16)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: frNNN
Agent attempted driving forward through a red light. (rewarded -9.62)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: frNNN
Agent attempted driving left through a red light. (rewarded -9.63)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: fglNN
Agent drove right instead of forward. (rewarded 1.46)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: lgNfl
Agent drove forward instead of left. (rewarded 0.54)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: lrNrl
Agent attempted driving left through a red light. (rewarded -9.78)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: lrffl
Agent properly idled at a red light. (rewarded 2.40)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: lrffl
Agent properly idled at a red light. (rewarded 1.57)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: lrfNl
Agent attempted driving forward through a red light. (rewarded -10.87)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: lgfNN
Agent drove right instead of left. (rewarded 0.74)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: frNrN
Agent drove right instead of forward. (rewarded 1.24)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: lrNNl
Agent drove right instead of left. (rewarded -0.00)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: fgNff
Agent followed the waypoint forward. (rewarded 2.16)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: fgNNN
Agent followed the waypoint forward. (rewarded 0.42)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: frNNl
Agent drove right instead of forward. (rewarded 0.19)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: lgrNl
Agent drove forward instead of left. (rewarded -0.69)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: lgNfl
Agent drove right instead of left. (rewarded 0.05)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 4
\-------------------------

test Epsilon0.429025
Simulating trial. . . 
epsilon = 0.2810; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: rgNNN
Agent drove left instead of right. (rewarded 0.34)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: rrlNN
Agent attempted driving forward through a red light. (rewarded -9.12)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: rrlNN
Agent followed the waypoint right. (rewarded 1.49)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: rrNlN
Agent followed the waypoint right. (rewarded 2.06)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: frlNN
Agent attempted driving forward through a red light. (rewarded -9.23)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: fglrN
Agent followed the waypoint forward. (rewarded 2.33)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 1.20)
77% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: lgNfN
Agent drove forward instead of left. (rewarded 0.22)
73% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: lrffN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.04)
70% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: lgfNN
Agent drove right instead of left. (rewarded 0.95)
67% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: lglNf
Agent drove forward instead of left. (rewarded 1.31)
63% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: lgNfN
Agent idled at a green light with no oncoming traffic. (rewarded -4.18)
60% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: lgNfN
Agent drove forward instead of left. (rewarded 1.09)
57% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: fgfNN
Agent attempted driving left through traffic and cause a minor accident. (rewarded -20.10)
53% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded -0.16)
50% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: lrfNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.63)
47% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: lgfNl
Agent drove forward instead of left. (rewarded -0.26)
43% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: lrNNN
Agent attempted driving left through a red light. (rewarded -9.38)
40% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: lrflf
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -39.35)
37% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: lrllN
Agent drove right instead of left. (rewarded 0.13)
33% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: fglNl
Agent followed the waypoint forward. (rewarded 0.94)
30% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: fgNNl
Agent followed the waypoint forward. (rewarded 1.88)
27% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded -0.01)
23% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: lgNNr
Agent followed the waypoint left. (rewarded 1.33)
20% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: frlNN
Agent attempted driving forward through a red light. (rewarded -10.14)
17% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 1.34)
13% of time remaining to reach destination.

/-------------------
| Step 26 Results
\-------------------

Agent previous state: lrNNf
Agent drove right instead of left. (rewarded 0.26)
10% of time remaining to reach destination.

/-------------------
| Step 27 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.68)
7% of time remaining to reach destination.

/-------------------
| Step 28 Results
\-------------------

Agent previous state: lgNNf
Agent drove forward instead of left. (rewarded 0.45)
3% of time remaining to reach destination.

/-------------------
| Step 29 Results
\-------------------

Agent previous state: lrNNN
Agent drove right instead of left. (rewarded -0.29)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 5
\-------------------------

test Epsilon0.281011375
Simulating trial. . . 
epsilon = 0.1841; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: lgffN
Agent drove forward instead of left. (rewarded 0.11)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: lgrll
Agent drove forward instead of left. (rewarded 0.37)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 2.57)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.05)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: lglNN
Agent drove forward instead of left. (rewarded 1.15)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: lgrfl
Agent attempted driving left through traffic and cause a minor accident. (rewarded -20.51)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: lrNfl
Agent properly idled at a red light. (rewarded 1.60)
77% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: lrNNl
Agent properly idled at a red light. (rewarded 1.63)
73% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.43)
70% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: lrNrN
Agent attempted driving forward through a red light. (rewarded -9.74)
67% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: lrNNN
Agent attempted driving forward through a red light. (rewarded -10.69)
63% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded -0.03)
60% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: lrlrN
Agent properly idled at a red light. (rewarded 2.46)
57% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: lglNN
Agent drove right instead of left. (rewarded 1.07)
53% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: rrrNN
Agent attempted driving forward through a red light. (rewarded -9.66)
50% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: rrNNN
Agent attempted driving forward through a red light. (rewarded -9.32)
47% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: rrNNN
Agent attempted driving forward through a red light. (rewarded -10.45)
43% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: rgNNN
Agent drove left instead of right. (rewarded 1.57)
40% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: lrfNl
Agent drove right instead of left. (rewarded 0.90)
37% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: fgrlf
Agent followed the waypoint forward. (rewarded 0.76)
33% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 0.16)
30% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: lgfNN
Agent drove right instead of left. (rewarded 0.28)
27% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: lrNNl
Agent attempted driving left through a red light. (rewarded -10.45)
23% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: lrfNN
Agent attempted driving forward through a red light. (rewarded -10.34)
20% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: lrlfN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.66)
17% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Agent previous state: lglNN
Agent drove right instead of left. (rewarded 0.44)
13% of time remaining to reach destination.

/-------------------
| Step 26 Results
\-------------------

Agent previous state: rrfNl
Agent attempted driving forward through a red light. (rewarded -9.06)
10% of time remaining to reach destination.

/-------------------
| Step 27 Results
\-------------------

Agent previous state: rrlNN
Agent followed the waypoint right. (rewarded 1.64)
7% of time remaining to reach destination.

/-------------------
| Step 28 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.57)
3% of time remaining to reach destination.

/-------------------
| Step 29 Results
\-------------------

Agent previous state: frlNN
Agent drove right instead of forward. (rewarded -0.01)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 6
\-------------------------

test Epsilon0.184062450625
Simulating trial. . . 
epsilon = 0.1206; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.05)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.32)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: frNlN
Agent attempted driving forward through a red light. (rewarded -9.55)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.44)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.84)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: fgNlN
Agent followed the waypoint forward. (rewarded 2.30)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.18)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: fgrNN
Agent attempted driving left through traffic and cause a minor accident. (rewarded -19.65)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 1.44)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: lrflN
Agent attempted driving forward through a red light. (rewarded -9.69)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: lgflN
Agent drove forward instead of left. (rewarded 0.11)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded -0.03)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: lgNff
Agent drove forward instead of left. (rewarded -0.09)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: lgNlN
Agent drove right instead of left. (rewarded -0.30)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: rrlrr
Agent attempted driving forward through a red light. (rewarded -9.76)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: rrlNN
Agent followed the waypoint right. (rewarded 2.43)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: rgNNl
Agent drove forward instead of right. (rewarded -0.55)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: rglNN
Agent drove forward instead of right. (rewarded 0.41)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: rgfNN
Agent drove forward instead of right. (rewarded -0.76)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: rgNlN
Agent drove forward instead of right. (rewarded 0.81)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 7
\-------------------------

test Epsilon0.120560905159
Simulating trial. . . 
epsilon = 0.0790; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: rrffl
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.79)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: rrfNN
Agent attempted driving forward through a red light. (rewarded -10.61)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: rrlNN
Agent followed the waypoint right. (rewarded 2.28)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 0.50)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: lgNfN
Agent drove forward instead of left. (rewarded 1.74)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.65)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: lgNNf
Agent drove forward instead of left. (rewarded 0.41)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: lrNlN
Agent attempted driving forward through a red light. (rewarded -10.57)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: lrflN
Agent drove right instead of left. (rewarded 1.23)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: rrNNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.14)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 0.96)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: rgNNN
Agent drove left instead of right. (rewarded 0.90)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: lgNfN
Agent drove forward instead of left. (rewarded 1.73)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.18)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: lrNfN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.70)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: lrrNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.97)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: lgrrN
Agent attempted driving left through traffic and cause a minor accident. (rewarded -19.22)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.19)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: lgNNl
Agent drove forward instead of left. (rewarded -0.12)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: lgNNl
Agent drove right instead of left. (rewarded 1.12)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: lrffN
Agent attempted driving right through traffic and cause a minor accident. (rewarded -20.92)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: lgfNN
Agent drove right instead of left. (rewarded 0.28)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: rrlNN
Agent followed the waypoint right. (rewarded 1.91)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: fgNNl
Agent followed the waypoint forward. (rewarded 2.00)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: fglNf
Agent followed the waypoint forward. (rewarded 0.48)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 8
\-------------------------

test Epsilon0.0789673928794
Simulating trial. . . 
epsilon = 0.0517; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 2.58)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 1.83)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 1.03)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 2.24)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: rgNNN
Agent drove left instead of right. (rewarded 1.35)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: frrrN
Agent attempted driving forward through a red light. (rewarded -9.98)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: fglNN
Agent drove right instead of forward. (rewarded 1.31)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.39)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: lrfNN
Agent drove right instead of left. (rewarded 0.07)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: frNll
Agent attempted driving forward through a red light. (rewarded -10.78)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: frNNf
Agent attempted driving left through a red light with traffic and cause a major accident. (rewarded -39.16)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.22)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: frllr
Agent attempted driving forward through a red light. (rewarded -10.77)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: fgllN
Agent followed the waypoint forward. (rewarded 0.86)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: frfNl
Agent attempted driving forward through a red light. (rewarded -9.76)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: frfNN
Agent attempted driving forward through a red light. (rewarded -10.45)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: fgfNN
Agent followed the waypoint forward. (rewarded 0.93)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded -0.34)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: lrNlr
Agent attempted driving forward through a red light. (rewarded -10.98)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: lrNlf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.81)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.63)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: lglNr
Agent drove forward instead of left. (rewarded -0.13)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: lgfNN
Agent drove right instead of left. (rewarded -0.11)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: lgrNN
Agent drove forward instead of left. (rewarded 0.32)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: lrfNN
Agent drove right instead of left. (rewarded -0.55)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 9
\-------------------------

test Epsilon0.051723642336
Simulating trial. . . 
epsilon = 0.0339; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: frffN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.01)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: frfNN
Agent drove right instead of forward. (rewarded 1.69)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.60)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.31)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.24)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: lglNN
Agent drove right instead of left. (rewarded 0.54)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: lglNN
Agent drove right instead of left. (rewarded 1.67)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: rrfNl
Agent followed the waypoint right. (rewarded 1.42)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.86)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.35)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: fglNN
Agent drove right instead of forward. (rewarded 1.50)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: lrfNr
Agent attempted driving forward through a red light. (rewarded -10.52)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: lrlNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.27)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: lglNN
Agent drove right instead of left. (rewarded 0.22)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded -0.12)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: frNrl
Agent attempted driving forward through a red light. (rewarded -9.78)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: frNNl
Agent drove right instead of forward. (rewarded 0.60)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: lgNlf
Agent drove forward instead of left. (rewarded 0.17)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: lrNNr
Agent attempted driving forward through a red light. (rewarded -10.91)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: lgNfl
Agent drove forward instead of left. (rewarded -0.02)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 10
\-------------------------

test Epsilon0.0338789857301
Simulating trial. . . 
epsilon = 0.0222; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: fglfl
Agent followed the waypoint forward. (rewarded 1.75)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: frlNl
Agent attempted driving forward through a red light. (rewarded -9.40)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 1.75)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.08)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: lgNrN
Agent idled at a green light with no oncoming traffic. (rewarded -4.04)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.77)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: lgNNl
Agent drove right instead of left. (rewarded 1.28)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: lrNlN
Agent drove right instead of left. (rewarded 0.67)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: rgNNf
Agent drove forward instead of right. (rewarded 0.01)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: rrffN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.53)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: rrfrN
Agent attempted driving forward through a red light. (rewarded -10.64)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: rrfNN
Agent followed the waypoint right. (rewarded 1.61)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: fgNlN
Agent followed the waypoint forward. (rewarded 1.48)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: fgNfl
Agent followed the waypoint forward. (rewarded 2.42)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: lgNlN
Agent drove right instead of left. (rewarded 1.33)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: fgNlN
Agent followed the waypoint forward. (rewarded 2.19)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: frNfN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.84)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 0.88)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 0.60)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: frNNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.35)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.66)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: fglNr
Agent followed the waypoint forward. (rewarded 1.74)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: fgNfl
Agent followed the waypoint forward. (rewarded 1.73)
8% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Training trial 11
\-------------------------

test Epsilon0.0221907356532
Simulating trial. . . 
epsilon = 0.0145; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 1.55)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 0.19)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: lgNll
Agent drove forward instead of left. (rewarded 1.92)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: lgNll
Agent drove forward instead of left. (rewarded 0.38)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: lrNff
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.45)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: lrrNN
Agent attempted driving forward through a red light. (rewarded -9.84)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.24)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 1.88)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.85)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.79)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: lrNlN
Agent drove right instead of left. (rewarded 1.18)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: frNNf
Agent drove right instead of forward. (rewarded -0.17)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: lgNNr
Agent followed the waypoint left. (rewarded 1.70)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: frrNN
Agent properly idled at a red light. (rewarded 1.11)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: frfNN
Agent drove right instead of forward. (rewarded -0.01)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: lgNff
Agent drove forward instead of left. (rewarded -0.16)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: lrNlr
Agent drove right instead of left. (rewarded 1.52)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: rrffN
Agent attempted driving right through traffic and cause a minor accident. (rewarded -19.84)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: rrffN
Agent properly idled at a red light. (rewarded 1.80)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: rgfNN
Agent followed the waypoint right. (rewarded 1.71)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: rglNf
Agent drove forward instead of right. (rewarded 0.13)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: rrNNf
Agent followed the waypoint right. (rewarded 0.98)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: frrNN
Agent properly idled at a red light. (rewarded 0.78)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: frflN
Agent attempted driving forward through a red light. (rewarded -9.45)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: frfrN
Agent attempted driving forward through a red light. (rewarded -10.65)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 12
\-------------------------

test Epsilon0.0145349318528
Simulating trial. . . 
epsilon = 0.0095; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: rrrrl
Agent attempted driving forward through a red light. (rewarded -9.90)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: rrfNl
Agent followed the waypoint right. (rewarded 2.74)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: rgNNf
Agent drove forward instead of right. (rewarded 1.38)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: rgNfN
Agent drove forward instead of right. (rewarded 1.60)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: rgNlf
Agent drove forward instead of right. (rewarded 0.17)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: rgNlN
Agent drove forward instead of right. (rewarded 0.12)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: rrlNN
Agent followed the waypoint right. (rewarded 1.19)
77% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: frNNl
Agent drove right instead of forward. (rewarded 0.40)
73% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: lgNrf
Agent drove forward instead of left. (rewarded 0.19)
70% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: lrNfN
Agent attempted driving right through traffic and cause a minor accident. (rewarded -19.91)
67% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.96)
63% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.15)
60% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: lgrfN
Agent drove forward instead of left. (rewarded 1.37)
57% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: lrrlf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.18)
53% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: lrrlN
Agent attempted driving forward through a red light. (rewarded -10.34)
50% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: lrNrN
Agent drove right instead of left. (rewarded 1.04)
47% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: rgfNN
Agent followed the waypoint right. (rewarded 2.21)
43% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: rrNfN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.13)
40% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: rrNNl
Agent attempted driving forward through a red light. (rewarded -9.56)
37% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: rgNNN
Agent drove left instead of right. (rewarded 1.10)
33% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 0.69)
30% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.40)
27% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: fgNlr
Agent followed the waypoint forward. (rewarded 1.48)
23% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: fgNNf
Agent followed the waypoint forward. (rewarded 1.07)
20% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: fgNNl
Agent followed the waypoint forward. (rewarded 2.40)
17% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Agent previous state: frNll
Agent drove right instead of forward. (rewarded -0.03)
13% of time remaining to reach destination.

/-------------------
| Step 26 Results
\-------------------

Agent previous state: lgNrN
Agent drove forward instead of left. (rewarded 0.01)
10% of time remaining to reach destination.

/-------------------
| Step 27 Results
\-------------------

Agent previous state: lrNNf
Agent drove right instead of left. (rewarded 1.04)
7% of time remaining to reach destination.

/-------------------
| Step 28 Results
\-------------------

Agent previous state: rgrNN
Agent drove forward instead of right. (rewarded 0.26)
3% of time remaining to reach destination.

/-------------------
| Step 29 Results
\-------------------

Agent previous state: rrNfN
Agent attempted driving right through traffic and cause a minor accident. (rewarded -20.76)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 13
\-------------------------

test Epsilon0.00952038036362
Simulating trial. . . 
epsilon = 0.0062; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: rrfrf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.79)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: rrflN
Agent attempted driving forward through a red light. (rewarded -10.58)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: rrfNN
Agent followed the waypoint right. (rewarded 2.36)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: rrNfN
Agent properly idled at a red light. (rewarded 1.94)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: rrfNN
Agent followed the waypoint right. (rewarded 1.52)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: lrlrf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.77)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.13)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: lglNN
Agent drove right instead of left. (rewarded 0.63)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: rgrff
Agent drove forward instead of right. (rewarded 1.32)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 0.53)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: lrllN
Agent drove right instead of left. (rewarded 0.04)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: rgfNf
Agent drove forward instead of right. (rewarded 0.84)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: rrlfN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.84)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: rrlNN
Agent followed the waypoint right. (rewarded 1.49)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded -0.19)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: lrlNr
Agent attempted driving forward through a red light. (rewarded -9.42)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: lglNN
Agent drove right instead of left. (rewarded 0.26)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: rrNff
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.75)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 0.72)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 1.17)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 14
\-------------------------

test Epsilon0.00623584913817
Simulating trial. . . 
epsilon = 0.0041; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: lrNNl
Agent properly idled at a red light. (rewarded 1.50)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 2.94)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.35)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.22)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: lglNf
Agent drove forward instead of left. (rewarded 1.39)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 1.43)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: lrllN
Agent drove right instead of left. (rewarded 0.69)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: frlfN
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.30)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 1.54)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: lglNN
Agent drove right instead of left. (rewarded 1.06)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: frNNf
Agent properly idled at a red light. (rewarded 2.33)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: fgNlN
Agent followed the waypoint forward. (rewarded 2.15)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: frllN
Agent attempted driving forward through a red light. (rewarded -10.29)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 0.45)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: lrNfl
Agent properly idled at a red light. (rewarded 1.19)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.49)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.53)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.75)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: lgfNN
Agent drove right instead of left. (rewarded 0.60)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: rgfNf
Agent drove forward instead of right. (rewarded 0.76)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: fgrfl
Agent followed the waypoint forward. (rewarded 1.47)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.57)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: frNrN
Agent drove right instead of forward. (rewarded 0.93)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.88)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: lrrNN
Agent drove right instead of left. (rewarded -0.47)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 15
\-------------------------

test Epsilon0.0040844811855
Simulating trial. . . 
epsilon = 0.0027; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.42)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: lrfNN
Agent properly idled at a red light. (rewarded 1.21)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: lrfNN
Agent properly idled at a red light. (rewarded 1.72)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: lrrNN
Agent properly idled at a red light. (rewarded 2.11)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: lrfrN
Agent attempted driving forward through a red light. (rewarded -9.82)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: lgfrN
Agent drove forward instead of left. (rewarded 0.77)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.79)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: lrNrf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.19)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: lrNrl
Agent attempted driving forward through a red light. (rewarded -9.06)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: lrNNl
Agent properly idled at a red light. (rewarded 1.20)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: lgfNN
Agent drove right instead of left. (rewarded 0.04)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.37)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 0.96)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.96)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: frNNf
Agent properly idled at a red light. (rewarded 1.22)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 0.86)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.06)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: fgNfN
Agent drove right instead of forward. (rewarded -0.26)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: lrflN
Agent drove right instead of left. (rewarded 0.85)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded -0.01)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: lrfNN
Agent properly idled at a red light. (rewarded 0.70)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: lrfrN
Agent drove right instead of left. (rewarded 0.07)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: frrNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.21)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: frfNr
Agent attempted driving forward through a red light. (rewarded -9.08)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: frfNN
Agent drove right instead of forward. (rewarded -0.49)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 16
\-------------------------

test Epsilon0.0026753351765
Simulating trial. . . 
epsilon = 0.0018; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: frNlN
Agent drove right instead of forward. (rewarded 1.15)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.07)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.27)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.32)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.39)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: lglfl
Agent drove forward instead of left. (rewarded 0.54)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: lgllr
Agent drove forward instead of left. (rewarded 0.05)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: lrNlN
Agent drove right instead of left. (rewarded 0.06)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 1.33)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: lrNfl
Agent properly idled at a red light. (rewarded 2.08)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: lrNlN
Agent drove right instead of left. (rewarded 1.15)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: rglNN
Agent drove forward instead of right. (rewarded 0.84)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 1.79)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: rrffN
Agent properly idled at a red light. (rewarded 0.99)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: rrfNN
Agent followed the waypoint right. (rewarded 0.67)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.06)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded -0.36)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: lrNNf
Agent drove right instead of left. (rewarded -0.34)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: lgNff
Agent drove forward instead of left. (rewarded -0.76)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: fgffN
Agent followed the waypoint forward. (rewarded 0.85)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 17
\-------------------------

test Epsilon0.00175234454061
Simulating trial. . . 
epsilon = 0.0011; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: rrfll
Agent attempted driving forward through a red light. (rewarded -10.67)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: rrfrl
Agent attempted driving forward through a red light. (rewarded -10.12)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: rrfNN
Agent followed the waypoint right. (rewarded 2.73)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: frfff
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.73)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: frfNf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.94)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: fgfNl
Agent followed the waypoint forward. (rewarded 1.31)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.67)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: fgNfN
Agent drove right instead of forward. (rewarded 1.58)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: lgNff
Agent drove right instead of left. (rewarded 0.29)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: rglrN
Agent drove forward instead of right. (rewarded 0.02)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: rgNlr
Agent drove forward instead of right. (rewarded 1.20)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: rrlNr
Agent followed the waypoint right. (rewarded 1.82)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: rrNNf
Agent followed the waypoint right. (rewarded 2.42)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: fgrNN
Agent followed the waypoint forward. (rewarded 1.65)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: fgNlN
Agent followed the waypoint forward. (rewarded 1.53)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: fglff
Agent followed the waypoint forward. (rewarded 1.62)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.50)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: lrflf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.90)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: lrfNN
Agent properly idled at a red light. (rewarded 0.53)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: lrffN
Agent properly idled at a red light. (rewarded 0.70)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 18
\-------------------------

test Epsilon0.0011477856741
Simulating trial. . . 
epsilon = 0.0008; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: fglff
Agent followed the waypoint forward. (rewarded 2.15)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: fgNll
Agent followed the waypoint forward. (rewarded 2.65)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 0.04)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.19)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.96)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: lglNN
Agent drove right instead of left. (rewarded 1.36)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: rrlNr
Agent followed the waypoint right. (rewarded 1.64)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: rgNNN
Agent drove left instead of right. (rewarded 1.03)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: rrrlN
Agent attempted driving forward through a red light. (rewarded -10.70)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: rgNNl
Agent followed the waypoint right. (rewarded 2.63)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: rgNNl
Agent followed the waypoint right. (rewarded 2.61)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: fglfN
Agent followed the waypoint forward. (rewarded 2.70)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: fglfN
Agent followed the waypoint forward. (rewarded 2.62)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: fgNlN
Agent followed the waypoint forward. (rewarded 0.78)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.87)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: lrfrl
Agent drove right instead of left. (rewarded 0.27)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: rgNfl
Agent drove forward instead of right. (rewarded 0.96)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: rrlll
Agent attempted driving forward through a red light. (rewarded -9.61)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: rrlNN
Agent followed the waypoint right. (rewarded 1.74)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: rgrrr
Agent drove forward instead of right. (rewarded 0.98)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: rrNNl
Agent followed the waypoint right. (rewarded 0.85)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: rglrN
Agent drove forward instead of right. (rewarded -0.55)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 2.20)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 0.33)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 1.52)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 19
\-------------------------

test Epsilon0.000751799616535
Simulating trial. . . 
epsilon = 0.0005; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 0.77)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: lrNrN
Agent drove right instead of left. (rewarded 1.85)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: frfNN
Agent drove right instead of forward. (rewarded 0.62)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: lrfNN
Agent properly idled at a red light. (rewarded 2.07)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: lrflN
Agent drove right instead of left. (rewarded 1.49)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: frlrN
Agent attempted driving forward through a red light. (rewarded -9.61)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 1.72)
77% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: lgNNr
Agent followed the waypoint left. (rewarded 2.72)
73% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: fgrNN
Agent followed the waypoint forward. (rewarded 2.16)
70% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.70)
67% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.12)
63% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 0.16)
60% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: lgNNl
Agent drove right instead of left. (rewarded 1.66)
57% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.30)
53% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: lrNNl
Agent properly idled at a red light. (rewarded 1.82)
50% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: lrNlN
Agent drove right instead of left. (rewarded 0.71)
47% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: rgrNN
Agent drove forward instead of right. (rewarded 0.54)
43% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: rgrfN
Agent drove forward instead of right. (rewarded -0.19)
40% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: rglNN
Agent drove forward instead of right. (rewarded 0.16)
37% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: rrNlN
Agent followed the waypoint right. (rewarded 1.14)
33% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: fgNfN
Agent drove right instead of forward. (rewarded 1.31)
30% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.67)
27% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: lrfrl
Agent drove right instead of left. (rewarded 0.68)
23% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 0.92)
20% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 0.91)
17% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Agent previous state: rgNNN
Agent drove left instead of right. (rewarded 0.78)
13% of time remaining to reach destination.

/-------------------
| Step 26 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.04)
10% of time remaining to reach destination.

/-------------------
| Step 27 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 0.47)
7% of time remaining to reach destination.

/-------------------
| Step 28 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 0.75)
3% of time remaining to reach destination.

/-------------------
| Step 29 Results
\-------------------

Agent previous state: lglNN
Agent drove right instead of left. (rewarded -0.55)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Training trial 20
\-------------------------

test Epsilon0.00049242874883
Simulating trial. . . 
epsilon = 0.0003; alpha = 0.6550

/-------------------
| Step 0 Results
\-------------------

Agent previous state: lgrNN
Agent drove forward instead of left. (rewarded 0.12)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: lgNNf
Agent drove forward instead of left. (rewarded 1.00)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: lrfNl
Agent drove right instead of left. (rewarded 0.97)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: frllN
Agent drove right instead of forward. (rewarded 1.49)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: lrNlf
Agent drove right instead of left. (rewarded 1.70)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 0.30)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: lrrNN
Agent properly idled at a red light. (rewarded 1.01)
77% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: lgNrN
Agent drove forward instead of left. (rewarded 0.54)
73% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: lglNf
Agent drove forward instead of left. (rewarded 1.56)
70% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.50)
67% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: lrNrN
Agent drove right instead of left. (rewarded 0.03)
63% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: frNNl
Agent drove right instead of forward. (rewarded 1.54)
60% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: lgNlf
Agent drove forward instead of left. (rewarded 1.62)
57% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: lglNN
Agent drove right instead of left. (rewarded 0.22)
53% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: fglfl
Agent followed the waypoint forward. (rewarded 1.07)
50% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: frNNf
Agent properly idled at a red light. (rewarded 1.99)
47% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: fgNNf
Agent followed the waypoint forward. (rewarded 1.37)
43% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: fgNff
Agent followed the waypoint forward. (rewarded 2.07)
40% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.62)
37% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded -0.28)
33% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: lgllN
Agent drove forward instead of left. (rewarded 0.81)
30% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded -0.37)
27% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: lrNlf
Agent drove right instead of left. (rewarded 0.53)
23% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: rrrNl
Agent attempted driving forward through a red light. (rewarded -10.52)
20% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: rrNfN
Agent properly idled at a red light. (rewarded 2.26)
17% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Agent previous state: rgNNl
Agent followed the waypoint right. (rewarded 1.20)
13% of time remaining to reach destination.

/-------------------
| Step 26 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 2.29)
10% of time remaining to reach destination.

/-------------------
| Step 27 Results
\-------------------

Agent previous state: rrNrN
Agent attempted driving forward through a red light. (rewarded -10.04)
7% of time remaining to reach destination.

/-------------------
| Step 28 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 1.41)
3% of time remaining to reach destination.

/-------------------
| Step 29 Results
\-------------------

Agent previous state: rglNN
Agent drove forward instead of right. (rewarded -0.75)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Testing trial 1
\-------------------------

test Epsilon0.000322540830484
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Agent previous state: frlll
Agent attempted driving forward through a red light. (rewarded -9.47)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: frlrl
Agent attempted driving forward through a red light. (rewarded -9.84)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 0.20)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: lgNfN
Agent drove forward instead of left. (rewarded 0.60)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: lgNrl
Agent drove forward instead of left. (rewarded 1.25)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: lgfNN
Agent drove right instead of left. (rewarded 1.02)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 1.35)
77% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: lglfN
Agent drove forward instead of left. (rewarded 1.75)
73% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: lgNNf
Agent drove forward instead of left. (rewarded 0.29)
70% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: lglNf
Agent drove forward instead of left. (rewarded 1.30)
67% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: lglfN
Agent drove forward instead of left. (rewarded 0.33)
63% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: lgfNl
Agent drove right instead of left. (rewarded 1.52)
60% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 1.81)
57% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: lrNfr
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.91)
53% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: lrlNf
Agent drove right instead of left. (rewarded 0.73)
50% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: fglll
Agent followed the waypoint forward. (rewarded 2.31)
47% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: frNfN
Agent attempted driving right through traffic and cause a minor accident. (rewarded -20.98)
43% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: fgNlf
Agent followed the waypoint forward. (rewarded 2.19)
40% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: fgNfN
Agent drove right instead of forward. (rewarded 1.22)
37% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 0.82)
33% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.63)
30% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: lglNN
Agent drove right instead of left. (rewarded 0.06)
27% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: lrffN
Agent properly idled at a red light. (rewarded 1.87)
23% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: lrfNN
Agent properly idled at a red light. (rewarded 1.81)
20% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: lrffl
Agent properly idled at a red light. (rewarded 0.99)
17% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Agent previous state: lgfNl
Agent drove right instead of left. (rewarded 0.80)
13% of time remaining to reach destination.

/-------------------
| Step 26 Results
\-------------------

Agent previous state: rrlNl
Agent attempted driving forward through a red light. (rewarded -9.90)
10% of time remaining to reach destination.

/-------------------
| Step 27 Results
\-------------------

Agent previous state: rrllN
Agent attempted driving forward through a red light. (rewarded -10.53)
7% of time remaining to reach destination.

/-------------------
| Step 28 Results
\-------------------

Agent previous state: rrlNN
Agent followed the waypoint right. (rewarded 1.81)
3% of time remaining to reach destination.

/-------------------
| Step 29 Results
\-------------------

Agent previous state: fgNfN
Agent drove right instead of forward. (rewarded 0.50)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Testing trial 2
\-------------------------

test Epsilon0
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Agent previous state: fgNNl
Agent followed the waypoint forward. (rewarded 1.53)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: fgNNf
Agent followed the waypoint forward. (rewarded 2.17)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: lrlll
Agent attempted driving forward through a red light. (rewarded -9.37)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.50)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: lglNN
Agent drove right instead of left. (rewarded 1.88)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded -0.02)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 1.73)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: lrNNl
Agent properly idled at a red light. (rewarded 2.83)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: lrNNf
Agent drove right instead of left. (rewarded 0.72)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: rgNfN
Agent drove forward instead of right. (rewarded 1.30)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: rgNff
Agent drove forward instead of right. (rewarded 0.17)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: rrlNl
Agent attempted driving forward through a red light. (rewarded -10.36)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: rrlrl
Agent attempted driving forward through a red light. (rewarded -10.38)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: rgllf
Agent drove forward instead of right. (rewarded -0.03)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: rgNNN
Agent drove left instead of right. (rewarded 1.53)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: rrNfN
Agent properly idled at a red light. (rewarded 1.73)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: rgNNN
Agent drove left instead of right. (rewarded 1.09)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: lgflN
Agent drove forward instead of left. (rewarded -0.17)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: lglrN
Agent drove forward instead of left. (rewarded -0.31)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: lgNfN
Agent drove forward instead of left. (rewarded 0.39)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: lgNNl
Agent drove right instead of left. (rewarded 1.16)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: frNlN
Agent drove right instead of forward. (rewarded -0.07)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: lrNff
Agent attempted driving right through traffic and cause a minor accident. (rewarded -20.89)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: lrfNf
Agent drove right instead of left. (rewarded -0.60)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: fgfNf
Agent drove right instead of forward. (rewarded -0.48)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Testing trial 3
\-------------------------

test Epsilon0
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Agent previous state: fgNNf
Agent followed the waypoint forward. (rewarded 1.30)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: fgfNN
Agent followed the waypoint forward. (rewarded 1.71)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: fgNfN
Agent drove right instead of forward. (rewarded 1.82)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: lrfrN
Agent drove right instead of left. (rewarded 0.45)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: rrNNl
Agent followed the waypoint right. (rewarded 2.93)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: rgNNN
Agent drove left instead of right. (rewarded 1.82)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: rrNff
Agent attempted driving right through traffic and cause a minor accident. (rewarded -19.04)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: rrlNN
Agent followed the waypoint right. (rewarded 2.46)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: rgNNN
Agent drove left instead of right. (rewarded -0.10)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 0.46)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: lrfNN
Agent properly idled at a red light. (rewarded 2.14)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: lgfNN
Agent drove right instead of left. (rewarded 1.14)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.40)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: frfNN
Agent drove right instead of forward. (rewarded 1.22)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: lgNNf
Agent drove forward instead of left. (rewarded 0.91)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.11)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: lgNfr
Agent drove forward instead of left. (rewarded 1.35)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: lrNfN
Agent properly idled at a red light. (rewarded 1.58)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: lrNNl
Agent properly idled at a red light. (rewarded 1.50)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: lgfNN
Agent drove right instead of left. (rewarded 0.23)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 0.68)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: lrlNr
Agent drove right instead of left. (rewarded 0.70)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded -0.65)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: lrNrN
Agent drove right instead of left. (rewarded -0.33)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: fgNfr
Agent drove left instead of forward. (rewarded -0.83)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Testing trial 4
\-------------------------

test Epsilon0
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Agent previous state: lgNfN
Agent drove forward instead of left. (rewarded 1.72)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.90)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.11)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.55)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.97)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: fgNlN
Agent followed the waypoint forward. (rewarded 1.71)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.76)
77% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: frNNr
Agent drove right instead of forward. (rewarded 1.28)
73% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: lrNNf
Agent drove right instead of left. (rewarded 0.46)
70% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.41)
67% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: fgNlf
Agent followed the waypoint forward. (rewarded 2.36)
63% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: frflN
Agent drove right instead of forward. (rewarded 1.00)
60% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: lrlNf
Agent drove right instead of left. (rewarded 0.81)
57% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: lgNrN
Agent drove forward instead of left. (rewarded 0.44)
53% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: fglrN
Agent followed the waypoint forward. (rewarded 2.31)
50% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: frfNN
Agent drove right instead of forward. (rewarded 0.73)
47% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: lrflf
Agent drove right instead of left. (rewarded 0.92)
43% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.65)
40% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.27)
37% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.76)
33% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: fgfNf
Agent drove right instead of forward. (rewarded 0.94)
30% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: lrNlN
Agent drove right instead of left. (rewarded 0.04)
27% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 1.42)
23% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.25)
20% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: lrfNN
Agent properly idled at a red light. (rewarded 1.74)
17% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Agent previous state: lgfNN
Agent drove right instead of left. (rewarded 0.06)
13% of time remaining to reach destination.

/-------------------
| Step 26 Results
\-------------------

Agent previous state: fgNfN
Agent drove right instead of forward. (rewarded -0.30)
10% of time remaining to reach destination.

/-------------------
| Step 27 Results
\-------------------

Agent previous state: lrrNN
Agent properly idled at a red light. (rewarded 0.38)
7% of time remaining to reach destination.

/-------------------
| Step 28 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.35)
3% of time remaining to reach destination.

/-------------------
| Step 29 Results
\-------------------

Agent previous state: lgNNf
Agent drove forward instead of left. (rewarded -0.79)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Testing trial 5
\-------------------------

test Epsilon0
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Agent previous state: rgNNr
Agent drove forward instead of right. (rewarded 0.92)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: rgNNN
Agent drove left instead of right. (rewarded 0.84)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: frfNN
Agent drove right instead of forward. (rewarded 1.05)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: lgNll
Agent drove forward instead of left. (rewarded 1.77)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: lgNrN
Agent drove forward instead of left. (rewarded 0.15)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: lgNlN
Agent drove right instead of left. (rewarded 0.09)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: fglNf
Agent followed the waypoint forward. (rewarded 2.81)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: frNNl
Agent drove right instead of forward. (rewarded 1.18)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: lgfNN
Agent drove right instead of left. (rewarded 1.16)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: lgNlf
Agent drove forward instead of left. (rewarded 1.35)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: fgNNl
Agent followed the waypoint forward. (rewarded 1.99)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: frNfN
Agent attempted driving right through traffic and cause a minor accident. (rewarded -19.29)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.01)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 0.93)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 2.12)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: lrlNl
Agent attempted driving forward through a red light. (rewarded -10.69)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: lglNN
Agent drove right instead of left. (rewarded 1.43)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: rgrNN
Agent drove forward instead of right. (rewarded 1.24)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: fgNfN
Agent drove right instead of forward. (rewarded 1.33)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: lrlNf
Agent drove right instead of left. (rewarded 1.32)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: frNNl
Agent drove right instead of forward. (rewarded 0.72)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: lgNll
Agent drove forward instead of left. (rewarded 1.34)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 0.89)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.30)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 0.42)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Testing trial 6
\-------------------------

test Epsilon0
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Agent previous state: fgfll
Agent followed the waypoint forward. (rewarded 1.17)
95% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 2.53)
90% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 2.77)
85% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: rrNNl
Agent followed the waypoint right. (rewarded 2.90)
80% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: frlNN
Agent drove right instead of forward. (rewarded 1.69)
75% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: lgrfl
Agent drove forward instead of left. (rewarded 1.70)
70% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: lrrNN
Agent properly idled at a red light. (rewarded 2.40)
65% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 1.06)
60% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: lgNrf
Agent drove forward instead of left. (rewarded 0.93)
55% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: fgllN
Agent followed the waypoint forward. (rewarded 2.01)
50% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: fglNl
Agent followed the waypoint forward. (rewarded 2.51)
45% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: frrNN
Agent properly idled at a red light. (rewarded 1.69)
40% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: frfNN
Agent drove right instead of forward. (rewarded 0.36)
35% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.53)
30% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 0.69)
25% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.57)
20% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.11)
15% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.22)
10% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: lrrNN
Agent properly idled at a red light. (rewarded 1.45)
5% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 0.78)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Testing trial 7
\-------------------------

test Epsilon0
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Agent previous state: rrNlf
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.48)
97% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: rrNfN
Agent properly idled at a red light. (rewarded 2.21)
93% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 2.50)
90% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 2.86)
87% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 2.30)
83% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: rrNNf
Agent followed the waypoint right. (rewarded 2.45)
80% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: frNlN
Agent drove right instead of forward. (rewarded 0.30)
77% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 1.73)
73% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 2.75)
70% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 1.72)
67% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: lgNNf
Agent drove forward instead of left. (rewarded 1.56)
63% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: lglfN
Agent drove forward instead of left. (rewarded 0.95)
60% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: lgNNN
Agent drove forward instead of left. (rewarded 0.46)
57% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: lrNlf
Agent drove right instead of left. (rewarded 1.64)
53% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: rgNNf
Agent drove forward instead of right. (rewarded 1.14)
50% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: fgNll
Agent followed the waypoint forward. (rewarded 2.48)
47% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: frlNN
Agent drove right instead of forward. (rewarded -0.18)
43% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: lrNNf
Agent drove right instead of left. (rewarded 0.03)
40% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 1.68)
37% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: lrNfN
Agent properly idled at a red light. (rewarded 1.77)
33% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: lrNNN
Agent properly idled at a red light. (rewarded 0.90)
30% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: lgNNl
Agent drove right instead of left. (rewarded 1.01)
27% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 0.73)
23% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: rrrrN
Agent attempted driving forward through a red light. (rewarded -9.10)
20% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 2.34)
17% of time remaining to reach destination.

/-------------------
| Step 25 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 0.74)
13% of time remaining to reach destination.

/-------------------
| Step 26 Results
\-------------------

Agent previous state: rgNNN
Agent drove left instead of right. (rewarded -0.25)
10% of time remaining to reach destination.

/-------------------
| Step 27 Results
\-------------------

Agent previous state: frlNl
Agent drove right instead of forward. (rewarded 0.54)
7% of time remaining to reach destination.

/-------------------
| Step 28 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 0.53)
3% of time remaining to reach destination.

/-------------------
| Step 29 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.63)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Testing trial 8
\-------------------------

test Epsilon0
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Agent previous state: lrNrN
Agent drove right instead of left. (rewarded 1.22)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: rglll
Agent drove forward instead of right. (rewarded 1.47)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: frNNl
Agent drove right instead of forward. (rewarded 1.69)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: lgNfN
Agent drove forward instead of left. (rewarded 0.05)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: lgNff
Agent drove right instead of left. (rewarded 0.48)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.43)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: frNfN
Agent attempted driving right through traffic and cause a minor accident. (rewarded -19.48)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 0.80)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: lrNfN
Agent properly idled at a red light. (rewarded 1.70)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: lrNNf
Agent drove right instead of left. (rewarded 1.17)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: fglll
Agent followed the waypoint forward. (rewarded 1.65)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: frfNN
Agent drove right instead of forward. (rewarded 1.02)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: lgfNf
Agent drove forward instead of left. (rewarded 0.78)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: lgNNl
Agent drove right instead of left. (rewarded 1.30)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: rgNrf
Agent followed the waypoint right. (rewarded 1.86)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: rgNNN
Agent drove left instead of right. (rewarded 1.64)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: fgNfl
Agent followed the waypoint forward. (rewarded 0.88)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: fgNrN
Agent followed the waypoint forward. (rewarded 1.48)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.10)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: frrNN
Agent properly idled at a red light. (rewarded 0.62)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: frNfN
Agent attempted driving right through traffic and cause a minor accident. (rewarded -20.52)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: fgNfl
Agent followed the waypoint forward. (rewarded 1.12)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: fglNN
Agent drove right instead of forward. (rewarded 1.00)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: lrrNN
Agent properly idled at a red light. (rewarded 1.81)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: lrrNf
Agent drove right instead of left. (rewarded 0.09)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

/-------------------------
| Testing trial 9
\-------------------------

test Epsilon0
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 0.75)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: lgNlN
Agent drove right instead of left. (rewarded 0.87)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: fgNNl
Agent followed the waypoint forward. (rewarded 2.05)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: fglfN
Agent followed the waypoint forward. (rewarded 2.06)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: fgNfl
Agent followed the waypoint forward. (rewarded 2.31)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: rrNfl
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -40.82)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 2.46)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: rrNrN
Agent followed the waypoint right. (rewarded 1.84)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: fgNlf
Agent followed the waypoint forward. (rewarded 2.27)
64% of time remaining to reach destination.

Trial Completed!
Agent reached the destination.

/-------------------------
| Testing trial 10
\-------------------------

test Epsilon0
Simulating trial. . . 
epsilon = 0.0000; alpha = 0.0000

/-------------------
| Step 0 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 1.75)
96% of time remaining to reach destination.

/-------------------
| Step 1 Results
\-------------------

Agent previous state: frlNN
Agent drove right instead of forward. (rewarded -0.01)
92% of time remaining to reach destination.

/-------------------
| Step 2 Results
\-------------------

Agent previous state: lrfNr
Agent drove right instead of left. (rewarded 0.39)
88% of time remaining to reach destination.

/-------------------
| Step 3 Results
\-------------------

Agent previous state: fgNNN
Agent drove right instead of forward. (rewarded 0.39)
84% of time remaining to reach destination.

/-------------------
| Step 4 Results
\-------------------

Agent previous state: lrlNl
Agent attempted driving forward through a red light. (rewarded -9.20)
80% of time remaining to reach destination.

/-------------------
| Step 5 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.43)
76% of time remaining to reach destination.

/-------------------
| Step 6 Results
\-------------------

Agent previous state: lglNN
Agent drove right instead of left. (rewarded 0.72)
72% of time remaining to reach destination.

/-------------------
| Step 7 Results
\-------------------

Agent previous state: fgNfr
Agent drove left instead of forward. (rewarded 0.52)
68% of time remaining to reach destination.

/-------------------
| Step 8 Results
\-------------------

Agent previous state: rrfNN
Agent followed the waypoint right. (rewarded 1.28)
64% of time remaining to reach destination.

/-------------------
| Step 9 Results
\-------------------

Agent previous state: frNNN
Agent properly idled at a red light. (rewarded 2.26)
60% of time remaining to reach destination.

/-------------------
| Step 10 Results
\-------------------

Agent previous state: frNNf
Agent properly idled at a red light. (rewarded 2.58)
56% of time remaining to reach destination.

/-------------------
| Step 11 Results
\-------------------

Agent previous state: frNfl
Agent attempted driving forward through a red light with traffic and cause a major accident. (rewarded -39.60)
52% of time remaining to reach destination.

/-------------------
| Step 12 Results
\-------------------

Agent previous state: frNlN
Agent drove right instead of forward. (rewarded 0.66)
48% of time remaining to reach destination.

/-------------------
| Step 13 Results
\-------------------

Agent previous state: lgllN
Agent drove forward instead of left. (rewarded 0.86)
44% of time remaining to reach destination.

/-------------------
| Step 14 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 1.85)
40% of time remaining to reach destination.

/-------------------
| Step 15 Results
\-------------------

Agent previous state: lrlNN
Agent properly idled at a red light. (rewarded 2.16)
36% of time remaining to reach destination.

/-------------------
| Step 16 Results
\-------------------

Agent previous state: lglNN
Agent drove right instead of left. (rewarded 0.34)
32% of time remaining to reach destination.

/-------------------
| Step 17 Results
\-------------------

Agent previous state: rgNNl
Agent followed the waypoint right. (rewarded 0.92)
28% of time remaining to reach destination.

/-------------------
| Step 18 Results
\-------------------

Agent previous state: rgllN
Agent drove forward instead of right. (rewarded 0.08)
24% of time remaining to reach destination.

/-------------------
| Step 19 Results
\-------------------

Agent previous state: rrNNf
Agent followed the waypoint right. (rewarded 1.76)
20% of time remaining to reach destination.

/-------------------
| Step 20 Results
\-------------------

Agent previous state: frlNl
Agent drove right instead of forward. (rewarded -0.33)
16% of time remaining to reach destination.

/-------------------
| Step 21 Results
\-------------------

Agent previous state: lgNfl
Agent drove forward instead of left. (rewarded 0.22)
12% of time remaining to reach destination.

/-------------------
| Step 22 Results
\-------------------

Agent previous state: lrNNl
Agent properly idled at a red light. (rewarded 1.75)
8% of time remaining to reach destination.

/-------------------
| Step 23 Results
\-------------------

Agent previous state: lrNlN
Agent drove right instead of left. (rewarded -0.81)
4% of time remaining to reach destination.

/-------------------
| Step 24 Results
\-------------------

Agent previous state: rrNNN
Agent properly idled at a red light. (rewarded 0.18)
0% of time remaining to reach destination.

Trial Aborted!
Agent did not reach the destination.

Simulation ended. . . 
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[50]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Load the &#39;sim_improved-learning&#39; file from the improved Q-Learning simulation</span>
<span class="n">vs</span><span class="o">.</span><span class="n">plot_trials</span><span class="p">(</span><span class="s1">&#39;sim_improved-learning.csv&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA1gAAAI4CAYAAAB3HEhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Question-7">Question 7<a class="anchor-link" href="#Question-7">&#182;</a></h3><p>Using the visualization above that was produced from your improved Q-Learning simulation, provide a final analysis and make observations about the improved driving agent like in <strong>Question 6</strong>. Questions you should answer:</p>
<ul>
<li><em>What decaying function was used for epsilon (the exploration factor)?</em></li>
<li><em>Approximately how many training trials were needed for your agent before begining testing?</em></li>
<li><em>What epsilon-tolerance and alpha (learning rate) did you use? Why did you use them?</em></li>
<li><em>How much improvement was made with this Q-Learner when compared to the default Q-Learner from the previous section?</em></li>
<li><em>Would you say that the Q-Learner results show that your driving agent successfully learned an appropriate policy?</em></li>
<li><em>Are you satisfied with the safety and reliability ratings of the </em>Smartcab<em>?</em></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Answer:</strong></p>
<ul>
<li>I tried all the optinal function but I got the best result from this function $$ \epsilon = a^t, \textrm{for } 0 < a < 1 $$ </li>
<li>I used the same amount of trials for privece testing which is 20 for learning and 10 for testing.</li>
<li>The learning start with 0.8 for epsilon and 0.65 for alpha.</li>
<li>The result is incremtal changed from the last section like the total bad action at the end  is 0.1156 and reliability is between 80% to 60%.</li>
<li>The agent started to learn from because the bad action is redused so it get benifit from the policyes.</li>
<li>No, I think should the rating be better but I tried so many times and I changed the value of alpha without any prograssied.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Define-an-Optimal-Policy">Define an Optimal Policy<a class="anchor-link" href="#Define-an-Optimal-Policy">&#182;</a></h3><p>Sometimes, the answer to the important question <em>"what am I trying to get my agent to learn?"</em> only has a theoretical answer and cannot be concretely described. Here, however, you can concretely define what it is the agent is trying to learn, and that is the U.S. right-of-way traffic laws. Since these laws are known information, you can further define, for each state the <em>Smartcab</em> is occupying, the optimal action for the driving agent based on these laws. In that case, we call the set of optimal state-action pairs an <strong>optimal policy</strong>. Hence, unlike some theoretical answers, it is clear whether the agent is acting "incorrectly" not only by the reward (penalty) it receives, but also by pure observation. If the agent drives through a red light, we both see it receive a negative reward but also know that it is not the correct behavior. This can be used to your advantage for verifying whether the <strong>policy</strong> your driving agent has learned is the correct one, or if it is a <strong>suboptimal policy</strong>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Question-8">Question 8<a class="anchor-link" href="#Question-8">&#182;</a></h3><p>Provide a few examples (using the states you've defined) of what an optimal policy for this problem would look like. Afterwards, investigate the <code>'sim_improved-learning.txt'</code> text file to see the results of your improved Q-Learning algorithm. <em>For each state that has been recorded from the simulation, is the <strong>policy</strong> (the action with the highest value) correct for the given state? Are there any states where the policy is different than what would be expected from an optimal policy?</em> Provide an example of a state and all state-action rewards recorded, and explain why it is the correct policy.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Answer:</strong> 
In this states the which the id represent (waypoint, light, oncoming, left, right) so the first letter is waypoint and the value is forward beside that forward is the highiest value which is rghit.
fgNrf
 -- forward : 0.39
 -- right : 0.00
 -- None : 0.00
 -- left : 0.00</p>
<p>fgfrl
 -- forward : 1.47
 -- right : 0.00
 -- None : 0.00
 -- left : 0.00</p>
<p>And in this case which is diffrent from the status we could find the light is green and shoud go forward but the best action is None</p>
<p>fglNr
 -- forward : 0.00
 -- right : 0.00
 -- None : 1.18
 -- left : 0.00</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Optional:-Future-Rewards---Discount-Factor,-'gamma'">Optional: Future Rewards - Discount Factor, <code>'gamma'</code><a class="anchor-link" href="#Optional:-Future-Rewards---Discount-Factor,-'gamma'">&#182;</a></h3><p>Curiously, as part of the Q-Learning algorithm, you were asked to <strong>not</strong> use the discount factor, <code>'gamma'</code> in the implementation. Including future rewards in the algorithm is used to aid in propogating positive rewards backwards from a future state to the current state. Essentially, if the driving agent is given the option to make several actions to arrive at different states, including future rewards will bias the agent towards states that could provide even more rewards. An example of this would be the driving agent moving towards a goal: With all actions and rewards equal, moving towards the goal would theoretically yield better rewards if there is an additional reward for reaching the goal. However, even though in this project, the driving agent is trying to reach a destination in the allotted time, including future rewards will not benefit the agent. In fact, if the agent were given many trials to learn, it could negatively affect Q-values!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Optional-Question-9">Optional Question 9<a class="anchor-link" href="#Optional-Question-9">&#182;</a></h3><p><em>There are two characteristics about the project that invalidate the use of future rewards in the Q-Learning algorithm. One characteristic has to do with the </em>Smartcab<em> itself, and the other has to do with the environment. Can you figure out what they are and why future rewards won't work for this project?</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Answer:</strong>
the environment characteristics is the dummies which is randomly moving and that changing the future reward.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p><strong>Note</strong>: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to<br>
<strong>File -&gt; Download as -&gt; HTML (.html)</strong>. Include the finished document along with this notebook as your submission.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
    </div>
  </div>
</body>
</html>
